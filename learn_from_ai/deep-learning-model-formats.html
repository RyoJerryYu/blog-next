<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="width=device-width, initial-scale=1" data-next-head=""/><meta property="og:image" content="https://ryojerryyu.github.io/blog-next/img/home-bg-kasumi-hanabi.jpg" data-next-head=""/><meta name="twitter:image" content="https://ryojerryyu.github.io/blog-next/img/home-bg-kasumi-hanabi.jpg" data-next-head=""/><meta property="og:type" content="website" data-next-head=""/><meta property="og:url" content="https://blog.ryo-okami.xyz/learn_from_ai/deep-learning-model-formats" data-next-head=""/><meta name="twitter:card" content="summary_large_image" data-next-head=""/><meta name="twitter:site" content="@ryo_okami" data-next-head=""/><meta name="twitter:creator" content="@ryo_okami" data-next-head=""/><link rel="icon" href="/blog-next/favicon.ico" data-next-head=""/><meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests" data-next-head=""/><title data-next-head="">深度学习模型文件格式对比：pth、safetensor 与 onnx | Ryo&#x27;s Blog</title><meta property="og:title" content="深度学习模型文件格式对比：pth、safetensor 与 onnx" data-next-head=""/><meta property="og:site_name" content="Ryo&#x27;s Blog" data-next-head=""/><meta name="twitter:title" content="深度学习模型文件格式对比：pth、safetensor 与 onnx | Ryo&#x27;s Blog" data-next-head=""/><meta name="description" content="&gt; 本页面介绍了三种机器学习模型文件格式：.pth、.safetensor 和 .onnx。主要内容包括每种格式的定义、保存的内容、用途以及它们之间的区别和转换方法。
PyTorch 中的`.pth`文件通常用于保存模型的权重（parameters）和训练过程中的优化器状态（optimizer state）。具体来说，一个`.pth`文件可能包含以下内容：
1. **模型状态字典（Model state dictionary）**：" data-next-head=""/><meta property="og:description" content="&gt; 本页面介绍了三种机器学习模型文件格式：.pth、.safetensor 和 .onnx。主要内容包括每种格式的定义、保存的内容、用途以及它们之间的区别和转换方法。
PyTorch 中的`.pth`文件通常用于保存模型的权重（parameters）和训练过程中的优化器状态（optimizer state）。具体来说，一个`.pth`文件可能包含以下内容：
1. **模型状态字典（Model state dictionary）**：" data-next-head=""/><meta name="twitter:description" content="&gt; 本页面介绍了三种机器学习模型文件格式：.pth、.safetensor 和 .onnx。主要内容包括每种格式的定义、保存的内容、用途以及它们之间的区别和转换方法。
PyTorch 中的`.pth`文件通常用于保存模型的权重（parameters）和训练过程中的优化器状态（optimizer state）。具体来说，一个`.pth`文件可能包含以下内容：
1. **模型状态字典（Model state dictionary）**：" data-next-head=""/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><link rel="apple-touch-icon" href="/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="192x192" href="/android-chrome-192x192.png"/><link rel="manifest" href="/site.webmanifest"/><meta name="msapplication-TileColor" content="#da532c"/><meta name="theme-color" content="#ffffff"/><link data-next-font="" rel="preconnect" href="/" crossorigin="anonymous"/><link rel="preload" href="/blog-next/_next/static/css/4a3cf47ca0630aac.css" as="style"/><link rel="preload" href="/blog-next/_next/static/css/ef8d13f536c01c5b.css" as="style"/><link rel="stylesheet" href="/blog-next/_next/static/css/4a3cf47ca0630aac.css" data-n-g=""/><link rel="stylesheet" href="/blog-next/_next/static/css/ef8d13f536c01c5b.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" noModule="" src="/blog-next/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/blog-next/_next/static/chunks/webpack-2425e15f1e5dad7a.js" defer=""></script><script src="/blog-next/_next/static/chunks/framework-dbc2568ebd4bd029.js" defer=""></script><script src="/blog-next/_next/static/chunks/main-1bf486756f8ae5cb.js" defer=""></script><script src="/blog-next/_next/static/chunks/pages/_app-262e0ceb0db45a8b.js" defer=""></script><script src="/blog-next/_next/static/chunks/6d2b60a9-83a8c926c8260086.js" defer=""></script><script src="/blog-next/_next/static/chunks/52d06cd5-1bcdd4311345b439.js" defer=""></script><script src="/blog-next/_next/static/chunks/5426-9c12869cfb286694.js" defer=""></script><script src="/blog-next/_next/static/chunks/4587-a20f45cd24abe7eb.js" defer=""></script><script src="/blog-next/_next/static/chunks/6531-89dc84d48728a227.js" defer=""></script><script src="/blog-next/_next/static/chunks/226-00fd6c15dd2bda34.js" defer=""></script><script src="/blog-next/_next/static/chunks/5630-002844667a39aabf.js" defer=""></script><script src="/blog-next/_next/static/chunks/pages/learn_from_ai/%5Bslug%5D-2fa0e7de99320ef8.js" defer=""></script><script src="/blog-next/_next/static/OwkYdUeC5nrv7JKUkxwdh/_buildManifest.js" defer=""></script><script src="/blog-next/_next/static/OwkYdUeC5nrv7JKUkxwdh/_ssgManifest.js" defer=""></script></head><body><div id="__next"><style data-emotion="css czlpqi">.css-czlpqi{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;width:100%;box-sizing:border-box;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;position:fixed;z-index:1100;top:0;left:auto;right:0;--AppBar-background:#1976d2;--AppBar-color:#fff;background-color:var(--AppBar-background);color:var(--AppBar-color);background-color:rgba(15, 23, 42, 0.75);}@media print{.css-czlpqi{position:absolute;}}</style><style data-emotion="css 1cmpeoq">.css-1cmpeoq{background-color:#fff;color:rgba(0, 0, 0, 0.87);-webkit-transition:box-shadow 300ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:box-shadow 300ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;box-shadow:var(--Paper-shadow);background-image:var(--Paper-overlay);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;width:100%;box-sizing:border-box;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;position:fixed;z-index:1100;top:0;left:auto;right:0;--AppBar-background:#1976d2;--AppBar-color:#fff;background-color:var(--AppBar-background);color:var(--AppBar-color);background-color:rgba(15, 23, 42, 0.75);}@media print{.css-1cmpeoq{position:absolute;}}</style><header class="MuiPaper-root MuiPaper-elevation MuiPaper-elevation4 MuiAppBar-root MuiAppBar-colorPrimary MuiAppBar-positionFixed mui-fixed css-1cmpeoq" style="--Paper-shadow:0px 2px 4px -1px rgba(0,0,0,0.2),0px 4px 5px 0px rgba(0,0,0,0.14),0px 1px 10px 0px rgba(0,0,0,0.12)"><style data-emotion="css awgou1">.css-awgou1{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-left:16px;padding-right:16px;min-height:56px;}@media (min-width:600px){.css-awgou1{padding-left:24px;padding-right:24px;}}@media (min-width:0px){@media (orientation: landscape){.css-awgou1{min-height:48px;}}}@media (min-width:600px){.css-awgou1{min-height:64px;}}</style><div class="MuiToolbar-root MuiToolbar-gutters MuiToolbar-regular css-awgou1"><style data-emotion="css 1guk29">@media (min-width:0px){.css-1guk29{display:none;}}@media (min-width:900px){.css-1guk29{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}</style><div class="ml-2 w-24 mr-4 MuiBox-root css-1guk29"><a class="DefaultLayout_textlink__W55gl" href="/blog-next">Ryo&#x27;s Blog</a></div><style data-emotion="css 1m04nb5">@media (min-width:0px){.css-1m04nb5{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}@media (min-width:900px){.css-1m04nb5{display:none;}}</style><div class="ml-2 mr-4 MuiBox-root css-1m04nb5"><a title="Ryo&#x27;s Blog" href="/blog-next"><style data-emotion="css q7mezt">.css-q7mezt{-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;width:1em;height:1em;display:inline-block;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;-webkit-transition:fill 200ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:fill 200ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;fill:currentColor;font-size:1.5rem;}</style><svg class="MuiSvgIcon-root MuiSvgIcon-fontSizeMedium h-6 w-6 text-gray-300 hover:text-white css-q7mezt" focusable="false" aria-hidden="true" viewBox="0 0 24 24" data-testid="HomeIcon"><path d="M10 20v-6h4v6h5v-8h3L12 3 2 12h3v8z"></path></svg></a></div><style data-emotion="css nznm6s">.css-nznm6s{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex:1;-ms-flex:1;flex:1;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}</style><div class="MuiBox-root css-nznm6s"><div class="DefaultLayoutMenu bg-transparent min-w-full"><ul class="rc-menu-overflow rc-menu rc-menu-root rc-menu-horizontal" role="menu" tabindex="0" data-menu-list="true"><li class="rc-menu-overflow-item rc-menu-item" style="opacity:1;order:0" role="menuitem" tabindex="-1"><a class="DefaultLayout_textlink__W55gl" href="/blog-next/articles">Articles</a></li><li class="rc-menu-overflow-item rc-menu-item" style="opacity:1;order:1" role="menuitem" tabindex="-1"><a class="DefaultLayout_textlink__W55gl" href="/blog-next/learn_from_ai">Learn from AI</a></li><li class="rc-menu-overflow-item rc-menu-item" style="opacity:1;order:2" role="menuitem" tabindex="-1"><a class="DefaultLayout_textlink__W55gl" href="/blog-next/tags">Tags</a></li><li class="rc-menu-overflow-item rc-menu-submenu rc-menu-submenu-horizontal" style="opacity:1;order:3" role="none"><div role="menuitem" class="rc-menu-submenu-title" tabindex="-1" aria-expanded="false" aria-haspopup="true"><span class="DefaultLayout_textlink__W55gl">More</span><i class="rc-menu-submenu-arrow"></i></div></li><li class="rc-menu-overflow-item rc-menu-overflow-item-rest rc-menu-submenu rc-menu-submenu-horizontal" style="opacity:0;height:0;overflow-y:hidden;order:9007199254740991;pointer-events:none;position:absolute" aria-hidden="true" role="none"><div role="menuitem" class="rc-menu-submenu-title" tabindex="-1" title="..." aria-expanded="false" aria-haspopup="true">...<i class="rc-menu-submenu-arrow"></i></div></li></ul><div style="display:none" aria-hidden="true"></div></div></div><style data-emotion="css k008qs">.css-k008qs{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}</style><div class="MuiBox-root css-k008qs"><a title="Twitter" href="https://twitter.com/ryo_okami"><svg class="h-6 w-6 fill-gray-300 hover:fill-white mx-1 sm:mx-2" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a><a title="GitHub" href="https://github.com/RyoJerryYu"><svg class="h-6 w-6 fill-gray-300 hover:fill-white mx-1 sm:mx-2" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a><a title="Pixiv" href="https://www.pixiv.net/users/9159893"><svg class="h-6 w-6 fill-gray-300 hover:fill-white mx-1 sm:mx-2" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4.935 0A4.924 4.924 0 0 0 0 4.935v14.13A4.924 4.924 0 0 0 4.935 24h14.13A4.924 4.924 0 0 0 24 19.065V4.935A4.924 4.924 0 0 0 19.065 0zm7.81 4.547c2.181 0 4.058.676 5.399 1.847a6.118 6.118 0 0 1 2.116 4.66c.005 1.854-.88 3.476-2.257 4.563-1.375 1.092-3.225 1.697-5.258 1.697-2.314 0-4.46-.842-4.46-.842v2.718c.397.116 1.048.365.635.779H5.79c-.41-.41.19-.65.644-.779V7.666c-1.053.81-1.593 1.51-1.868 2.031.32 1.02-.284.969-.284.969l-1.09-1.73s3.868-4.39 9.553-4.39zm-.19.971c-1.423-.003-3.184.473-4.27 1.244v8.646c.988.487 2.484.832 4.26.832h.01c1.596 0 2.98-.593 3.93-1.533.952-.948 1.486-2.183 1.492-3.683-.005-1.54-.504-2.864-1.42-3.86-.918-.992-2.274-1.645-4.002-1.646Z"></path></svg></a></div></div></header><style data-emotion="css awgou1">.css-awgou1{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-left:16px;padding-right:16px;min-height:56px;}@media (min-width:600px){.css-awgou1{padding-left:24px;padding-right:24px;}}@media (min-width:0px){@media (orientation: landscape){.css-awgou1{min-height:48px;}}}@media (min-width:600px){.css-awgou1{min-height:64px;}}</style><div class="MuiToolbar-root MuiToolbar-gutters MuiToolbar-regular css-awgou1"></div><style data-emotion="css vktxal">.css-vktxal{--Grid-columns:12;--Grid-columnSpacing:0px;--Grid-rowSpacing:0px;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;min-width:0;box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;gap:var(--Grid-rowSpacing) var(--Grid-columnSpacing);width:100%;max-width:80rem;margin-left:auto;margin-right:auto;padding:0.5rem;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;}.css-vktxal >*{--Grid-parent-columns:12;}.css-vktxal >*{--Grid-parent-columnSpacing:0px;}.css-vktxal >*{--Grid-parent-rowSpacing:0px;}</style><div class="MuiGrid2-root MuiGrid2-container MuiGrid2-direction-xs-row css-vktxal"><style data-emotion="css 9gdssj">.css-9gdssj{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 0 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 0) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));min-width:0;box-sizing:border-box;}@media (min-width:900px){.css-9gdssj{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 0 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 0) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}@media (min-width:1200px){.css-9gdssj{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 2 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 2) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}</style><div class="MuiGrid2-root MuiGrid2-direction-xs-row MuiGrid2-grid-xs-0 MuiGrid2-grid-md-0 MuiGrid2-grid-lg-2 css-9gdssj"></div><style data-emotion="css 9h67uz">.css-9h67uz{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 12 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 12) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));min-width:0;box-sizing:border-box;}@media (min-width:900px){.css-9h67uz{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 9 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 9) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}@media (min-width:1200px){.css-9h67uz{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 8 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 8) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}</style><div class="MuiGrid2-root MuiGrid2-direction-xs-row MuiGrid2-grid-xs-12 MuiGrid2-grid-md-9 MuiGrid2-grid-lg-8 css-9h67uz"><div class="DefaultLayout_contentHeight__RDRZE"><article class="Post_post__acRqJ"><h1 class="Post_postTitle__N1NIA">深度学习模型文件格式对比：pth、safetensor 与 onnx</h1><div class="Post_postDate__SQx7A"><time dateTime="2024-11-29T02:00:00.000Z">2024-11-29</time></div><div class="TagsBox_tagsBox__WzhAf mt-2"><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/pytorch">#<!-- -->PyTorch</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/onnx">#<!-- -->ONNX</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0">#<!-- -->深度学习</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2">#<!-- -->模型部署</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0">#<!-- -->学习笔记</a></div><div class="post-body Post_postContent__mJ_Ju"><blockquote>
<p>本页面介绍了三种机器学习模型文件格式：.pth、.safetensor 和 .onnx。主要内容包括每种格式的定义、保存的内容、用途以及它们之间的区别和转换方法。</p>
</blockquote>
<h2 id="pytorch-保存的-pth-文件里都保存了些什么东西"><a href="#pytorch-保存的-pth-文件里都保存了些什么东西">pytorch 保存的 .pth 文件里都保存了些什么东西？</a></h2>
<p>PyTorch 中的<span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.pth</span></span></code></span>文件通常用于保存模型的权重（parameters）和训练过程中的优化器状态（optimizer state）。具体来说，一个<span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.pth</span></span></code></span>文件可能包含以下内容：</p>
<ol>
<li><strong>模型状态字典（Model state dictionary）</strong>：<!-- -->
<ul>
<li>这是<span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.pth</span></span></code></span>文件中最主要的部分，它包含了模型的所有权重（即神经网络的参数），包括卷积层的滤波器、全连接层的权重和偏置等。</li>
<li>状态字典是一个简单的 Python 字典对象，其键是层的名字，值是相应的参数张量。</li>
</ul>
</li>
<li><strong>优化器状态字典（Optimizer state dictionary）</strong>：<!-- -->
<ul>
<li>当保存模型时，通常也会保存优化器的状态，这样可以在模型训练中断后，从上次停止的地方继续训练。</li>
<li>优化器状态字典通常包含每个参数的梯度、动量（momentum）和其他与优化器相关的状态信息（例如 Adam 优化器的矩估计）。</li>
</ul>
</li>
<li><strong>其他可选信息</strong>：<!-- -->
<ul>
<li>有时候，<span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.pth</span></span></code></span>文件可能还会包含其他辅助信息，比如训练的损失值、额外的元数据或者批处理大小等，但这些信息不是必须的。
以下是一个简单的例子，展示如何在 PyTorch 中保存和加载<span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.pth</span></span></code></span>文件：</li>
</ul>
</li>
</ol>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="python" data-theme="plastic"><code data-language="python" data-theme="plastic" style="display:grid"><span data-line=""><span style="color:#5F6672;font-style:italic"># 保存模型和优化器状态</span></span>
<span data-line=""><span style="color:#A9B2C3">torch.save({</span></span>
<span data-line=""><span style="color:#A9B2C3">    &#x27;</span><span style="color:#98C379">epoch</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#A9B2C3">: epoch,</span></span>
<span data-line=""><span style="color:#A9B2C3">    &#x27;</span><span style="color:#98C379">model_state_dict</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#A9B2C3">: model.state_dict(),</span></span>
<span data-line=""><span style="color:#A9B2C3">    &#x27;</span><span style="color:#98C379">optimizer_state_dict</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#A9B2C3">: optimizer.state_dict(),</span></span>
<span data-line=""><span style="color:#A9B2C3">    &#x27;</span><span style="color:#98C379">loss</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#A9B2C3">: loss,</span></span>
<span data-line=""><span style="color:#56B6C2">    ...</span></span>
<span data-line=""><span style="color:#A9B2C3">}, </span><span style="color:#A9B2C3">&#x27;</span><span style="color:#98C379">model.pth</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#A9B2C3">)</span></span>
<span data-line=""><span style="color:#5F6672;font-style:italic"># 加载模型和优化器状态</span></span>
<span data-line=""><span style="color:#A9B2C3">checkpoint </span><span style="color:#E06C75">=</span><span style="color:#A9B2C3"> torch.load(</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#98C379">model.pth</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#A9B2C3">)</span></span>
<span data-line=""><span style="color:#A9B2C3">model.load_state_dict(checkpoint[</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#98C379">model_state_dict</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#A9B2C3">])</span></span>
<span data-line=""><span style="color:#A9B2C3">optimizer.load_state_dict(checkpoint[</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#98C379">optimizer_state_dict</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#A9B2C3">])</span></span>
<span data-line=""><span style="color:#A9B2C3">epoch </span><span style="color:#E06C75">=</span><span style="color:#A9B2C3"> checkpoint[</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#98C379">epoch</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#A9B2C3">]</span></span>
<span data-line=""><span style="color:#A9B2C3">loss </span><span style="color:#E06C75">=</span><span style="color:#A9B2C3"> checkpoint[</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#98C379">loss</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#A9B2C3">]</span></span>
<span data-line=""><span style="color:#56B6C2">...</span></span></code></pre></figure>
<p>在这个例子中，<span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>model</span></span></code></span>是你要保存的模型对象，<span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>optimizer</span></span></code></span>是训练该模型使用的优化器。通过<span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>torch.save</span></span></code></span>函数，你可以将模型的状态字典和优化器的状态字典保存到文件中。之后，可以使用<span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>torch.load</span></span></code></span>函数来恢复这些状态，以便继续训练或者进行推理。</p>
<h2 id="safetensor-文件中又保存了什么东西"><a href="#safetensor-文件中又保存了什么东西">.safetensor 文件中又保存了什么东西？</a></h2>
<p><span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.safetensor</span></span></code></span> 文件格式是由 Hugging Face 的 Safety Checker 工具引入的，它是为了在模型推理时提供一个额外的安全层。<span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.safetensor</span></span></code></span> 文件中保存的内容主要包括：</p>
<ol>
<li><strong>模型权重</strong>：<!-- -->
<ul>
<li>这是最核心的部分，与 PyTorch 的 <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.pth</span></span></code></span> 文件类似，<span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.safetensor</span></span></code></span> 文件也保存了模型的权重，即神经网络中的参数。</li>
</ul>
</li>
<li><strong>元数据</strong>：<!-- -->
<ul>
<li><span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.safetensor</span></span></code></span> 文件包含了一些元数据，这些数据描述了模型的架构、权重形状、数据类型等信息，这样可以在加载模型时进行验证和适配。</li>
</ul>
</li>
<li><strong>安全性信息</strong>：<!-- -->
<ul>
<li><span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.safetensor</span></span></code></span> 文件可能会包含与模型安全性相关的信息，例如哪些层或参数可能需要特别的安全检查，以及可能的阈值设置等。
具体来说，<span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.safetensor</span></span></code></span> 文件的内容结构可能如下：</li>
</ul>
</li>
</ol>
<ul>
<li><span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>weights</span></span></code></span>: 包含模型权重的字典，通常是以张量的形式存储。</li>
<li><span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>metadata</span></span></code></span>: 包含模型的元数据，如版本号、架构信息等。</li>
<li><span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>config</span></span></code></span>: 包含模型配置信息，如模型类型、类名等。</li>
<li><span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>safety</span></span></code></span>: 包含模型安全性相关的信息。
使用 <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.safetensor</span></span></code></span> 文件的目的之一是为了确保在模型部署时能够进行有效的安全检查，特别是在处理生成型模型（如文本生成、图像生成等）时，可以防止生成不适当的内容。
请注意，<span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.safetensor</span></span></code></span> 文件格式并不是 PyTorch 的标准保存格式，而是 Hugging Face 的特定实现。因此，它可能不如 <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.pth</span></span></code></span> 文件那样被广泛使用。如果你在使用 Hugging Face 的模型和工具，可能会遇到 <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.safetensor</span></span></code></span> 文件。在使用时，需要确保你的环境支持这种格式。</li>
</ul>
<h2 id="onnx-文件中又保存了什么信息"><a href="#onnx-文件中又保存了什么信息">.onnx 文件中又保存了什么信息？</a></h2>
<p><span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.onnx</span></span></code></span>（Open Neural Network Exchange）文件是一个开放格式，用于表示机器学习模型。它旨在提供一种标准的方式来表示深度学习模型，使得模型可以在不同的框架和工具之间进行转换和互操作。一个<span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.onnx</span></span></code></span>文件中通常包含以下信息：</p>
<ol>
<li><strong>模型图（Model Graph）</strong>：<!-- -->
<ul>
<li>模型图定义了模型的计算流程，它由节点（nodes）和边（edges）组成。</li>
<li>节点代表计算操作，如卷积、矩阵乘法、激活函数等。</li>
<li>边代表节点之间的数据流，即张量（tensors）的流动。</li>
</ul>
</li>
<li><strong>初始值（Initializers）</strong>：<!-- -->
<ul>
<li>初始值包含了模型的权重、偏置等参数的值。</li>
<li>这些参数是在模型图执行之前就已经确定的。</li>
</ul>
</li>
<li><strong>模型属性（Attributes）</strong>：<!-- -->
<ul>
<li>每个节点可能有与之关联的属性，这些属性定义了节点的具体行为，例如卷积操作中的步长（stride）和填充（padding）。</li>
</ul>
</li>
<li><strong>输入和输出（Inputs and Outputs）</strong>：<!-- -->
<ul>
<li>定义了模型的输入和输出张量的名称、数据类型和形状。</li>
<li>这有助于理解模型期望的输入格式以及它将产生的输出格式。</li>
</ul>
</li>
<li><strong>元数据（Metadata）</strong>：<!-- -->
<ul>
<li>包括模型的名称、版本、作者、生产日期等信息。</li>
<li>这些信息有助于模型的追踪和管理。</li>
</ul>
</li>
<li><strong>优化信息（Optimization Information）</strong>（可选）：<!-- -->
<ul>
<li>一些<span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.onnx</span></span></code></span>文件可能包含用于优化模型执行的额外信息，如融合操作或特定硬件上的优化指令。
<span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.onnx</span></span></code></span>文件的结构大致如下：</li>
</ul>
</li>
</ol>
<ul>
<li><span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>ir_version</span></span></code></span>: ONNX 格式的版本号。</li>
<li><span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>opset_import</span></span></code></span>: 模型使用的操作集版本。</li>
<li><span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>producer_name</span></span></code></span>: 生成该 ONNX 模型的工具或库的名称。</li>
<li><span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>producer_version</span></span></code></span>: 生成该 ONNX 模型的工具或库的版本。</li>
<li><span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>graph</span></span></code></span>: 包含模型图的结构和属性。<!-- -->
<ul>
<li><span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>node</span></span></code></span>: 计算节点列表。</li>
<li><span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>input</span></span></code></span>: 输入列表。</li>
<li><span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>output</span></span></code></span>: 输出列表。</li>
<li><span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>initializer</span></span></code></span>: 初始化参数列表。</li>
<li><span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>value_info</span></span></code></span>: 提供额外的张量信息。
使用<span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.onnx</span></span></code></span>文件，可以轻松地将模型从 PyTorch、TensorFlow、Caffe2 等框架转换到 ONNX 格式，然后再部署到不同的推理引擎或硬件平台上，例如使用 ONNX Runtime 进行推理。这种格式提高了模型的便携性和互操作性。</li>
</ul>
</li>
</ul>
<h2 id="简述-pth--safetensor--onnx-保存的信息中有哪些是相同的有哪些有区别"><a href="#简述-pth--safetensor--onnx-保存的信息中有哪些是相同的有哪些有区别">简述 .pth ， .safetensor ， .onnx 保存的信息中，有哪些是相同的？有哪些有区别？</a></h2>
<p>.pth, .safetensor, 和 .onnx 文件格式都用于保存机器学习模型的相关信息，但它们的设计目的、兼容性和包含的具体内容有所不同。以下是它们之间相同点和区别的概述：
<strong>相同点：</strong></p>
<ol>
<li><strong>模型参数/权重</strong>：<!-- -->
<ul>
<li>所有三种格式都保存了模型的参数或权重，这些是训练过程中学习到的数值，对于模型的预测能力至关重要。</li>
</ul>
</li>
<li><strong>元数据</strong>：<!-- -->
<ul>
<li>它们都可能包含一些元数据，如模型的版本、创建日期或其他描述性信息，尽管具体的元数据内容和格式可能有所不同。
<strong>区别：</strong></li>
</ul>
</li>
<li><strong>格式和兼容性</strong>：<!-- -->
<ul>
<li><span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.pth</span></span></code></span> 是 PyTorch 的原生格式，专门用于保存和加载 PyTorch 模型的状态字典，包括模型权重和优化器状态。</li>
<li><span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.safetensor</span></span></code></span> 是 Hugging Face 的 Safety Checker 工具使用的格式，除了模型权重，还包含了安全性相关的信息。</li>
<li><span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.onnx</span></span></code></span> 是一个开放的、跨框架的格式，用于在不同的深度学习框架之间交换模型，不仅包含模型结构和参数，还定义了模型计算图。</li>
</ul>
</li>
<li><strong>包含内容</strong>：<!-- -->
<ul>
<li><span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.pth</span></span></code></span> 文件通常包含模型的状态字典和优化器的状态字典，以及可选的其他训练信息（如损失值、迭代次数等）。</li>
<li><span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.safetensor</span></span></code></span> 文件包含模型权重、元数据以及与模型安全性相关的信息。</li>
<li><span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.onnx</span></span></code></span> 文件包含模型计算图、节点定义、边的连接、初始值（模型权重）、输入输出定义以及可选的优化信息。</li>
</ul>
</li>
<li><strong>使用场景</strong>：<!-- -->
<ul>
<li><span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.pth</span></span></code></span> 文件主要用于 PyTorch 模型的训练和推理。</li>
<li><span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.safetensor</span></span></code></span> 文件用于在 Hugging Face 的生态系统中进行模型的安全检查。</li>
<li><span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.onnx</span></span></code></span> 文件用于模型在不同框架之间的转换和部署，特别是在需要跨平台或硬件优化的场景中。</li>
</ul>
</li>
<li><strong>开放性和互操作性</strong>：<!-- -->
<ul>
<li><span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.onnx</span></span></code></span> 格式的设计重点在于开放性和互操作性，使其成为不同框架和工具之间模型交换的桥梁。</li>
<li><span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.pth</span></span></code></span> 和 <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.safetensor</span></span></code></span> 更专注于特定框架或工具链内的使用。
总结来说，这三种格式都用于保存模型权重，但它们在格式兼容性、包含的额外信息和使用场景上存在明显差异。<span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.onnx</span></span></code></span> 格式更加开放和通用，而 <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.pth</span></span></code></span> 和 <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.safetensor</span></span></code></span> 更专注于特定的框架或应用需求。</li>
</ul>
</li>
</ol>
<h2 id="简述-pth--safetensor--onnx-保存的信息中有哪些是相同的保存的信息中又有哪些有区别"><a href="#简述-pth--safetensor--onnx-保存的信息中有哪些是相同的保存的信息中又有哪些有区别">简述 .pth ， .safetensor ， .onnx 保存的信息中有哪些是相同的？保存的信息中又有哪些有区别？</a></h2>
<p>.pth、.safetensor 和.onnx 文件格式虽然都是为了保存机器学习模型的相关信息，但它们在保存的内容上存在相同点和差异。
<strong>相同点：</strong></p>
<ol>
<li><strong>模型参数/权重</strong>：这三种文件格式都会保存模型的参数或权重，这些权重是模型在训练过程中学习到的，对模型的预测能力至关重要。</li>
<li><strong>元数据</strong>：它们都可能包含一些元数据，例如模型的版本、创建日期或其他描述性信息，尽管具体的元数据和格式可能因文件格式而异。
<strong>区别：</strong></li>
<li><strong>格式和兼容性</strong>：<!-- -->
<ul>
<li>.pth 文件是 PyTorch 的原生格式，主要用于保存和加载 PyTorch 模型的状态字典，包括模型权重和优化器状态。</li>
<li>.safetensor 文件是 Hugging Face 的 Safety Checker 工具使用的格式，除了模型权重，还包括安全性相关的信息。</li>
<li>.onnx 文件是一种开放的、跨框架的格式，用于在不同深度学习框架之间交换模型，包含模型结构和参数以及模型计算图。</li>
</ul>
</li>
<li><strong>包含内容</strong>：<!-- -->
<ul>
<li>.pth 文件通常包含模型的状态字典和优化器的状态字典，可能还包括其他训练信息，如损失值、迭代次数等。</li>
<li>.safetensor 文件包含模型权重、元数据以及与模型安全性相关的信息。</li>
<li>.onnx 文件包含模型计算图、节点定义、边的连接、初始值（模型权重）、输入输出定义以及可选的优化信息。</li>
</ul>
</li>
<li><strong>使用场景</strong>：<!-- -->
<ul>
<li>.pth 文件主要用于 PyTorch 模型的训练和推理。</li>
<li>.safetensor 文件用于 Hugging Face 生态系统中的模型安全检查。</li>
<li>.onnx 文件用于模型在不同框架之间的转换和部署，特别是在需要跨平台或硬件优化的场景中。</li>
</ul>
</li>
<li><strong>开放性和互操作性</strong>：<!-- -->
<ul>
<li>.onnx 格式重点在于开放性和互操作性，便于不同框架和工具之间模型交换。</li>
<li>.pth 和.safetensor 文件更专注于特定框架或工具链内的使用。
总结来说，这三种文件格式都保存模型权重，但在格式兼容性、包含的额外信息和使用场景上存在明显差异。.onnx 格式更开放和通用，而.pth 和.safetensor 则更专注于特定框架或应用需求。</li>
</ul>
</li>
</ol>
<h2 id="pth--safetensor--onnx-三种格式各自能否用于模型的-finetunning-为什么"><a href="#pth--safetensor--onnx-三种格式各自能否用于模型的-finetunning-为什么">.pth ， .safetensor ， .onnx 三种格式，各自能否用于模型的 finetunning ？为什么？</a></h2>
<p>.pth、.safetensor 和 .onnx 三种格式在模型微调（finetuning）方面的适用性各有不同，以下是各自的适用性分析：
<strong>.pth 格式：</strong>
.pth 文件可以用于模型的微调。原因如下：</p>
<ul>
<li>.pth 文件是 PyTorch 的原生格式，它保存了模型的状态字典，包括模型的权重和可选的优化器状态。</li>
<li>在微调过程中，可以加载 .pth 文件中的模型权重，然后根据新的数据集对模型进行进一步的训练。</li>
<li>如果 .pth 文件中包含了优化器状态，那么可以从中断点继续训练，这对于微调过程是有帮助的。
<strong>.safetensor 格式：</strong>
.safetensor 文件也可以用于模型的微调，但有一些限制：</li>
<li>.safetensor 文件主要是由 Hugging Face 的 Safety Checker 工具使用的，它保存了模型权重和与安全性相关的信息。</li>
<li>虽然这个格式主要用于安全检查，但它仍然包含了模型权重，因此理论上可以用于微调。</li>
<li>但是，由于 .safetensor 文件格式可能不如 .pth 那样被广泛支持，因此在微调时可能需要额外的步骤来转换格式或加载权重。
<strong>.onnx 格式：</strong>
.onnx 文件在微调方面的适用性较低，原因如下：</li>
<li>.onnx 文件是一个开放的、跨框架的格式，它不仅包含模型权重，还定义了模型计算图。</li>
<li>虽然 .onnx 格式支持在不同的框架之间转换模型，但它不是为了微调而设计的。计算图是固定的，不易于修改。</li>
<li>如果需要微调 .onnx 格式的模型，通常需要先将模型转换回原始框架（如 PyTorch 或 TensorFlow），然后再进行微调。</li>
<li>因此，直接在 .onnx 格式上进行微调通常不切实际，除非有特定的工具或库支持这种操作。
总结来说，.pth 格式最适合用于 PyTorch 模型的微调，因为它直接与 PyTorch 的训练和推理流程兼容。.safetensor 格式也可以用于微调，但可能需要额外的步骤来处理。而 .onnx 格式通常不直接用于微调，需要转换为其他框架格式后才能进行微调。</li>
</ul>
<h2 id="pth--safetensor--onnx-三种格式各自能否用于训练-lora-为什么"><a href="#pth--safetensor--onnx-三种格式各自能否用于训练-lora-为什么">.pth ， .safetensor ， .onnx 三种格式，各自能否用于训练 LoRA ？为什么？</a></h2>
<p>LoRA（Low-Rank Adaptation）是一种用于微调大型预训练模型的技术，它通过引入低秩分解来减少微调所需的参数数量，从而减少存储和计算需求。以下是关于 .pth、.safetensor 和 .onnx 格式在训练 LoRA 时的适用性分析：
<strong>.pth 格式：</strong>
.pth 文件可以用于训练 LoRA。原因如下：</p>
<ul>
<li>.pth 文件是 PyTorch 的原生格式，可以直接保存和加载模型的权重，包括 LoRA 引入的低秩矩阵。</li>
<li>在训练 LoRA 时，通常需要在原始预训练模型的基础上添加额外的参数（即低秩矩阵），这些参数可以在 PyTorch 中通过自定义层或修改现有层来实现。</li>
<li>由于 .pth 文件与 PyTorch 框架紧密集成，因此可以轻松地保存和加载 LoRA 的参数，并进行训练。
<strong>.safetensor 格式：</strong>
.safetensor 文件也可以用于训练 LoRA，但可能有一些限制：</li>
<li>.safetensor 文件是为了提高模型使用的安全性而设计的，它保存了模型权重和其他与安全性相关的信息。</li>
<li>如果 LoRA 的参数被包含在 .safetensor 文件中，那么理论上可以用于训练。</li>
<li>然而，由于 .safetensor 文件格式可能不如 .pth 那样被广泛支持，因此在训练 LoRA 时可能需要额外的步骤来处理文件格式。
<strong>.onnx 格式：</strong>
.onnx 文件在训练 LoRA 方面通常不适用。原因如下：</li>
<li>.onnx 文件定义了模型的计算图和权重，但它是一个静态的模型描述格式，不适合动态修改模型结构，如添加 LoRA 层。</li>
<li>LoRA 需要在预训练模型的特定层中插入低秩矩阵，这通常需要对模型结构进行修改，而 .onnx 格式不支持这种修改。</li>
<li>如果需要使用 .onnx 文件中的模型来训练 LoRA，通常需要先将模型转换回 PyTorch 或其他支持动态图修改的框架，然后再进行训练。
总结来说，.pth 格式最适合用于训练 LoRA，因为它与 PyTorch 框架紧密集成，支持动态图和自定义层的添加。.safetensor 格式在理论上也是可行的，但可能需要额外的处理步骤。而 .onnx 格式由于不支持动态修改模型结构，因此不适合直接用于训练 LoRA。</li>
</ul>
<h2 id="pth--safetensor--onnx-三种格式如何两两转换"><a href="#pth--safetensor--onnx-三种格式如何两两转换">pth ， safetensor ， onnx ，三种格式如何两两转换？</a></h2>
<p>.pth、.safetensor 和 .onnx 文件格式之间的转换通常需要通过特定的工具和库来实现。以下是如何在这三种格式之间进行两两转换的概述：</p>
<h3 id="pth-到-safetensor-的转换"><a href="#pth-到-safetensor-的转换">.pth 到 .safetensor 的转换</a></h3>
<p>目前，并没有直接的标准工具来将 .pth 文件转换为 .safetensor 文件。但是，可以手动加载 .pth 文件中的权重，并将其保存为 .safetensor 格式。以下是一个示例步骤：</p>
<ol>
<li>使用 PyTorch 加载 .pth 文件。</li>
<li>提取模型权重。</li>
<li>使用 Hugging Face 的 <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>transformers</span></span></code></span> 库或其他相关工具将权重保存为 .safetensor 文件。</li>
</ol>
<h3 id="safetensor-到-pth-的转换"><a href="#safetensor-到-pth-的转换">.safetensor 到 .pth 的转换</a></h3>
<p>同样地，将 .safetensor 文件转换为 .pth 文件也没有直接的转换工具。以下是手动转换的步骤：</p>
<ol>
<li>使用 Hugging Face 的 <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>transformers</span></span></code></span> 库或其他相关工具加载 .safetensor 文件。</li>
<li>提取模型权重。</li>
<li>使用 PyTorch 将权重保存为 .pth 文件。</li>
</ol>
<h3 id="pth-到-onnx-的转换"><a href="#pth-到-onnx-的转换">.pth 到 .onnx 的转换</a></h3>
<p>PyTorch 提供了直接将模型转换为 .onnx 格式的工具：</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="python" data-theme="plastic"><code data-language="python" data-theme="plastic" style="display:grid"><span data-line=""><span style="color:#E06C75">import</span><span style="color:#A9B2C3"> torch</span></span>
<span data-line=""><span style="color:#E06C75">import</span><span style="color:#A9B2C3"> torch.onnx</span></span>
<span data-line=""><span style="color:#5F6672;font-style:italic"># 假设 model 是一个 PyTorch 模型</span></span>
<span data-line=""><span style="color:#A9B2C3">model </span><span style="color:#E06C75">=</span><span style="color:#56B6C2"> ...</span><span style="color:#5F6672;font-style:italic">  # 加载或定义模型</span></span>
<span data-line=""><span style="color:#5F6672;font-style:italic"># 假设输入是一个张量，其形状与模型输入兼容</span></span>
<span data-line=""><span style="color:#A9B2C3">input_sample </span><span style="color:#E06C75">=</span><span style="color:#A9B2C3"> torch.randn(batch_size, channels, height, width)</span></span>
<span data-line=""><span style="color:#5F6672;font-style:italic"># 将模型转换为 ONNX 格式</span></span>
<span data-line=""><span style="color:#A9B2C3">torch.onnx.export(model,               </span><span style="color:#5F6672;font-style:italic"># 模型</span></span>
<span data-line=""><span style="color:#A9B2C3">                  input_sample,        </span><span style="color:#5F6672;font-style:italic"># 模型输入（或一个包含输入的元组）</span></span>
<span data-line=""><span style="color:#A9B2C3">                  &quot;</span><span style="color:#98C379">model.onnx</span><span style="color:#A9B2C3">&quot;</span><span style="color:#A9B2C3">,       </span><span style="color:#5F6672;font-style:italic"># 输出文件名</span></span>
<span data-line=""><span style="color:#C6CCD7">                  export_params</span><span style="color:#E06C75">=</span><span style="color:#56B6C2">True</span><span style="color:#A9B2C3">,  </span><span style="color:#5F6672;font-style:italic"># 是否导出参数</span></span>
<span data-line=""><span style="color:#C6CCD7">                  opset_version</span><span style="color:#E06C75">=</span><span style="color:#56B6C2">10</span><span style="color:#A9B2C3">,    </span><span style="color:#5F6672;font-style:italic"># ONNX 算子集版本</span></span>
<span data-line=""><span style="color:#C6CCD7">                  do_constant_folding</span><span style="color:#E06C75">=</span><span style="color:#56B6C2">True</span><span style="color:#A9B2C3">,  </span><span style="color:#5F6672;font-style:italic"># 是否执行常量折叠优化</span></span>
<span data-line=""><span style="color:#C6CCD7">                  input_names</span><span style="color:#E06C75">=</span><span style="color:#A9B2C3">[</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#98C379">input</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#A9B2C3">],   </span><span style="color:#5F6672;font-style:italic"># 输入名</span></span>
<span data-line=""><span style="color:#C6CCD7">                  output_names</span><span style="color:#E06C75">=</span><span style="color:#A9B2C3">[</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#98C379">output</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#A9B2C3">], </span><span style="color:#5F6672;font-style:italic"># 输出名</span></span>
<span data-line=""><span style="color:#C6CCD7">                  dynamic_axes</span><span style="color:#E06C75">=</span><span style="color:#A9B2C3">{</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#98C379">input</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#A9B2C3">: {</span><span style="color:#56B6C2">0</span><span style="color:#A9B2C3">: </span><span style="color:#A9B2C3">&#x27;</span><span style="color:#98C379">batch_size</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#A9B2C3">},  </span><span style="color:#5F6672;font-style:italic"># 动态轴</span></span>
<span data-line=""><span style="color:#A9B2C3">                                &#x27;</span><span style="color:#98C379">output</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#A9B2C3">: {</span><span style="color:#56B6C2">0</span><span style="color:#A9B2C3">: </span><span style="color:#A9B2C3">&#x27;</span><span style="color:#98C379">batch_size</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#A9B2C3">}})</span></span></code></pre></figure>
<h3 id="onnx-到-pth-的转换"><a href="#onnx-到-pth-的转换">.onnx 到 .pth 的转换</a></h3>
<p>将 .onnx 文件转换为 .pth 文件通常不直接进行，因为 .onnx 文件包含了模型的结构信息，而 .pth 文件只包含权重。如果需要，可以重新创建 PyTorch 模型结构，然后加载 .onnx 文件中的权重：</p>
<ol>
<li>定义与 .onnx 文件对应的 PyTorch 模型结构。</li>
<li>使用 <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>onnx.load</span></span></code></span> 加载 .onnx 文件。</li>
<li>提取权重并将其加载到 PyTorch 模型中。</li>
</ol>
<h3 id="safetensor-到-onnx-的转换"><a href="#safetensor-到-onnx-的转换">.safetensor 到 .onnx 的转换</a></h3>
<p>目前没有直接的方法将 .safetensor 文件转换为 .onnx 文件。如果需要，可以先将 .safetensor 文件转换为 .pth 文件，然后再按照上述方法将 .pth 文件转换为 .onnx 文件。</p>
<h3 id="onnx-到-safetensor-的转换"><a href="#onnx-到-safetensor-的转换">.onnx 到 .safetensor 的转换</a></h3>
<p>同样地，将 .onnx 文件转换为 .safetensor 文件也没有直接的转换工具。如果需要，可以先将 .onnx 文件转换为 .pth 文件，然后再将 .pth 文件转换为 .safetensor 文件。
在进行这些转换时，需要注意的是，转换过程中可能会丢失一些特定的信息，如优化器状态或模型配置，因此在转换后可能需要额外的步骤来确保模型的完整性和正确性。</p>
<h2 id="我有一个从网络上下载的-pth-文件-001pth-给我-python-代码将其转换为-onnx-格式"><a href="#我有一个从网络上下载的-pth-文件-001pth-给我-python-代码将其转换为-onnx-格式">我有一个从网络上下载的 .pth 文件 <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>001.pth</span></span></code></span> 。给我 Python 代码，将其转换为 onnx 格式。</a></h2>
<p>要将一个 <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.pth</span></span></code></span> 文件转换为 <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.onnx</span></span></code></span> 格式，你需要首先加载 <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.pth</span></span></code></span> 文件中的模型，然后使用 PyTorch 的 <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>torch.onnx.export</span></span></code></span> 函数来进行转换。以下是一个 Python 代码示例，展示了如何进行这一转换过程。假设你已经有了对应的 PyTorch 模型定义，并且 <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.pth</span></span></code></span> 文件中包含的是该模型的权重。
请注意，以下代码假设你的模型是一个标准的 PyTorch 模型，并且你知道模型的输入尺 ��。你需要根据你的模型实际情况来调整输入尺寸和模型结构。</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="python" data-theme="plastic"><code data-language="python" data-theme="plastic" style="display:grid"><span data-line=""><span style="color:#E06C75">import</span><span style="color:#A9B2C3"> torch</span></span>
<span data-line=""><span style="color:#E06C75">import</span><span style="color:#A9B2C3"> torch.onnx</span></span>
<span data-line=""><span style="color:#5F6672;font-style:italic"># 假设模型结构和输入尺寸已知</span></span>
<span data-line=""><span style="color:#5F6672;font-style:italic"># 这里是示例模型结构和输入尺寸，你需要根据你的模型进行修改</span></span>
<span data-line=""><span style="color:#61AFEF">class</span><span style="color:#E5C07B"> MyModel</span><span style="color:#A9B2C3">(</span><span style="color:#D19A66">torch</span><span style="color:#A9B2C3">.</span><span style="color:#D19A66">nn</span><span style="color:#A9B2C3">.</span><span style="color:#D19A66">Module</span><span style="color:#A9B2C3">):</span></span>
<span data-line=""><span style="color:#61AFEF">    def</span><span style="color:#B57EDC"> __init__</span><span style="color:#A9B2C3">(</span><span style="color:#C6CCD7">self</span><span style="color:#A9B2C3">):</span></span>
<span data-line=""><span style="color:#E5C07B">        super</span><span style="color:#A9B2C3">(MyModel, </span><span style="color:#E06C75">self</span><span style="color:#A9B2C3">).</span><span style="color:#B57EDC">__init__</span><span style="color:#A9B2C3">()</span></span>
<span data-line=""><span style="color:#5F6672;font-style:italic">        # 定义模型结构</span></span>
<span data-line=""><span style="color:#E06C75">        self</span><span style="color:#A9B2C3">.conv1 </span><span style="color:#E06C75">=</span><span style="color:#A9B2C3"> torch.nn.Conv2d(</span><span style="color:#56B6C2">3</span><span style="color:#A9B2C3">, </span><span style="color:#56B6C2">16</span><span style="color:#A9B2C3">, </span><span style="color:#C6CCD7">kernel_size</span><span style="color:#E06C75">=</span><span style="color:#56B6C2">3</span><span style="color:#A9B2C3">, </span><span style="color:#C6CCD7">stride</span><span style="color:#E06C75">=</span><span style="color:#56B6C2">1</span><span style="color:#A9B2C3">, </span><span style="color:#C6CCD7">padding</span><span style="color:#E06C75">=</span><span style="color:#56B6C2">1</span><span style="color:#A9B2C3">)</span></span>
<span data-line=""><span style="color:#E06C75">        self</span><span style="color:#A9B2C3">.relu </span><span style="color:#E06C75">=</span><span style="color:#A9B2C3"> torch.nn.ReLU()</span></span>
<span data-line=""><span style="color:#E06C75">        self</span><span style="color:#A9B2C3">.pool </span><span style="color:#E06C75">=</span><span style="color:#A9B2C3"> torch.nn.MaxPool2d(</span><span style="color:#C6CCD7">kernel_size</span><span style="color:#E06C75">=</span><span style="color:#56B6C2">2</span><span style="color:#A9B2C3">, </span><span style="color:#C6CCD7">stride</span><span style="color:#E06C75">=</span><span style="color:#56B6C2">2</span><span style="color:#A9B2C3">, </span><span style="color:#C6CCD7">padding</span><span style="color:#E06C75">=</span><span style="color:#56B6C2">0</span><span style="color:#A9B2C3">)</span></span>
<span data-line=""><span style="color:#5F6672;font-style:italic">        # ... 添加更多层 ...</span></span>
<span data-line=""><span style="color:#61AFEF">    def</span><span style="color:#B57EDC"> forward</span><span style="color:#A9B2C3">(</span><span style="color:#C6CCD7">self</span><span style="color:#A9B2C3">, </span><span style="color:#C6CCD7">x</span><span style="color:#A9B2C3">):</span></span>
<span data-line=""><span style="color:#5F6672;font-style:italic">        # 定义前向传播</span></span>
<span data-line=""><span style="color:#A9B2C3">        x </span><span style="color:#E06C75">=</span><span style="color:#E06C75"> self</span><span style="color:#A9B2C3">.conv1(x)</span></span>
<span data-line=""><span style="color:#A9B2C3">        x </span><span style="color:#E06C75">=</span><span style="color:#E06C75"> self</span><span style="color:#A9B2C3">.relu(x)</span></span>
<span data-line=""><span style="color:#A9B2C3">        x </span><span style="color:#E06C75">=</span><span style="color:#E06C75"> self</span><span style="color:#A9B2C3">.pool(x)</span></span>
<span data-line=""><span style="color:#5F6672;font-style:italic">        # ... 应用更多层 ...</span></span>
<span data-line=""><span style="color:#E06C75">        return</span><span style="color:#A9B2C3"> x</span></span>
<span data-line=""><span style="color:#5F6672;font-style:italic"># 创建模型实例</span></span>
<span data-line=""><span style="color:#A9B2C3">model </span><span style="color:#E06C75">=</span><span style="color:#A9B2C3"> MyModel()</span></span>
<span data-line=""><span style="color:#5F6672;font-style:italic"># 加载.pth文件中的权重</span></span>
<span data-line=""><span style="color:#A9B2C3">model.load_state_dict(torch.load(</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#98C379">001.pth</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#A9B2C3">))</span></span>
<span data-line=""><span style="color:#5F6672;font-style:italic"># 设置模型为评估模式（如果适用）</span></span>
<span data-line=""><span style="color:#A9B2C3">model.eval()</span></span>
<span data-line=""><span style="color:#5F6672;font-style:italic"># 创建一个符合模型输入尺寸的示例输入</span></span>
<span data-line=""><span style="color:#5F6672;font-style:italic"># 假设输入是单张图片，通道数为3，高和宽分别为224和224</span></span>
<span data-line=""><span style="color:#5F6672;font-style:italic"># 你需要根据你的模型调整输入尺寸</span></span>
<span data-line=""><span style="color:#A9B2C3">input_sample </span><span style="color:#E06C75">=</span><span style="color:#A9B2C3"> torch.randn(</span><span style="color:#56B6C2">1</span><span style="color:#A9B2C3">, </span><span style="color:#56B6C2">3</span><span style="color:#A9B2C3">, </span><span style="color:#56B6C2">224</span><span style="color:#A9B2C3">, </span><span style="color:#56B6C2">224</span><span style="color:#A9B2C3">)</span></span>
<span data-line=""><span style="color:#5F6672;font-style:italic"># 指定ONNX模型的输出文件名</span></span>
<span data-line=""><span style="color:#A9B2C3">output_file </span><span style="color:#E06C75">=</span><span style="color:#A9B2C3"> &#x27;</span><span style="color:#98C379">model.onnx</span><span style="color:#A9B2C3">&#x27;</span></span>
<span data-line=""><span style="color:#5F6672;font-style:italic"># 导出模型为ONNX格式</span></span>
<span data-line=""><span style="color:#A9B2C3">torch.onnx.export(model,               </span><span style="color:#5F6672;font-style:italic"># 模型</span></span>
<span data-line=""><span style="color:#A9B2C3">                  input_sample,        </span><span style="color:#5F6672;font-style:italic"># 模型输入（或一个包含输入的元组）</span></span>
<span data-line=""><span style="color:#A9B2C3">                  output_file,         </span><span style="color:#5F6672;font-style:italic"># 输出文件名</span></span>
<span data-line=""><span style="color:#C6CCD7">                  export_params</span><span style="color:#E06C75">=</span><span style="color:#56B6C2">True</span><span style="color:#A9B2C3">,  </span><span style="color:#5F6672;font-style:italic"># 是否导出参数</span></span>
<span data-line=""><span style="color:#C6CCD7">                  opset_version</span><span style="color:#E06C75">=</span><span style="color:#56B6C2">10</span><span style="color:#A9B2C3">,    </span><span style="color:#5F6672;font-style:italic"># ONNX 算子集版本</span></span>
<span data-line=""><span style="color:#C6CCD7">                  do_constant_folding</span><span style="color:#E06C75">=</span><span style="color:#56B6C2">True</span><span style="color:#A9B2C3">,  </span><span style="color:#5F6672;font-style:italic"># 是否执行常量折叠优化</span></span>
<span data-line=""><span style="color:#C6CCD7">                  input_names</span><span style="color:#E06C75">=</span><span style="color:#A9B2C3">[</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#98C379">input</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#A9B2C3">],   </span><span style="color:#5F6672;font-style:italic"># 输入名</span></span>
<span data-line=""><span style="color:#C6CCD7">                  output_names</span><span style="color:#E06C75">=</span><span style="color:#A9B2C3">[</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#98C379">output</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#A9B2C3">], </span><span style="color:#5F6672;font-style:italic"># 输出名</span></span>
<span data-line=""><span style="color:#C6CCD7">                  dynamic_axes</span><span style="color:#E06C75">=</span><span style="color:#A9B2C3">{</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#98C379">input</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#A9B2C3">: {</span><span style="color:#56B6C2">0</span><span style="color:#A9B2C3">: </span><span style="color:#A9B2C3">&#x27;</span><span style="color:#98C379">batch_size</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#A9B2C3">},  </span><span style="color:#5F6672;font-style:italic"># 动态轴</span></span>
<span data-line=""><span style="color:#A9B2C3">                                &#x27;</span><span style="color:#98C379">output</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#A9B2C3">: {</span><span style="color:#56B6C2">0</span><span style="color:#A9B2C3">: </span><span style="color:#A9B2C3">&#x27;</span><span style="color:#98C379">batch_size</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#A9B2C3">}})</span></span></code></pre></figure>
<p>在运行这段代码之前，请确保：</p>
<ul>
<li>你的环境中已经安装了 PyTorch 和 onnx。</li>
<li>你已经根据你的模型结构正确地定义了 <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>MyModel</span></span></code></span> 类。</li>
<li>你已经根据你的模型输入尺寸正确地设置了 <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>input_sample</span></span></code></span>。
运行上述代码后，你应该会在当前目录下得到一个名为 <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>model.onnx</span></span></code></span> 的文件，这就是转换后的 ONNX 格式的模型。</li>
</ul>
<h2 id="我没有对应的-pytorch-模型定义我要如何获得"><a href="#我没有对应的-pytorch-模型定义我要如何获得">我没有对应的 PyTorch 模型定义。我要如何获得？</a></h2>
<p>如果你没有模型的 PyTorch 定义，但你有一个 <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.pth</span></span></code></span> 文件，你可以尝试以下几种方法来获取或重建模型的结构：</p>
<h3 id="1-使用-pytorch-的-torchjitload"><a href="#1-使用-pytorch-的-torchjitload">1. 使用 PyTorch 的 <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>torch.jit.load</span></span></code></span></a></h3>
<p>如果你的 <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.pth</span></span></code></span> 文件是一个 JIT traced 的模型，你可以使用 <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>torch.jit.load</span></span></code></span> 来加载它，这样就不需要原始的模型定义。</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="python" data-theme="plastic"><code data-language="python" data-theme="plastic" style="display:grid"><span data-line=""><span style="color:#E06C75">import</span><span style="color:#A9B2C3"> torch</span></span>
<span data-line=""><span style="color:#5F6672;font-style:italic"># 加载JIT traced模型</span></span>
<span data-line=""><span style="color:#A9B2C3">traced_model </span><span style="color:#E06C75">=</span><span style="color:#A9B2C3"> torch.jit.load(</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#98C379">001.pth</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#A9B2C3">)</span></span>
<span data-line=""><span style="color:#5F6672;font-style:italic"># 使用模型（例如进行推理）</span></span>
<span data-line=""><span style="color:#5F6672;font-style:italic"># input_sample = ...  # 创建一个符合模型输入尺寸的示例输入</span></span>
<span data-line=""><span style="color:#5F6672;font-style:italic"># output = traced_model(input_sample)</span></span></code></pre></figure>
<h3 id="2-查找模型的文档或代码"><a href="#2-查找模型的文档或代码">2. 查找模型的文档或代码</a></h3>
<p>如果模型是从某个知名的代码库或论文中获得的，你可以尝试查找原始的模型定义代码。通常，论文的附录或代码库的 README 文件会包含模型的定义。</p>
<h3 id="3-使用第三方库"><a href="#3-使用第三方库">3. 使用第三方库</a></h3>
<p>有些第三方库可能提供了预定义的模型结构，你可以尝试使用这些库来加载模型。
例如，如果你有一个在 torchvision 中定义的模型，你可以这样做：</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="python" data-theme="plastic"><code data-language="python" data-theme="plastic" style="display:grid"><span data-line=""><span style="color:#E06C75">import</span><span style="color:#A9B2C3"> torch</span></span>
<span data-line=""><span style="color:#E06C75">import</span><span style="color:#A9B2C3"> torchvision.models </span><span style="color:#E06C75">as</span><span style="color:#A9B2C3"> models</span></span>
<span data-line=""><span style="color:#5F6672;font-style:italic"># 假设你知道模型是 torchvision 中的某个模型</span></span>
<span data-line=""><span style="color:#A9B2C3">model </span><span style="color:#E06C75">=</span><span style="color:#A9B2C3"> models.resnet50(</span><span style="color:#C6CCD7">pretrained</span><span style="color:#E06C75">=</span><span style="color:#56B6C2">False</span><span style="color:#A9B2C3">)</span></span>
<span data-line=""><span style="color:#5F6672;font-style:italic"># 加载权重</span></span>
<span data-line=""><span style="color:#A9B2C3">model.load_state_dict(torch.load(</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#98C379">001.pth</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#A9B2C3">))</span></span></code></pre></figure>
<h3 id="4-反序列化状态字典"><a href="#4-反序列化状态字典">4. 反序列化状态字典</a></h3>
<p>如果你只是丢失了模型定义，但你有状态字典，你可以尝试反序列化状态字典来重建模型结构。</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="python" data-theme="plastic"><code data-language="python" data-theme="plastic" style="display:grid"><span data-line=""><span style="color:#E06C75">import</span><span style="color:#A9B2C3"> torch</span></span>
<span data-line=""><span style="color:#5F6672;font-style:italic"># 加载状态字典</span></span>
<span data-line=""><span style="color:#A9B2C3">state_dict </span><span style="color:#E06C75">=</span><span style="color:#A9B2C3"> torch.load(</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#98C379">001.pth</span><span style="color:#A9B2C3">&#x27;</span><span style="color:#A9B2C3">)</span></span>
<span data-line=""><span style="color:#5F6672;font-style:italic"># 假设你知道模型结构，可以创建一个空的模型实例，然后加载状态字典</span></span>
<span data-line=""><span style="color:#5F6672;font-style:italic"># model = ...  # 创建模型实例</span></span>
<span data-line=""><span style="color:#5F6672;font-style:italic"># model.load_state_dict(state_dict)</span></span></code></pre></figure>
<h3 id="5-使用模型架构搜索工具"><a href="#5-使用模型架构搜索工具">5. 使用模型架构搜索工具</a></h3>
<p>有一些工具和库可以帮助你根据权重文件推断出模型结构。例如，<span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>netron</span></span></code></span> 是一个可视化神经网络工具，可以显示 <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.pth</span></span></code></span> 文件中的模型结构。</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="bash" data-theme="plastic"><code data-language="bash" data-theme="plastic" style="display:grid"><span data-line=""><span style="color:#5F6672;font-style:italic"># 安装 netron</span></span>
<span data-line=""><span style="color:#B57EDC">pip</span><span style="color:#98C379"> install</span><span style="color:#98C379"> netron</span></span>
<span data-line=""><span style="color:#5F6672;font-style:italic"># 使用 netron 可视化模型</span></span>
<span data-line=""><span style="color:#B57EDC">netron</span><span style="color:#98C379"> start</span><span style="color:#98C379"> 001.pth</span></span></code></pre></figure>
<p>通过这些方法，你应该能够找到或重建模型的结构。一旦你有了模型定义，你可以使用前面提供的代码示例来将 <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.pth</span></span></code></span> 文件转换为 <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="plastic"><span data-line=""><span>.onnx</span></span></code></span> 格式。如果你无法确定模型结构，你可能需要联系模型的原始作者或查找相关的文档来获取模型定义。</p></div><div class="w-96 text-gray-700 leading-none"><span class="!text-sm"><a class="!inline-block !p-0 !m-0 align-text-bottom" rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/"><img alt="Creative Commons License" loading="lazy" width="88" height="31" decoding="async" data-nimg="1" class="!m-0 h-4 w-auto pr-1" style="color:transparent;border-width:0" src="https://i.creativecommons.org/l/by-nc/4.0/88x31.png"/></a>This work is licensed under a<!-- --> <a class="underline" rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/">Creative Commons Attribution-NonCommercial 4.0 International License</a>.</span></div><div class="TagsBox_tagsBox__WzhAf mt-4"><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/pytorch">#<!-- -->PyTorch</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/onnx">#<!-- -->ONNX</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0">#<!-- -->深度学习</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2">#<!-- -->模型部署</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0">#<!-- -->学习笔记</a></div><div class="mt-4 mb-4 flex justify-center"><div class="ml-0 mr-auto"><a href="/blog-next/learn_from_ai/opencv-coordinate-system-conventions">&lt;- OpenCV 坐标表示：理解 (y, x) 与 (x, y) 的区别</a></div></div><hr class="mt-4"/></article></div></div><style data-emotion="css vkdybf">.css-vkdybf{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 0 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 0) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));min-width:0;box-sizing:border-box;}@media (min-width:900px){.css-vkdybf{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 3 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 3) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}@media (min-width:1200px){.css-vkdybf{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 2 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 2) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}</style><div class="MuiGrid2-root MuiGrid2-direction-xs-row MuiGrid2-grid-xs-0 MuiGrid2-grid-md-3 MuiGrid2-grid-lg-2 css-vkdybf"><div class="inset-0 w-full h-full flex items-center justify-center bg-transparent"><style data-emotion="css 14awfyb animation-61bdi0">.css-14awfyb{display:inline-block;-webkit-animation:animation-61bdi0 1.4s linear infinite;animation:animation-61bdi0 1.4s linear infinite;color:#1976d2;}@-webkit-keyframes animation-61bdi0{0%{-webkit-transform:rotate(0deg);-moz-transform:rotate(0deg);-ms-transform:rotate(0deg);transform:rotate(0deg);}100%{-webkit-transform:rotate(360deg);-moz-transform:rotate(360deg);-ms-transform:rotate(360deg);transform:rotate(360deg);}}@keyframes animation-61bdi0{0%{-webkit-transform:rotate(0deg);-moz-transform:rotate(0deg);-ms-transform:rotate(0deg);transform:rotate(0deg);}100%{-webkit-transform:rotate(360deg);-moz-transform:rotate(360deg);-ms-transform:rotate(360deg);transform:rotate(360deg);}}</style><span class="MuiCircularProgress-root MuiCircularProgress-indeterminate MuiCircularProgress-colorPrimary css-14awfyb" style="width:40px;height:40px" role="progressbar"><style data-emotion="css 4ejps8">.css-4ejps8{display:block;}</style><svg class="MuiCircularProgress-svg css-4ejps8" viewBox="22 22 44 44"><style data-emotion="css 13odlrs animation-1o38n3e">.css-13odlrs{stroke:currentColor;stroke-dasharray:80px,200px;stroke-dashoffset:0;-webkit-animation:animation-1o38n3e 1.4s ease-in-out infinite;animation:animation-1o38n3e 1.4s ease-in-out infinite;}@-webkit-keyframes animation-1o38n3e{0%{stroke-dasharray:1px,200px;stroke-dashoffset:0;}50%{stroke-dasharray:100px,200px;stroke-dashoffset:-15px;}100%{stroke-dasharray:1px,200px;stroke-dashoffset:-126px;}}@keyframes animation-1o38n3e{0%{stroke-dasharray:1px,200px;stroke-dashoffset:0;}50%{stroke-dasharray:100px,200px;stroke-dashoffset:-15px;}100%{stroke-dasharray:1px,200px;stroke-dashoffset:-126px;}}</style><circle class="MuiCircularProgress-circle MuiCircularProgress-circleIndeterminate css-13odlrs" cx="44" cy="44" r="20.2" fill="none" stroke-width="3.6"></circle></svg></span></div></div></div><footer class="DefaultLayout_footer__aWV4u"><style data-emotion="css vktxal">.css-vktxal{--Grid-columns:12;--Grid-columnSpacing:0px;--Grid-rowSpacing:0px;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;min-width:0;box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;gap:var(--Grid-rowSpacing) var(--Grid-columnSpacing);width:100%;max-width:80rem;margin-left:auto;margin-right:auto;padding:0.5rem;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;}.css-vktxal >*{--Grid-parent-columns:12;}.css-vktxal >*{--Grid-parent-columnSpacing:0px;}.css-vktxal >*{--Grid-parent-rowSpacing:0px;}</style><div class="MuiGrid2-root MuiGrid2-container MuiGrid2-direction-xs-row css-vktxal"><style data-emotion="css 9gdssj">.css-9gdssj{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 0 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 0) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));min-width:0;box-sizing:border-box;}@media (min-width:900px){.css-9gdssj{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 0 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 0) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}@media (min-width:1200px){.css-9gdssj{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 2 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 2) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}</style><div class="MuiGrid2-root MuiGrid2-direction-xs-row MuiGrid2-grid-xs-0 MuiGrid2-grid-md-0 MuiGrid2-grid-lg-2 css-9gdssj"></div><style data-emotion="css 9h67uz">.css-9h67uz{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 12 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 12) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));min-width:0;box-sizing:border-box;}@media (min-width:900px){.css-9h67uz{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 9 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 9) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}@media (min-width:1200px){.css-9h67uz{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 8 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 8) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}</style><div class="MuiGrid2-root MuiGrid2-direction-xs-row MuiGrid2-grid-xs-12 MuiGrid2-grid-md-9 MuiGrid2-grid-lg-8 css-9h67uz"><div class="flex flex-row justify-center items-center"><div class="DefaultLayout_footerLeft__Qn_VV">© 2023 Ryo Jerry Yu. All rights reserved.</div><div class="DefaultLayout_footerRight__GlReP"><a title="Twitter" href="https://twitter.com/ryo_okami"><svg class="h-6 w-6 fill-gray-300 hover:fill-white transition-all ease-in-out mx-1 md:mx-2" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a><a title="GitHub" href="https://github.com/RyoJerryYu"><svg class="h-6 w-6 fill-gray-300 hover:fill-white transition-all ease-in-out mx-1 md:mx-2" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a><a title="Pixiv" href="https://www.pixiv.net/users/9159893"><svg class="h-6 w-6 fill-gray-300 hover:fill-white transition-all ease-in-out mx-1 md:mx-2" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4.935 0A4.924 4.924 0 0 0 0 4.935v14.13A4.924 4.924 0 0 0 4.935 24h14.13A4.924 4.924 0 0 0 24 19.065V4.935A4.924 4.924 0 0 0 19.065 0zm7.81 4.547c2.181 0 4.058.676 5.399 1.847a6.118 6.118 0 0 1 2.116 4.66c.005 1.854-.88 3.476-2.257 4.563-1.375 1.092-3.225 1.697-5.258 1.697-2.314 0-4.46-.842-4.46-.842v2.718c.397.116 1.048.365.635.779H5.79c-.41-.41.19-.65.644-.779V7.666c-1.053.81-1.593 1.51-1.868 2.031.32 1.02-.284.969-.284.969l-1.09-1.73s3.868-4.39 9.553-4.39zm-.19.971c-1.423-.003-3.184.473-4.27 1.244v8.646c.988.487 2.484.832 4.26.832h.01c1.596 0 2.98-.593 3.93-1.533.952-.948 1.486-2.183 1.492-3.683-.005-1.54-.504-2.864-1.42-3.86-.918-.992-2.274-1.645-4.002-1.646Z"></path></svg></a></div></div></div><style data-emotion="css vkdybf">.css-vkdybf{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 0 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 0) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));min-width:0;box-sizing:border-box;}@media (min-width:900px){.css-vkdybf{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 3 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 3) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}@media (min-width:1200px){.css-vkdybf{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 2 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 2) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}</style><div class="MuiGrid2-root MuiGrid2-direction-xs-row MuiGrid2-grid-xs-0 MuiGrid2-grid-md-3 MuiGrid2-grid-lg-2 css-vkdybf"></div></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"slug":"deep-learning-model-formats","tags":[{"tag":"PyTorch","slug":"pytorch","path":"/tags/pytorch","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/deep-learning-model-formats"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/pytorch-backpropagation-mechanism"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/pytorch-model-save-and-load"}]},{"tag":"ONNX","slug":"onnx","path":"/tags/onnx","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/deep-learning-model-formats"}]},{"tag":"深度学习","slug":"深度学习","path":"/tags/深度学习","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/deep-learning-model-formats"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/lora-matrix-initialization-strategy"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/pytorch-backpropagation-mechanism"}]},{"tag":"模型部署","slug":"模型部署","path":"/tags/模型部署","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/deep-learning-model-formats"}]},{"tag":"学习笔记","slug":"学习笔记","path":"/tags/学习笔记","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/deep-learning-model-formats"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/opencv-coordinate-system-conventions"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/executable-file-formats"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/lora-matrix-initialization-strategy"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/pytorch-backpropagation-mechanism"}]}],"source":{"compiledSource":"\"use strict\";\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = {\n    a: \"a\",\n    blockquote: \"blockquote\",\n    code: \"code\",\n    figure: \"figure\",\n    h2: \"h2\",\n    h3: \"h3\",\n    li: \"li\",\n    ol: \"ol\",\n    p: \"p\",\n    pre: \"pre\",\n    span: \"span\",\n    strong: \"strong\",\n    ul: \"ul\",\n    ..._provideComponents(),\n    ...props.components\n  };\n  return _jsxs(_Fragment, {\n    children: [_jsxs(_components.blockquote, {\n      children: [\"\\n\", _jsx(_components.p, {\n        children: \"本页面介绍了三种机器学习模型文件格式：.pth、.safetensor 和 .onnx。主要内容包括每种格式的定义、保存的内容、用途以及它们之间的区别和转换方法。\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      id: \"pytorch-保存的-pth-文件里都保存了些什么东西\",\n      children: _jsx(_components.a, {\n        href: \"#pytorch-保存的-pth-文件里都保存了些什么东西\",\n        children: \"pytorch 保存的 .pth 文件里都保存了些什么东西？\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"PyTorch 中的\", _jsx(_components.span, {\n        \"data-rehype-pretty-code-figure\": \"\",\n        children: _jsx(_components.code, {\n          \"data-language\": \"plaintext\",\n          \"data-theme\": \"plastic\",\n          children: _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              children: \".pth\"\n            })\n          })\n        })\n      }), \"文件通常用于保存模型的权重（parameters）和训练过程中的优化器状态（optimizer state）。具体来说，一个\", _jsx(_components.span, {\n        \"data-rehype-pretty-code-figure\": \"\",\n        children: _jsx(_components.code, {\n          \"data-language\": \"plaintext\",\n          \"data-theme\": \"plastic\",\n          children: _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              children: \".pth\"\n            })\n          })\n        })\n      }), \"文件可能包含以下内容：\"]\n    }), \"\\n\", _jsxs(_components.ol, {\n      children: [\"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.strong, {\n          children: \"模型状态字典（Model state dictionary）\"\n        }), \"：\", \"\\n\", _jsxs(_components.ul, {\n          children: [\"\\n\", _jsxs(_components.li, {\n            children: [\"这是\", _jsx(_components.span, {\n              \"data-rehype-pretty-code-figure\": \"\",\n              children: _jsx(_components.code, {\n                \"data-language\": \"plaintext\",\n                \"data-theme\": \"plastic\",\n                children: _jsx(_components.span, {\n                  \"data-line\": \"\",\n                  children: _jsx(_components.span, {\n                    children: \".pth\"\n                  })\n                })\n              })\n            }), \"文件中最主要的部分，它包含了模型的所有权重（即神经网络的参数），包括卷积层的滤波器、全连接层的权重和偏置等。\"]\n          }), \"\\n\", _jsx(_components.li, {\n            children: \"状态字典是一个简单的 Python 字典对象，其键是层的名字，值是相应的参数张量。\"\n          }), \"\\n\"]\n        }), \"\\n\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.strong, {\n          children: \"优化器状态字典（Optimizer state dictionary）\"\n        }), \"：\", \"\\n\", _jsxs(_components.ul, {\n          children: [\"\\n\", _jsx(_components.li, {\n            children: \"当保存模型时，通常也会保存优化器的状态，这样可以在模型训练中断后，从上次停止的地方继续训练。\"\n          }), \"\\n\", _jsx(_components.li, {\n            children: \"优化器状态字典通常包含每个参数的梯度、动量（momentum）和其他与优化器相关的状态信息（例如 Adam 优化器的矩估计）。\"\n          }), \"\\n\"]\n        }), \"\\n\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.strong, {\n          children: \"其他可选信息\"\n        }), \"：\", \"\\n\", _jsxs(_components.ul, {\n          children: [\"\\n\", _jsxs(_components.li, {\n            children: [\"有时候，\", _jsx(_components.span, {\n              \"data-rehype-pretty-code-figure\": \"\",\n              children: _jsx(_components.code, {\n                \"data-language\": \"plaintext\",\n                \"data-theme\": \"plastic\",\n                children: _jsx(_components.span, {\n                  \"data-line\": \"\",\n                  children: _jsx(_components.span, {\n                    children: \".pth\"\n                  })\n                })\n              })\n            }), \"文件可能还会包含其他辅助信息，比如训练的损失值、额外的元数据或者批处理大小等，但这些信息不是必须的。\\n以下是一个简单的例子，展示如何在 PyTorch 中保存和加载\", _jsx(_components.span, {\n              \"data-rehype-pretty-code-figure\": \"\",\n              children: _jsx(_components.code, {\n                \"data-language\": \"plaintext\",\n                \"data-theme\": \"plastic\",\n                children: _jsx(_components.span, {\n                  \"data-line\": \"\",\n                  children: _jsx(_components.span, {\n                    children: \".pth\"\n                  })\n                })\n              })\n            }), \"文件：\"]\n          }), \"\\n\"]\n        }), \"\\n\"]\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.figure, {\n      \"data-rehype-pretty-code-figure\": \"\",\n      children: _jsx(_components.pre, {\n        tabIndex: \"0\",\n        \"data-language\": \"python\",\n        \"data-theme\": \"plastic\",\n        children: _jsxs(_components.code, {\n          \"data-language\": \"python\",\n          \"data-theme\": \"plastic\",\n          style: {\n            display: \"grid\"\n          },\n          children: [_jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 保存模型和优化器状态\"\n            })\n          }), \"\\n\", _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"torch.save({\"\n            })\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"    '\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#98C379\"\n              },\n              children: \"epoch\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \": epoch,\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"    '\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#98C379\"\n              },\n              children: \"model_state_dict\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \": model.state_dict(),\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"    '\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#98C379\"\n              },\n              children: \"optimizer_state_dict\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \": optimizer.state_dict(),\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"    '\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#98C379\"\n              },\n              children: \"loss\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \": loss,\"\n            })]\n          }), \"\\n\", _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#56B6C2\"\n              },\n              children: \"    ...\"\n            })\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"}, \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#98C379\"\n              },\n              children: \"model.pth\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \")\"\n            })]\n          }), \"\\n\", _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 加载模型和优化器状态\"\n            })\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"checkpoint \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \" torch.load(\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#98C379\"\n              },\n              children: \"model.pth\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \")\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"model.load_state_dict(checkpoint[\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#98C379\"\n              },\n              children: \"model_state_dict\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"])\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"optimizer.load_state_dict(checkpoint[\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#98C379\"\n              },\n              children: \"optimizer_state_dict\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"])\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"epoch \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \" checkpoint[\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#98C379\"\n              },\n              children: \"epoch\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"]\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"loss \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \" checkpoint[\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#98C379\"\n              },\n              children: \"loss\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"]\"\n            })]\n          }), \"\\n\", _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#56B6C2\"\n              },\n              children: \"...\"\n            })\n          })]\n        })\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"在这个例子中，\", _jsx(_components.span, {\n        \"data-rehype-pretty-code-figure\": \"\",\n        children: _jsx(_components.code, {\n          \"data-language\": \"plaintext\",\n          \"data-theme\": \"plastic\",\n          children: _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              children: \"model\"\n            })\n          })\n        })\n      }), \"是你要保存的模型对象，\", _jsx(_components.span, {\n        \"data-rehype-pretty-code-figure\": \"\",\n        children: _jsx(_components.code, {\n          \"data-language\": \"plaintext\",\n          \"data-theme\": \"plastic\",\n          children: _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              children: \"optimizer\"\n            })\n          })\n        })\n      }), \"是训练该模型使用的优化器。通过\", _jsx(_components.span, {\n        \"data-rehype-pretty-code-figure\": \"\",\n        children: _jsx(_components.code, {\n          \"data-language\": \"plaintext\",\n          \"data-theme\": \"plastic\",\n          children: _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              children: \"torch.save\"\n            })\n          })\n        })\n      }), \"函数，你可以将模型的状态字典和优化器的状态字典保存到文件中。之后，可以使用\", _jsx(_components.span, {\n        \"data-rehype-pretty-code-figure\": \"\",\n        children: _jsx(_components.code, {\n          \"data-language\": \"plaintext\",\n          \"data-theme\": \"plastic\",\n          children: _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              children: \"torch.load\"\n            })\n          })\n        })\n      }), \"函数来恢复这些状态，以便继续训练或者进行推理。\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      id: \"safetensor-文件中又保存了什么东西\",\n      children: _jsx(_components.a, {\n        href: \"#safetensor-文件中又保存了什么东西\",\n        children: \".safetensor 文件中又保存了什么东西？\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.span, {\n        \"data-rehype-pretty-code-figure\": \"\",\n        children: _jsx(_components.code, {\n          \"data-language\": \"plaintext\",\n          \"data-theme\": \"plastic\",\n          children: _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              children: \".safetensor\"\n            })\n          })\n        })\n      }), \" 文件格式是由 Hugging Face 的 Safety Checker 工具引入的，它是为了在模型推理时提供一个额外的安全层。\", _jsx(_components.span, {\n        \"data-rehype-pretty-code-figure\": \"\",\n        children: _jsx(_components.code, {\n          \"data-language\": \"plaintext\",\n          \"data-theme\": \"plastic\",\n          children: _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              children: \".safetensor\"\n            })\n          })\n        })\n      }), \" 文件中保存的内容主要包括：\"]\n    }), \"\\n\", _jsxs(_components.ol, {\n      children: [\"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.strong, {\n          children: \"模型权重\"\n        }), \"：\", \"\\n\", _jsxs(_components.ul, {\n          children: [\"\\n\", _jsxs(_components.li, {\n            children: [\"这是最核心的部分，与 PyTorch 的 \", _jsx(_components.span, {\n              \"data-rehype-pretty-code-figure\": \"\",\n              children: _jsx(_components.code, {\n                \"data-language\": \"plaintext\",\n                \"data-theme\": \"plastic\",\n                children: _jsx(_components.span, {\n                  \"data-line\": \"\",\n                  children: _jsx(_components.span, {\n                    children: \".pth\"\n                  })\n                })\n              })\n            }), \" 文件类似，\", _jsx(_components.span, {\n              \"data-rehype-pretty-code-figure\": \"\",\n              children: _jsx(_components.code, {\n                \"data-language\": \"plaintext\",\n                \"data-theme\": \"plastic\",\n                children: _jsx(_components.span, {\n                  \"data-line\": \"\",\n                  children: _jsx(_components.span, {\n                    children: \".safetensor\"\n                  })\n                })\n              })\n            }), \" 文件也保存了模型的权重，即神经网络中的参数。\"]\n          }), \"\\n\"]\n        }), \"\\n\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.strong, {\n          children: \"元数据\"\n        }), \"：\", \"\\n\", _jsxs(_components.ul, {\n          children: [\"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.span, {\n              \"data-rehype-pretty-code-figure\": \"\",\n              children: _jsx(_components.code, {\n                \"data-language\": \"plaintext\",\n                \"data-theme\": \"plastic\",\n                children: _jsx(_components.span, {\n                  \"data-line\": \"\",\n                  children: _jsx(_components.span, {\n                    children: \".safetensor\"\n                  })\n                })\n              })\n            }), \" 文件包含了一些元数据，这些数据描述了模型的架构、权重形状、数据类型等信息，这样可以在加载模型时进行验证和适配。\"]\n          }), \"\\n\"]\n        }), \"\\n\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.strong, {\n          children: \"安全性信息\"\n        }), \"：\", \"\\n\", _jsxs(_components.ul, {\n          children: [\"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.span, {\n              \"data-rehype-pretty-code-figure\": \"\",\n              children: _jsx(_components.code, {\n                \"data-language\": \"plaintext\",\n                \"data-theme\": \"plastic\",\n                children: _jsx(_components.span, {\n                  \"data-line\": \"\",\n                  children: _jsx(_components.span, {\n                    children: \".safetensor\"\n                  })\n                })\n              })\n            }), \" 文件可能会包含与模型安全性相关的信息，例如哪些层或参数可能需要特别的安全检查，以及可能的阈值设置等。\\n具体来说，\", _jsx(_components.span, {\n              \"data-rehype-pretty-code-figure\": \"\",\n              children: _jsx(_components.code, {\n                \"data-language\": \"plaintext\",\n                \"data-theme\": \"plastic\",\n                children: _jsx(_components.span, {\n                  \"data-line\": \"\",\n                  children: _jsx(_components.span, {\n                    children: \".safetensor\"\n                  })\n                })\n              })\n            }), \" 文件的内容结构可能如下：\"]\n          }), \"\\n\"]\n        }), \"\\n\"]\n      }), \"\\n\"]\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.span, {\n          \"data-rehype-pretty-code-figure\": \"\",\n          children: _jsx(_components.code, {\n            \"data-language\": \"plaintext\",\n            \"data-theme\": \"plastic\",\n            children: _jsx(_components.span, {\n              \"data-line\": \"\",\n              children: _jsx(_components.span, {\n                children: \"weights\"\n              })\n            })\n          })\n        }), \": 包含模型权重的字典，通常是以张量的形式存储。\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.span, {\n          \"data-rehype-pretty-code-figure\": \"\",\n          children: _jsx(_components.code, {\n            \"data-language\": \"plaintext\",\n            \"data-theme\": \"plastic\",\n            children: _jsx(_components.span, {\n              \"data-line\": \"\",\n              children: _jsx(_components.span, {\n                children: \"metadata\"\n              })\n            })\n          })\n        }), \": 包含模型的元数据，如版本号、架构信息等。\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.span, {\n          \"data-rehype-pretty-code-figure\": \"\",\n          children: _jsx(_components.code, {\n            \"data-language\": \"plaintext\",\n            \"data-theme\": \"plastic\",\n            children: _jsx(_components.span, {\n              \"data-line\": \"\",\n              children: _jsx(_components.span, {\n                children: \"config\"\n              })\n            })\n          })\n        }), \": 包含模型配置信息，如模型类型、类名等。\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.span, {\n          \"data-rehype-pretty-code-figure\": \"\",\n          children: _jsx(_components.code, {\n            \"data-language\": \"plaintext\",\n            \"data-theme\": \"plastic\",\n            children: _jsx(_components.span, {\n              \"data-line\": \"\",\n              children: _jsx(_components.span, {\n                children: \"safety\"\n              })\n            })\n          })\n        }), \": 包含模型安全性相关的信息。\\n使用 \", _jsx(_components.span, {\n          \"data-rehype-pretty-code-figure\": \"\",\n          children: _jsx(_components.code, {\n            \"data-language\": \"plaintext\",\n            \"data-theme\": \"plastic\",\n            children: _jsx(_components.span, {\n              \"data-line\": \"\",\n              children: _jsx(_components.span, {\n                children: \".safetensor\"\n              })\n            })\n          })\n        }), \" 文件的目的之一是为了确保在模型部署时能够进行有效的安全检查，特别是在处理生成型模型（如文本生成、图像生成等）时，可以防止生成不适当的内容。\\n请注意，\", _jsx(_components.span, {\n          \"data-rehype-pretty-code-figure\": \"\",\n          children: _jsx(_components.code, {\n            \"data-language\": \"plaintext\",\n            \"data-theme\": \"plastic\",\n            children: _jsx(_components.span, {\n              \"data-line\": \"\",\n              children: _jsx(_components.span, {\n                children: \".safetensor\"\n              })\n            })\n          })\n        }), \" 文件格式并不是 PyTorch 的标准保存格式，而是 Hugging Face 的特定实现。因此，它可能不如 \", _jsx(_components.span, {\n          \"data-rehype-pretty-code-figure\": \"\",\n          children: _jsx(_components.code, {\n            \"data-language\": \"plaintext\",\n            \"data-theme\": \"plastic\",\n            children: _jsx(_components.span, {\n              \"data-line\": \"\",\n              children: _jsx(_components.span, {\n                children: \".pth\"\n              })\n            })\n          })\n        }), \" 文件那样被广泛使用。如果你在使用 Hugging Face 的模型和工具，可能会遇到 \", _jsx(_components.span, {\n          \"data-rehype-pretty-code-figure\": \"\",\n          children: _jsx(_components.code, {\n            \"data-language\": \"plaintext\",\n            \"data-theme\": \"plastic\",\n            children: _jsx(_components.span, {\n              \"data-line\": \"\",\n              children: _jsx(_components.span, {\n                children: \".safetensor\"\n              })\n            })\n          })\n        }), \" 文件。在使用时，需要确保你的环境支持这种格式。\"]\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      id: \"onnx-文件中又保存了什么信息\",\n      children: _jsx(_components.a, {\n        href: \"#onnx-文件中又保存了什么信息\",\n        children: \".onnx 文件中又保存了什么信息？\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.span, {\n        \"data-rehype-pretty-code-figure\": \"\",\n        children: _jsx(_components.code, {\n          \"data-language\": \"plaintext\",\n          \"data-theme\": \"plastic\",\n          children: _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              children: \".onnx\"\n            })\n          })\n        })\n      }), \"（Open Neural Network Exchange）文件是一个开放格式，用于表示机器学习模型。它旨在提供一种标准的方式来表示深度学习模型，使得模型可以在不同的框架和工具之间进行转换和互操作。一个\", _jsx(_components.span, {\n        \"data-rehype-pretty-code-figure\": \"\",\n        children: _jsx(_components.code, {\n          \"data-language\": \"plaintext\",\n          \"data-theme\": \"plastic\",\n          children: _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              children: \".onnx\"\n            })\n          })\n        })\n      }), \"文件中通常包含以下信息：\"]\n    }), \"\\n\", _jsxs(_components.ol, {\n      children: [\"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.strong, {\n          children: \"模型图（Model Graph）\"\n        }), \"：\", \"\\n\", _jsxs(_components.ul, {\n          children: [\"\\n\", _jsx(_components.li, {\n            children: \"模型图定义了模型的计算流程，它由节点（nodes）和边（edges）组成。\"\n          }), \"\\n\", _jsx(_components.li, {\n            children: \"节点代表计算操作，如卷积、矩阵乘法、激活函数等。\"\n          }), \"\\n\", _jsx(_components.li, {\n            children: \"边代表节点之间的数据流，即张量（tensors）的流动。\"\n          }), \"\\n\"]\n        }), \"\\n\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.strong, {\n          children: \"初始值（Initializers）\"\n        }), \"：\", \"\\n\", _jsxs(_components.ul, {\n          children: [\"\\n\", _jsx(_components.li, {\n            children: \"初始值包含了模型的权重、偏置等参数的值。\"\n          }), \"\\n\", _jsx(_components.li, {\n            children: \"这些参数是在模型图执行之前就已经确定的。\"\n          }), \"\\n\"]\n        }), \"\\n\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.strong, {\n          children: \"模型属性（Attributes）\"\n        }), \"：\", \"\\n\", _jsxs(_components.ul, {\n          children: [\"\\n\", _jsx(_components.li, {\n            children: \"每个节点可能有与之关联的属性，这些属性定义了节点的具体行为，例如卷积操作中的步长（stride）和填充（padding）。\"\n          }), \"\\n\"]\n        }), \"\\n\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.strong, {\n          children: \"输入和输出（Inputs and Outputs）\"\n        }), \"：\", \"\\n\", _jsxs(_components.ul, {\n          children: [\"\\n\", _jsx(_components.li, {\n            children: \"定义了模型的输入和输出张量的名称、数据类型和形状。\"\n          }), \"\\n\", _jsx(_components.li, {\n            children: \"这有助于理解模型期望的输入格式以及它将产生的输出格式。\"\n          }), \"\\n\"]\n        }), \"\\n\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.strong, {\n          children: \"元数据（Metadata）\"\n        }), \"：\", \"\\n\", _jsxs(_components.ul, {\n          children: [\"\\n\", _jsx(_components.li, {\n            children: \"包括模型的名称、版本、作者、生产日期等信息。\"\n          }), \"\\n\", _jsx(_components.li, {\n            children: \"这些信息有助于模型的追踪和管理。\"\n          }), \"\\n\"]\n        }), \"\\n\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.strong, {\n          children: \"优化信息（Optimization Information）\"\n        }), \"（可选）：\", \"\\n\", _jsxs(_components.ul, {\n          children: [\"\\n\", _jsxs(_components.li, {\n            children: [\"一些\", _jsx(_components.span, {\n              \"data-rehype-pretty-code-figure\": \"\",\n              children: _jsx(_components.code, {\n                \"data-language\": \"plaintext\",\n                \"data-theme\": \"plastic\",\n                children: _jsx(_components.span, {\n                  \"data-line\": \"\",\n                  children: _jsx(_components.span, {\n                    children: \".onnx\"\n                  })\n                })\n              })\n            }), \"文件可能包含用于优化模型执行的额外信息，如融合操作或特定硬件上的优化指令。\\n\", _jsx(_components.span, {\n              \"data-rehype-pretty-code-figure\": \"\",\n              children: _jsx(_components.code, {\n                \"data-language\": \"plaintext\",\n                \"data-theme\": \"plastic\",\n                children: _jsx(_components.span, {\n                  \"data-line\": \"\",\n                  children: _jsx(_components.span, {\n                    children: \".onnx\"\n                  })\n                })\n              })\n            }), \"文件的结构大致如下：\"]\n          }), \"\\n\"]\n        }), \"\\n\"]\n      }), \"\\n\"]\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.span, {\n          \"data-rehype-pretty-code-figure\": \"\",\n          children: _jsx(_components.code, {\n            \"data-language\": \"plaintext\",\n            \"data-theme\": \"plastic\",\n            children: _jsx(_components.span, {\n              \"data-line\": \"\",\n              children: _jsx(_components.span, {\n                children: \"ir_version\"\n              })\n            })\n          })\n        }), \": ONNX 格式的版本号。\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.span, {\n          \"data-rehype-pretty-code-figure\": \"\",\n          children: _jsx(_components.code, {\n            \"data-language\": \"plaintext\",\n            \"data-theme\": \"plastic\",\n            children: _jsx(_components.span, {\n              \"data-line\": \"\",\n              children: _jsx(_components.span, {\n                children: \"opset_import\"\n              })\n            })\n          })\n        }), \": 模型使用的操作集版本。\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.span, {\n          \"data-rehype-pretty-code-figure\": \"\",\n          children: _jsx(_components.code, {\n            \"data-language\": \"plaintext\",\n            \"data-theme\": \"plastic\",\n            children: _jsx(_components.span, {\n              \"data-line\": \"\",\n              children: _jsx(_components.span, {\n                children: \"producer_name\"\n              })\n            })\n          })\n        }), \": 生成该 ONNX 模型的工具或库的名称。\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.span, {\n          \"data-rehype-pretty-code-figure\": \"\",\n          children: _jsx(_components.code, {\n            \"data-language\": \"plaintext\",\n            \"data-theme\": \"plastic\",\n            children: _jsx(_components.span, {\n              \"data-line\": \"\",\n              children: _jsx(_components.span, {\n                children: \"producer_version\"\n              })\n            })\n          })\n        }), \": 生成该 ONNX 模型的工具或库的版本。\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.span, {\n          \"data-rehype-pretty-code-figure\": \"\",\n          children: _jsx(_components.code, {\n            \"data-language\": \"plaintext\",\n            \"data-theme\": \"plastic\",\n            children: _jsx(_components.span, {\n              \"data-line\": \"\",\n              children: _jsx(_components.span, {\n                children: \"graph\"\n              })\n            })\n          })\n        }), \": 包含模型图的结构和属性。\", \"\\n\", _jsxs(_components.ul, {\n          children: [\"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.span, {\n              \"data-rehype-pretty-code-figure\": \"\",\n              children: _jsx(_components.code, {\n                \"data-language\": \"plaintext\",\n                \"data-theme\": \"plastic\",\n                children: _jsx(_components.span, {\n                  \"data-line\": \"\",\n                  children: _jsx(_components.span, {\n                    children: \"node\"\n                  })\n                })\n              })\n            }), \": 计算节点列表。\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.span, {\n              \"data-rehype-pretty-code-figure\": \"\",\n              children: _jsx(_components.code, {\n                \"data-language\": \"plaintext\",\n                \"data-theme\": \"plastic\",\n                children: _jsx(_components.span, {\n                  \"data-line\": \"\",\n                  children: _jsx(_components.span, {\n                    children: \"input\"\n                  })\n                })\n              })\n            }), \": 输入列表。\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.span, {\n              \"data-rehype-pretty-code-figure\": \"\",\n              children: _jsx(_components.code, {\n                \"data-language\": \"plaintext\",\n                \"data-theme\": \"plastic\",\n                children: _jsx(_components.span, {\n                  \"data-line\": \"\",\n                  children: _jsx(_components.span, {\n                    children: \"output\"\n                  })\n                })\n              })\n            }), \": 输出列表。\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.span, {\n              \"data-rehype-pretty-code-figure\": \"\",\n              children: _jsx(_components.code, {\n                \"data-language\": \"plaintext\",\n                \"data-theme\": \"plastic\",\n                children: _jsx(_components.span, {\n                  \"data-line\": \"\",\n                  children: _jsx(_components.span, {\n                    children: \"initializer\"\n                  })\n                })\n              })\n            }), \": 初始化参数列表。\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.span, {\n              \"data-rehype-pretty-code-figure\": \"\",\n              children: _jsx(_components.code, {\n                \"data-language\": \"plaintext\",\n                \"data-theme\": \"plastic\",\n                children: _jsx(_components.span, {\n                  \"data-line\": \"\",\n                  children: _jsx(_components.span, {\n                    children: \"value_info\"\n                  })\n                })\n              })\n            }), \": 提供额外的张量信息。\\n使用\", _jsx(_components.span, {\n              \"data-rehype-pretty-code-figure\": \"\",\n              children: _jsx(_components.code, {\n                \"data-language\": \"plaintext\",\n                \"data-theme\": \"plastic\",\n                children: _jsx(_components.span, {\n                  \"data-line\": \"\",\n                  children: _jsx(_components.span, {\n                    children: \".onnx\"\n                  })\n                })\n              })\n            }), \"文件，可以轻松地将模型从 PyTorch、TensorFlow、Caffe2 等框架转换到 ONNX 格式，然后再部署到不同的推理引擎或硬件平台上，例如使用 ONNX Runtime 进行推理。这种格式提高了模型的便携性和互操作性。\"]\n          }), \"\\n\"]\n        }), \"\\n\"]\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      id: \"简述-pth--safetensor--onnx-保存的信息中有哪些是相同的有哪些有区别\",\n      children: _jsx(_components.a, {\n        href: \"#简述-pth--safetensor--onnx-保存的信息中有哪些是相同的有哪些有区别\",\n        children: \"简述 .pth ， .safetensor ， .onnx 保存的信息中，有哪些是相同的？有哪些有区别？\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\".pth, .safetensor, 和 .onnx 文件格式都用于保存机器学习模型的相关信息，但它们的设计目的、兼容性和包含的具体内容有所不同。以下是它们之间相同点和区别的概述：\\n\", _jsx(_components.strong, {\n        children: \"相同点：\"\n      })]\n    }), \"\\n\", _jsxs(_components.ol, {\n      children: [\"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.strong, {\n          children: \"模型参数/权重\"\n        }), \"：\", \"\\n\", _jsxs(_components.ul, {\n          children: [\"\\n\", _jsx(_components.li, {\n            children: \"所有三种格式都保存了模型的参数或权重，这些是训练过程中学习到的数值，对于模型的预测能力至关重要。\"\n          }), \"\\n\"]\n        }), \"\\n\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.strong, {\n          children: \"元数据\"\n        }), \"：\", \"\\n\", _jsxs(_components.ul, {\n          children: [\"\\n\", _jsxs(_components.li, {\n            children: [\"它们都可能包含一些元数据，如模型的版本、创建日期或其他描述性信息，尽管具体的元数据内容和格式可能有所不同。\\n\", _jsx(_components.strong, {\n              children: \"区别：\"\n            })]\n          }), \"\\n\"]\n        }), \"\\n\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.strong, {\n          children: \"格式和兼容性\"\n        }), \"：\", \"\\n\", _jsxs(_components.ul, {\n          children: [\"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.span, {\n              \"data-rehype-pretty-code-figure\": \"\",\n              children: _jsx(_components.code, {\n                \"data-language\": \"plaintext\",\n                \"data-theme\": \"plastic\",\n                children: _jsx(_components.span, {\n                  \"data-line\": \"\",\n                  children: _jsx(_components.span, {\n                    children: \".pth\"\n                  })\n                })\n              })\n            }), \" 是 PyTorch 的原生格式，专门用于保存和加载 PyTorch 模型的状态字典，包括模型权重和优化器状态。\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.span, {\n              \"data-rehype-pretty-code-figure\": \"\",\n              children: _jsx(_components.code, {\n                \"data-language\": \"plaintext\",\n                \"data-theme\": \"plastic\",\n                children: _jsx(_components.span, {\n                  \"data-line\": \"\",\n                  children: _jsx(_components.span, {\n                    children: \".safetensor\"\n                  })\n                })\n              })\n            }), \" 是 Hugging Face 的 Safety Checker 工具使用的格式，除了模型权重，还包含了安全性相关的信息。\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.span, {\n              \"data-rehype-pretty-code-figure\": \"\",\n              children: _jsx(_components.code, {\n                \"data-language\": \"plaintext\",\n                \"data-theme\": \"plastic\",\n                children: _jsx(_components.span, {\n                  \"data-line\": \"\",\n                  children: _jsx(_components.span, {\n                    children: \".onnx\"\n                  })\n                })\n              })\n            }), \" 是一个开放的、跨框架的格式，用于在不同的深度学习框架之间交换模型，不仅包含模型结构和参数，还定义了模型计算图。\"]\n          }), \"\\n\"]\n        }), \"\\n\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.strong, {\n          children: \"包含内容\"\n        }), \"：\", \"\\n\", _jsxs(_components.ul, {\n          children: [\"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.span, {\n              \"data-rehype-pretty-code-figure\": \"\",\n              children: _jsx(_components.code, {\n                \"data-language\": \"plaintext\",\n                \"data-theme\": \"plastic\",\n                children: _jsx(_components.span, {\n                  \"data-line\": \"\",\n                  children: _jsx(_components.span, {\n                    children: \".pth\"\n                  })\n                })\n              })\n            }), \" 文件通常包含模型的状态字典和优化器的状态字典，以及可选的其他训练信息（如损失值、迭代次数等）。\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.span, {\n              \"data-rehype-pretty-code-figure\": \"\",\n              children: _jsx(_components.code, {\n                \"data-language\": \"plaintext\",\n                \"data-theme\": \"plastic\",\n                children: _jsx(_components.span, {\n                  \"data-line\": \"\",\n                  children: _jsx(_components.span, {\n                    children: \".safetensor\"\n                  })\n                })\n              })\n            }), \" 文件包含模型权重、元数据以及与模型安全性相关的信息。\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.span, {\n              \"data-rehype-pretty-code-figure\": \"\",\n              children: _jsx(_components.code, {\n                \"data-language\": \"plaintext\",\n                \"data-theme\": \"plastic\",\n                children: _jsx(_components.span, {\n                  \"data-line\": \"\",\n                  children: _jsx(_components.span, {\n                    children: \".onnx\"\n                  })\n                })\n              })\n            }), \" 文件包含模型计算图、节点定义、边的连接、初始值（模型权重）、输入输出定义以及可选的优化信息。\"]\n          }), \"\\n\"]\n        }), \"\\n\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.strong, {\n          children: \"使用场景\"\n        }), \"：\", \"\\n\", _jsxs(_components.ul, {\n          children: [\"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.span, {\n              \"data-rehype-pretty-code-figure\": \"\",\n              children: _jsx(_components.code, {\n                \"data-language\": \"plaintext\",\n                \"data-theme\": \"plastic\",\n                children: _jsx(_components.span, {\n                  \"data-line\": \"\",\n                  children: _jsx(_components.span, {\n                    children: \".pth\"\n                  })\n                })\n              })\n            }), \" 文件主要用于 PyTorch 模型的训练和推理。\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.span, {\n              \"data-rehype-pretty-code-figure\": \"\",\n              children: _jsx(_components.code, {\n                \"data-language\": \"plaintext\",\n                \"data-theme\": \"plastic\",\n                children: _jsx(_components.span, {\n                  \"data-line\": \"\",\n                  children: _jsx(_components.span, {\n                    children: \".safetensor\"\n                  })\n                })\n              })\n            }), \" 文件用于在 Hugging Face 的生态系统中进行模型的安全检查。\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.span, {\n              \"data-rehype-pretty-code-figure\": \"\",\n              children: _jsx(_components.code, {\n                \"data-language\": \"plaintext\",\n                \"data-theme\": \"plastic\",\n                children: _jsx(_components.span, {\n                  \"data-line\": \"\",\n                  children: _jsx(_components.span, {\n                    children: \".onnx\"\n                  })\n                })\n              })\n            }), \" 文件用于模型在不同框架之间的转换和部署，特别是在需要跨平台或硬件优化的场景中。\"]\n          }), \"\\n\"]\n        }), \"\\n\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.strong, {\n          children: \"开放性和互操作性\"\n        }), \"：\", \"\\n\", _jsxs(_components.ul, {\n          children: [\"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.span, {\n              \"data-rehype-pretty-code-figure\": \"\",\n              children: _jsx(_components.code, {\n                \"data-language\": \"plaintext\",\n                \"data-theme\": \"plastic\",\n                children: _jsx(_components.span, {\n                  \"data-line\": \"\",\n                  children: _jsx(_components.span, {\n                    children: \".onnx\"\n                  })\n                })\n              })\n            }), \" 格式的设计重点在于开放性和互操作性，使其成为不同框架和工具之间模型交换的桥梁。\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.span, {\n              \"data-rehype-pretty-code-figure\": \"\",\n              children: _jsx(_components.code, {\n                \"data-language\": \"plaintext\",\n                \"data-theme\": \"plastic\",\n                children: _jsx(_components.span, {\n                  \"data-line\": \"\",\n                  children: _jsx(_components.span, {\n                    children: \".pth\"\n                  })\n                })\n              })\n            }), \" 和 \", _jsx(_components.span, {\n              \"data-rehype-pretty-code-figure\": \"\",\n              children: _jsx(_components.code, {\n                \"data-language\": \"plaintext\",\n                \"data-theme\": \"plastic\",\n                children: _jsx(_components.span, {\n                  \"data-line\": \"\",\n                  children: _jsx(_components.span, {\n                    children: \".safetensor\"\n                  })\n                })\n              })\n            }), \" 更专注于特定框架或工具链内的使用。\\n总结来说，这三种格式都用于保存模型权重，但它们在格式兼容性、包含的额外信息和使用场景上存在明显差异。\", _jsx(_components.span, {\n              \"data-rehype-pretty-code-figure\": \"\",\n              children: _jsx(_components.code, {\n                \"data-language\": \"plaintext\",\n                \"data-theme\": \"plastic\",\n                children: _jsx(_components.span, {\n                  \"data-line\": \"\",\n                  children: _jsx(_components.span, {\n                    children: \".onnx\"\n                  })\n                })\n              })\n            }), \" 格式更加开放和通用，而 \", _jsx(_components.span, {\n              \"data-rehype-pretty-code-figure\": \"\",\n              children: _jsx(_components.code, {\n                \"data-language\": \"plaintext\",\n                \"data-theme\": \"plastic\",\n                children: _jsx(_components.span, {\n                  \"data-line\": \"\",\n                  children: _jsx(_components.span, {\n                    children: \".pth\"\n                  })\n                })\n              })\n            }), \" 和 \", _jsx(_components.span, {\n              \"data-rehype-pretty-code-figure\": \"\",\n              children: _jsx(_components.code, {\n                \"data-language\": \"plaintext\",\n                \"data-theme\": \"plastic\",\n                children: _jsx(_components.span, {\n                  \"data-line\": \"\",\n                  children: _jsx(_components.span, {\n                    children: \".safetensor\"\n                  })\n                })\n              })\n            }), \" 更专注于特定的框架或应用需求。\"]\n          }), \"\\n\"]\n        }), \"\\n\"]\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      id: \"简述-pth--safetensor--onnx-保存的信息中有哪些是相同的保存的信息中又有哪些有区别\",\n      children: _jsx(_components.a, {\n        href: \"#简述-pth--safetensor--onnx-保存的信息中有哪些是相同的保存的信息中又有哪些有区别\",\n        children: \"简述 .pth ， .safetensor ， .onnx 保存的信息中有哪些是相同的？保存的信息中又有哪些有区别？\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\".pth、.safetensor 和.onnx 文件格式虽然都是为了保存机器学习模型的相关信息，但它们在保存的内容上存在相同点和差异。\\n\", _jsx(_components.strong, {\n        children: \"相同点：\"\n      })]\n    }), \"\\n\", _jsxs(_components.ol, {\n      children: [\"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.strong, {\n          children: \"模型参数/权重\"\n        }), \"：这三种文件格式都会保存模型的参数或权重，这些权重是模型在训练过程中学习到的，对模型的预测能力至关重要。\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.strong, {\n          children: \"元数据\"\n        }), \"：它们都可能包含一些元数据，例如模型的版本、创建日期或其他描述性信息，尽管具体的元数据和格式可能因文件格式而异。\\n\", _jsx(_components.strong, {\n          children: \"区别：\"\n        })]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.strong, {\n          children: \"格式和兼容性\"\n        }), \"：\", \"\\n\", _jsxs(_components.ul, {\n          children: [\"\\n\", _jsx(_components.li, {\n            children: \".pth 文件是 PyTorch 的原生格式，主要用于保存和加载 PyTorch 模型的状态字典，包括模型权重和优化器状态。\"\n          }), \"\\n\", _jsx(_components.li, {\n            children: \".safetensor 文件是 Hugging Face 的 Safety Checker 工具使用的格式，除了模型权重，还包括安全性相关的信息。\"\n          }), \"\\n\", _jsx(_components.li, {\n            children: \".onnx 文件是一种开放的、跨框架的格式，用于在不同深度学习框架之间交换模型，包含模型结构和参数以及模型计算图。\"\n          }), \"\\n\"]\n        }), \"\\n\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.strong, {\n          children: \"包含内容\"\n        }), \"：\", \"\\n\", _jsxs(_components.ul, {\n          children: [\"\\n\", _jsx(_components.li, {\n            children: \".pth 文件通常包含模型的状态字典和优化器的状态字典，可能还包括其他训练信息，如损失值、迭代次数等。\"\n          }), \"\\n\", _jsx(_components.li, {\n            children: \".safetensor 文件包含模型权重、元数据以及与模型安全性相关的信息。\"\n          }), \"\\n\", _jsx(_components.li, {\n            children: \".onnx 文件包含模型计算图、节点定义、边的连接、初始值（模型权重）、输入输出定义以及可选的优化信息。\"\n          }), \"\\n\"]\n        }), \"\\n\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.strong, {\n          children: \"使用场景\"\n        }), \"：\", \"\\n\", _jsxs(_components.ul, {\n          children: [\"\\n\", _jsx(_components.li, {\n            children: \".pth 文件主要用于 PyTorch 模型的训练和推理。\"\n          }), \"\\n\", _jsx(_components.li, {\n            children: \".safetensor 文件用于 Hugging Face 生态系统中的模型安全检查。\"\n          }), \"\\n\", _jsx(_components.li, {\n            children: \".onnx 文件用于模型在不同框架之间的转换和部署，特别是在需要跨平台或硬件优化的场景中。\"\n          }), \"\\n\"]\n        }), \"\\n\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.strong, {\n          children: \"开放性和互操作性\"\n        }), \"：\", \"\\n\", _jsxs(_components.ul, {\n          children: [\"\\n\", _jsx(_components.li, {\n            children: \".onnx 格式重点在于开放性和互操作性，便于不同框架和工具之间模型交换。\"\n          }), \"\\n\", _jsx(_components.li, {\n            children: \".pth 和.safetensor 文件更专注于特定框架或工具链内的使用。\\n总结来说，这三种文件格式都保存模型权重，但在格式兼容性、包含的额外信息和使用场景上存在明显差异。.onnx 格式更开放和通用，而.pth 和.safetensor 则更专注于特定框架或应用需求。\"\n          }), \"\\n\"]\n        }), \"\\n\"]\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      id: \"pth--safetensor--onnx-三种格式各自能否用于模型的-finetunning-为什么\",\n      children: _jsx(_components.a, {\n        href: \"#pth--safetensor--onnx-三种格式各自能否用于模型的-finetunning-为什么\",\n        children: \".pth ， .safetensor ， .onnx 三种格式，各自能否用于模型的 finetunning ？为什么？\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\".pth、.safetensor 和 .onnx 三种格式在模型微调（finetuning）方面的适用性各有不同，以下是各自的适用性分析：\\n\", _jsx(_components.strong, {\n        children: \".pth 格式：\"\n      }), \"\\n.pth 文件可以用于模型的微调。原因如下：\"]\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \".pth 文件是 PyTorch 的原生格式，它保存了模型的状态字典，包括模型的权重和可选的优化器状态。\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"在微调过程中，可以加载 .pth 文件中的模型权重，然后根据新的数据集对模型进行进一步的训练。\"\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"如果 .pth 文件中包含了优化器状态，那么可以从中断点继续训练，这对于微调过程是有帮助的。\\n\", _jsx(_components.strong, {\n          children: \".safetensor 格式：\"\n        }), \"\\n.safetensor 文件也可以用于模型的微调，但有一些限制：\"]\n      }), \"\\n\", _jsx(_components.li, {\n        children: \".safetensor 文件主要是由 Hugging Face 的 Safety Checker 工具使用的，它保存了模型权重和与安全性相关的信息。\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"虽然这个格式主要用于安全检查，但它仍然包含了模型权重，因此理论上可以用于微调。\"\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"但是，由于 .safetensor 文件格式可能不如 .pth 那样被广泛支持，因此在微调时可能需要额外的步骤来转换格式或加载权重。\\n\", _jsx(_components.strong, {\n          children: \".onnx 格式：\"\n        }), \"\\n.onnx 文件在微调方面的适用性较低，原因如下：\"]\n      }), \"\\n\", _jsx(_components.li, {\n        children: \".onnx 文件是一个开放的、跨框架的格式，它不仅包含模型权重，还定义了模型计算图。\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"虽然 .onnx 格式支持在不同的框架之间转换模型，但它不是为了微调而设计的。计算图是固定的，不易于修改。\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"如果需要微调 .onnx 格式的模型，通常需要先将模型转换回原始框架（如 PyTorch 或 TensorFlow），然后再进行微调。\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"因此，直接在 .onnx 格式上进行微调通常不切实际，除非有特定的工具或库支持这种操作。\\n总结来说，.pth 格式最适合用于 PyTorch 模型的微调，因为它直接与 PyTorch 的训练和推理流程兼容。.safetensor 格式也可以用于微调，但可能需要额外的步骤来处理。而 .onnx 格式通常不直接用于微调，需要转换为其他框架格式后才能进行微调。\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      id: \"pth--safetensor--onnx-三种格式各自能否用于训练-lora-为什么\",\n      children: _jsx(_components.a, {\n        href: \"#pth--safetensor--onnx-三种格式各自能否用于训练-lora-为什么\",\n        children: \".pth ， .safetensor ， .onnx 三种格式，各自能否用于训练 LoRA ？为什么？\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"LoRA（Low-Rank Adaptation）是一种用于微调大型预训练模型的技术，它通过引入低秩分解来减少微调所需的参数数量，从而减少存储和计算需求。以下是关于 .pth、.safetensor 和 .onnx 格式在训练 LoRA 时的适用性分析：\\n\", _jsx(_components.strong, {\n        children: \".pth 格式：\"\n      }), \"\\n.pth 文件可以用于训练 LoRA。原因如下：\"]\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \".pth 文件是 PyTorch 的原生格式，可以直接保存和加载模型的权重，包括 LoRA 引入的低秩矩阵。\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"在训练 LoRA 时，通常需要在原始预训练模型的基础上添加额外的参数（即低秩矩阵），这些参数可以在 PyTorch 中通过自定义层或修改现有层来实现。\"\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"由于 .pth 文件与 PyTorch 框架紧密集成，因此可以轻松地保存和加载 LoRA 的参数，并进行训练。\\n\", _jsx(_components.strong, {\n          children: \".safetensor 格式：\"\n        }), \"\\n.safetensor 文件也可以用于训练 LoRA，但可能有一些限制：\"]\n      }), \"\\n\", _jsx(_components.li, {\n        children: \".safetensor 文件是为了提高模型使用的安全性而设计的，它保存了模型权重和其他与安全性相关的信息。\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"如果 LoRA 的参数被包含在 .safetensor 文件中，那么理论上可以用于训练。\"\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"然而，由于 .safetensor 文件格式可能不如 .pth 那样被广泛支持，因此在训练 LoRA 时可能需要额外的步骤来处理文件格式。\\n\", _jsx(_components.strong, {\n          children: \".onnx 格式：\"\n        }), \"\\n.onnx 文件在训练 LoRA 方面通常不适用。原因如下：\"]\n      }), \"\\n\", _jsx(_components.li, {\n        children: \".onnx 文件定义了模型的计算图和权重，但它是一个静态的模型描述格式，不适合动态修改模型结构，如添加 LoRA 层。\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"LoRA 需要在预训练模型的特定层中插入低秩矩阵，这通常需要对模型结构进行修改，而 .onnx 格式不支持这种修改。\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"如果需要使用 .onnx 文件中的模型来训练 LoRA，通常需要先将模型转换回 PyTorch 或其他支持动态图修改的框架，然后再进行训练。\\n总结来说，.pth 格式最适合用于训练 LoRA，因为它与 PyTorch 框架紧密集成，支持动态图和自定义层的添加。.safetensor 格式在理论上也是可行的，但可能需要额外的处理步骤。而 .onnx 格式由于不支持动态修改模型结构，因此不适合直接用于训练 LoRA。\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      id: \"pth--safetensor--onnx-三种格式如何两两转换\",\n      children: _jsx(_components.a, {\n        href: \"#pth--safetensor--onnx-三种格式如何两两转换\",\n        children: \"pth ， safetensor ， onnx ，三种格式如何两两转换？\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \".pth、.safetensor 和 .onnx 文件格式之间的转换通常需要通过特定的工具和库来实现。以下是如何在这三种格式之间进行两两转换的概述：\"\n    }), \"\\n\", _jsx(_components.h3, {\n      id: \"pth-到-safetensor-的转换\",\n      children: _jsx(_components.a, {\n        href: \"#pth-到-safetensor-的转换\",\n        children: \".pth 到 .safetensor 的转换\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"目前，并没有直接的标准工具来将 .pth 文件转换为 .safetensor 文件。但是，可以手动加载 .pth 文件中的权重，并将其保存为 .safetensor 格式。以下是一个示例步骤：\"\n    }), \"\\n\", _jsxs(_components.ol, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"使用 PyTorch 加载 .pth 文件。\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"提取模型权重。\"\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"使用 Hugging Face 的 \", _jsx(_components.span, {\n          \"data-rehype-pretty-code-figure\": \"\",\n          children: _jsx(_components.code, {\n            \"data-language\": \"plaintext\",\n            \"data-theme\": \"plastic\",\n            children: _jsx(_components.span, {\n              \"data-line\": \"\",\n              children: _jsx(_components.span, {\n                children: \"transformers\"\n              })\n            })\n          })\n        }), \" 库或其他相关工具将权重保存为 .safetensor 文件。\"]\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h3, {\n      id: \"safetensor-到-pth-的转换\",\n      children: _jsx(_components.a, {\n        href: \"#safetensor-到-pth-的转换\",\n        children: \".safetensor 到 .pth 的转换\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"同样地，将 .safetensor 文件转换为 .pth 文件也没有直接的转换工具。以下是手动转换的步骤：\"\n    }), \"\\n\", _jsxs(_components.ol, {\n      children: [\"\\n\", _jsxs(_components.li, {\n        children: [\"使用 Hugging Face 的 \", _jsx(_components.span, {\n          \"data-rehype-pretty-code-figure\": \"\",\n          children: _jsx(_components.code, {\n            \"data-language\": \"plaintext\",\n            \"data-theme\": \"plastic\",\n            children: _jsx(_components.span, {\n              \"data-line\": \"\",\n              children: _jsx(_components.span, {\n                children: \"transformers\"\n              })\n            })\n          })\n        }), \" 库或其他相关工具加载 .safetensor 文件。\"]\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"提取模型权重。\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"使用 PyTorch 将权重保存为 .pth 文件。\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h3, {\n      id: \"pth-到-onnx-的转换\",\n      children: _jsx(_components.a, {\n        href: \"#pth-到-onnx-的转换\",\n        children: \".pth 到 .onnx 的转换\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"PyTorch 提供了直接将模型转换为 .onnx 格式的工具：\"\n    }), \"\\n\", _jsx(_components.figure, {\n      \"data-rehype-pretty-code-figure\": \"\",\n      children: _jsx(_components.pre, {\n        tabIndex: \"0\",\n        \"data-language\": \"python\",\n        \"data-theme\": \"plastic\",\n        children: _jsxs(_components.code, {\n          \"data-language\": \"python\",\n          \"data-theme\": \"plastic\",\n          style: {\n            display: \"grid\"\n          },\n          children: [_jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"import\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \" torch\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"import\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \" torch.onnx\"\n            })]\n          }), \"\\n\", _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 假设 model 是一个 PyTorch 模型\"\n            })\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"model \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#56B6C2\"\n              },\n              children: \" ...\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"  # 加载或定义模型\"\n            })]\n          }), \"\\n\", _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 假设输入是一个张量，其形状与模型输入兼容\"\n            })\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"input_sample \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \" torch.randn(batch_size, channels, height, width)\"\n            })]\n          }), \"\\n\", _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 将模型转换为 ONNX 格式\"\n            })\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"torch.onnx.export(model,               \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 模型\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"                  input_sample,        \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 模型输入（或一个包含输入的元组）\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"                  \\\"\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#98C379\"\n              },\n              children: \"model.onnx\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"\\\"\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \",       \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 输出文件名\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#C6CCD7\"\n              },\n              children: \"                  export_params\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#56B6C2\"\n              },\n              children: \"True\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \",  \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 是否导出参数\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#C6CCD7\"\n              },\n              children: \"                  opset_version\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#56B6C2\"\n              },\n              children: \"10\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \",    \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# ONNX 算子集版本\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#C6CCD7\"\n              },\n              children: \"                  do_constant_folding\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#56B6C2\"\n              },\n              children: \"True\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \",  \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 是否执行常量折叠优化\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#C6CCD7\"\n              },\n              children: \"                  input_names\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"[\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#98C379\"\n              },\n              children: \"input\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"],   \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 输入名\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#C6CCD7\"\n              },\n              children: \"                  output_names\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"[\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#98C379\"\n              },\n              children: \"output\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"], \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 输出名\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#C6CCD7\"\n              },\n              children: \"                  dynamic_axes\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"{\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#98C379\"\n              },\n              children: \"input\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \": {\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#56B6C2\"\n              },\n              children: \"0\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \": \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#98C379\"\n              },\n              children: \"batch_size\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"},  \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 动态轴\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"                                '\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#98C379\"\n              },\n              children: \"output\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \": {\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#56B6C2\"\n              },\n              children: \"0\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \": \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#98C379\"\n              },\n              children: \"batch_size\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"}})\"\n            })]\n          })]\n        })\n      })\n    }), \"\\n\", _jsx(_components.h3, {\n      id: \"onnx-到-pth-的转换\",\n      children: _jsx(_components.a, {\n        href: \"#onnx-到-pth-的转换\",\n        children: \".onnx 到 .pth 的转换\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"将 .onnx 文件转换为 .pth 文件通常不直接进行，因为 .onnx 文件包含了模型的结构信息，而 .pth 文件只包含权重。如果需要，可以重新创建 PyTorch 模型结构，然后加载 .onnx 文件中的权重：\"\n    }), \"\\n\", _jsxs(_components.ol, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"定义与 .onnx 文件对应的 PyTorch 模型结构。\"\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"使用 \", _jsx(_components.span, {\n          \"data-rehype-pretty-code-figure\": \"\",\n          children: _jsx(_components.code, {\n            \"data-language\": \"plaintext\",\n            \"data-theme\": \"plastic\",\n            children: _jsx(_components.span, {\n              \"data-line\": \"\",\n              children: _jsx(_components.span, {\n                children: \"onnx.load\"\n              })\n            })\n          })\n        }), \" 加载 .onnx 文件。\"]\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"提取权重并将其加载到 PyTorch 模型中。\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h3, {\n      id: \"safetensor-到-onnx-的转换\",\n      children: _jsx(_components.a, {\n        href: \"#safetensor-到-onnx-的转换\",\n        children: \".safetensor 到 .onnx 的转换\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"目前没有直接的方法将 .safetensor 文件转换为 .onnx 文件。如果需要，可以先将 .safetensor 文件转换为 .pth 文件，然后再按照上述方法将 .pth 文件转换为 .onnx 文件。\"\n    }), \"\\n\", _jsx(_components.h3, {\n      id: \"onnx-到-safetensor-的转换\",\n      children: _jsx(_components.a, {\n        href: \"#onnx-到-safetensor-的转换\",\n        children: \".onnx 到 .safetensor 的转换\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"同样地，将 .onnx 文件转换为 .safetensor 文件也没有直接的转换工具。如果需要，可以先将 .onnx 文件转换为 .pth 文件，然后再将 .pth 文件转换为 .safetensor 文件。\\n在进行这些转换时，需要注意的是，转换过程中可能会丢失一些特定的信息，如优化器状态或模型配置，因此在转换后可能需要额外的步骤来确保模型的完整性和正确性。\"\n    }), \"\\n\", _jsx(_components.h2, {\n      id: \"我有一个从网络上下载的-pth-文件-001pth-给我-python-代码将其转换为-onnx-格式\",\n      children: _jsxs(_components.a, {\n        href: \"#我有一个从网络上下载的-pth-文件-001pth-给我-python-代码将其转换为-onnx-格式\",\n        children: [\"我有一个从网络上下载的 .pth 文件 \", _jsx(_components.span, {\n          \"data-rehype-pretty-code-figure\": \"\",\n          children: _jsx(_components.code, {\n            \"data-language\": \"plaintext\",\n            \"data-theme\": \"plastic\",\n            children: _jsx(_components.span, {\n              \"data-line\": \"\",\n              children: _jsx(_components.span, {\n                children: \"001.pth\"\n              })\n            })\n          })\n        }), \" 。给我 Python 代码，将其转换为 onnx 格式。\"]\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"要将一个 \", _jsx(_components.span, {\n        \"data-rehype-pretty-code-figure\": \"\",\n        children: _jsx(_components.code, {\n          \"data-language\": \"plaintext\",\n          \"data-theme\": \"plastic\",\n          children: _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              children: \".pth\"\n            })\n          })\n        })\n      }), \" 文件转换为 \", _jsx(_components.span, {\n        \"data-rehype-pretty-code-figure\": \"\",\n        children: _jsx(_components.code, {\n          \"data-language\": \"plaintext\",\n          \"data-theme\": \"plastic\",\n          children: _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              children: \".onnx\"\n            })\n          })\n        })\n      }), \" 格式，你需要首先加载 \", _jsx(_components.span, {\n        \"data-rehype-pretty-code-figure\": \"\",\n        children: _jsx(_components.code, {\n          \"data-language\": \"plaintext\",\n          \"data-theme\": \"plastic\",\n          children: _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              children: \".pth\"\n            })\n          })\n        })\n      }), \" 文件中的模型，然后使用 PyTorch 的 \", _jsx(_components.span, {\n        \"data-rehype-pretty-code-figure\": \"\",\n        children: _jsx(_components.code, {\n          \"data-language\": \"plaintext\",\n          \"data-theme\": \"plastic\",\n          children: _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              children: \"torch.onnx.export\"\n            })\n          })\n        })\n      }), \" 函数来进行转换。以下是一个 Python 代码示例，展示了如何进行这一转换过程。假设你已经有了对应的 PyTorch 模型定义，并且 \", _jsx(_components.span, {\n        \"data-rehype-pretty-code-figure\": \"\",\n        children: _jsx(_components.code, {\n          \"data-language\": \"plaintext\",\n          \"data-theme\": \"plastic\",\n          children: _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              children: \".pth\"\n            })\n          })\n        })\n      }), \" 文件中包含的是该模型的权重。\\n请注意，以下代码假设你的模型是一个标准的 PyTorch 模型，并且你知道模型的输入尺 ��。你需要根据你的模型实际情况来调整输入尺寸和模型结构。\"]\n    }), \"\\n\", _jsx(_components.figure, {\n      \"data-rehype-pretty-code-figure\": \"\",\n      children: _jsx(_components.pre, {\n        tabIndex: \"0\",\n        \"data-language\": \"python\",\n        \"data-theme\": \"plastic\",\n        children: _jsxs(_components.code, {\n          \"data-language\": \"python\",\n          \"data-theme\": \"plastic\",\n          style: {\n            display: \"grid\"\n          },\n          children: [_jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"import\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \" torch\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"import\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \" torch.onnx\"\n            })]\n          }), \"\\n\", _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 假设模型结构和输入尺寸已知\"\n            })\n          }), \"\\n\", _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 这里是示例模型结构和输入尺寸，你需要根据你的模型进行修改\"\n            })\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#61AFEF\"\n              },\n              children: \"class\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E5C07B\"\n              },\n              children: \" MyModel\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"(\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#D19A66\"\n              },\n              children: \"torch\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \".\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#D19A66\"\n              },\n              children: \"nn\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \".\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#D19A66\"\n              },\n              children: \"Module\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"):\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#61AFEF\"\n              },\n              children: \"    def\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#B57EDC\"\n              },\n              children: \" __init__\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"(\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#C6CCD7\"\n              },\n              children: \"self\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"):\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#E5C07B\"\n              },\n              children: \"        super\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"(MyModel, \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"self\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \").\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#B57EDC\"\n              },\n              children: \"__init__\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"()\"\n            })]\n          }), \"\\n\", _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"        # 定义模型结构\"\n            })\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"        self\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \".conv1 \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \" torch.nn.Conv2d(\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#56B6C2\"\n              },\n              children: \"3\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \", \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#56B6C2\"\n              },\n              children: \"16\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \", \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#C6CCD7\"\n              },\n              children: \"kernel_size\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#56B6C2\"\n              },\n              children: \"3\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \", \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#C6CCD7\"\n              },\n              children: \"stride\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#56B6C2\"\n              },\n              children: \"1\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \", \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#C6CCD7\"\n              },\n              children: \"padding\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#56B6C2\"\n              },\n              children: \"1\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \")\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"        self\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \".relu \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \" torch.nn.ReLU()\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"        self\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \".pool \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \" torch.nn.MaxPool2d(\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#C6CCD7\"\n              },\n              children: \"kernel_size\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#56B6C2\"\n              },\n              children: \"2\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \", \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#C6CCD7\"\n              },\n              children: \"stride\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#56B6C2\"\n              },\n              children: \"2\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \", \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#C6CCD7\"\n              },\n              children: \"padding\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#56B6C2\"\n              },\n              children: \"0\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \")\"\n            })]\n          }), \"\\n\", _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"        # ... 添加更多层 ...\"\n            })\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#61AFEF\"\n              },\n              children: \"    def\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#B57EDC\"\n              },\n              children: \" forward\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"(\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#C6CCD7\"\n              },\n              children: \"self\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \", \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#C6CCD7\"\n              },\n              children: \"x\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"):\"\n            })]\n          }), \"\\n\", _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"        # 定义前向传播\"\n            })\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"        x \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \" self\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \".conv1(x)\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"        x \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \" self\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \".relu(x)\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"        x \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \" self\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \".pool(x)\"\n            })]\n          }), \"\\n\", _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"        # ... 应用更多层 ...\"\n            })\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"        return\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \" x\"\n            })]\n          }), \"\\n\", _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 创建模型实例\"\n            })\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"model \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \" MyModel()\"\n            })]\n          }), \"\\n\", _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 加载.pth文件中的权重\"\n            })\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"model.load_state_dict(torch.load(\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#98C379\"\n              },\n              children: \"001.pth\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"))\"\n            })]\n          }), \"\\n\", _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 设置模型为评估模式（如果适用）\"\n            })\n          }), \"\\n\", _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"model.eval()\"\n            })\n          }), \"\\n\", _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 创建一个符合模型输入尺寸的示例输入\"\n            })\n          }), \"\\n\", _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 假设输入是单张图片，通道数为3，高和宽分别为224和224\"\n            })\n          }), \"\\n\", _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 你需要根据你的模型调整输入尺寸\"\n            })\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"input_sample \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \" torch.randn(\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#56B6C2\"\n              },\n              children: \"1\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \", \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#56B6C2\"\n              },\n              children: \"3\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \", \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#56B6C2\"\n              },\n              children: \"224\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \", \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#56B6C2\"\n              },\n              children: \"224\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \")\"\n            })]\n          }), \"\\n\", _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 指定ONNX模型的输出文件名\"\n            })\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"output_file \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \" '\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#98C379\"\n              },\n              children: \"model.onnx\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            })]\n          }), \"\\n\", _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 导出模型为ONNX格式\"\n            })\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"torch.onnx.export(model,               \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 模型\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"                  input_sample,        \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 模型输入（或一个包含输入的元组）\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"                  output_file,         \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 输出文件名\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#C6CCD7\"\n              },\n              children: \"                  export_params\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#56B6C2\"\n              },\n              children: \"True\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \",  \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 是否导出参数\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#C6CCD7\"\n              },\n              children: \"                  opset_version\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#56B6C2\"\n              },\n              children: \"10\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \",    \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# ONNX 算子集版本\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#C6CCD7\"\n              },\n              children: \"                  do_constant_folding\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#56B6C2\"\n              },\n              children: \"True\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \",  \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 是否执行常量折叠优化\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#C6CCD7\"\n              },\n              children: \"                  input_names\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"[\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#98C379\"\n              },\n              children: \"input\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"],   \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 输入名\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#C6CCD7\"\n              },\n              children: \"                  output_names\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"[\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#98C379\"\n              },\n              children: \"output\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"], \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 输出名\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#C6CCD7\"\n              },\n              children: \"                  dynamic_axes\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"{\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#98C379\"\n              },\n              children: \"input\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \": {\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#56B6C2\"\n              },\n              children: \"0\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \": \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#98C379\"\n              },\n              children: \"batch_size\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"},  \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 动态轴\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"                                '\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#98C379\"\n              },\n              children: \"output\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \": {\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#56B6C2\"\n              },\n              children: \"0\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \": \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#98C379\"\n              },\n              children: \"batch_size\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"}})\"\n            })]\n          })]\n        })\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"在运行这段代码之前，请确保：\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"你的环境中已经安装了 PyTorch 和 onnx。\"\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"你已经根据你的模型结构正确地定义了 \", _jsx(_components.span, {\n          \"data-rehype-pretty-code-figure\": \"\",\n          children: _jsx(_components.code, {\n            \"data-language\": \"plaintext\",\n            \"data-theme\": \"plastic\",\n            children: _jsx(_components.span, {\n              \"data-line\": \"\",\n              children: _jsx(_components.span, {\n                children: \"MyModel\"\n              })\n            })\n          })\n        }), \" 类。\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"你已经根据你的模型输入尺寸正确地设置了 \", _jsx(_components.span, {\n          \"data-rehype-pretty-code-figure\": \"\",\n          children: _jsx(_components.code, {\n            \"data-language\": \"plaintext\",\n            \"data-theme\": \"plastic\",\n            children: _jsx(_components.span, {\n              \"data-line\": \"\",\n              children: _jsx(_components.span, {\n                children: \"input_sample\"\n              })\n            })\n          })\n        }), \"。\\n运行上述代码后，你应该会在当前目录下得到一个名为 \", _jsx(_components.span, {\n          \"data-rehype-pretty-code-figure\": \"\",\n          children: _jsx(_components.code, {\n            \"data-language\": \"plaintext\",\n            \"data-theme\": \"plastic\",\n            children: _jsx(_components.span, {\n              \"data-line\": \"\",\n              children: _jsx(_components.span, {\n                children: \"model.onnx\"\n              })\n            })\n          })\n        }), \" 的文件，这就是转换后的 ONNX 格式的模型。\"]\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      id: \"我没有对应的-pytorch-模型定义我要如何获得\",\n      children: _jsx(_components.a, {\n        href: \"#我没有对应的-pytorch-模型定义我要如何获得\",\n        children: \"我没有对应的 PyTorch 模型定义。我要如何获得？\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"如果你没有模型的 PyTorch 定义，但你有一个 \", _jsx(_components.span, {\n        \"data-rehype-pretty-code-figure\": \"\",\n        children: _jsx(_components.code, {\n          \"data-language\": \"plaintext\",\n          \"data-theme\": \"plastic\",\n          children: _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              children: \".pth\"\n            })\n          })\n        })\n      }), \" 文件，你可以尝试以下几种方法来获取或重建模型的结构：\"]\n    }), \"\\n\", _jsx(_components.h3, {\n      id: \"1-使用-pytorch-的-torchjitload\",\n      children: _jsxs(_components.a, {\n        href: \"#1-使用-pytorch-的-torchjitload\",\n        children: [\"1. 使用 PyTorch 的 \", _jsx(_components.span, {\n          \"data-rehype-pretty-code-figure\": \"\",\n          children: _jsx(_components.code, {\n            \"data-language\": \"plaintext\",\n            \"data-theme\": \"plastic\",\n            children: _jsx(_components.span, {\n              \"data-line\": \"\",\n              children: _jsx(_components.span, {\n                children: \"torch.jit.load\"\n              })\n            })\n          })\n        })]\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"如果你的 \", _jsx(_components.span, {\n        \"data-rehype-pretty-code-figure\": \"\",\n        children: _jsx(_components.code, {\n          \"data-language\": \"plaintext\",\n          \"data-theme\": \"plastic\",\n          children: _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              children: \".pth\"\n            })\n          })\n        })\n      }), \" 文件是一个 JIT traced 的模型，你可以使用 \", _jsx(_components.span, {\n        \"data-rehype-pretty-code-figure\": \"\",\n        children: _jsx(_components.code, {\n          \"data-language\": \"plaintext\",\n          \"data-theme\": \"plastic\",\n          children: _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              children: \"torch.jit.load\"\n            })\n          })\n        })\n      }), \" 来加载它，这样就不需要原始的模型定义。\"]\n    }), \"\\n\", _jsx(_components.figure, {\n      \"data-rehype-pretty-code-figure\": \"\",\n      children: _jsx(_components.pre, {\n        tabIndex: \"0\",\n        \"data-language\": \"python\",\n        \"data-theme\": \"plastic\",\n        children: _jsxs(_components.code, {\n          \"data-language\": \"python\",\n          \"data-theme\": \"plastic\",\n          style: {\n            display: \"grid\"\n          },\n          children: [_jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"import\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \" torch\"\n            })]\n          }), \"\\n\", _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 加载JIT traced模型\"\n            })\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"traced_model \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \" torch.jit.load(\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#98C379\"\n              },\n              children: \"001.pth\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \")\"\n            })]\n          }), \"\\n\", _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 使用模型（例如进行推理）\"\n            })\n          }), \"\\n\", _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# input_sample = ...  # 创建一个符合模型输入尺寸的示例输入\"\n            })\n          }), \"\\n\", _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# output = traced_model(input_sample)\"\n            })\n          })]\n        })\n      })\n    }), \"\\n\", _jsx(_components.h3, {\n      id: \"2-查找模型的文档或代码\",\n      children: _jsx(_components.a, {\n        href: \"#2-查找模型的文档或代码\",\n        children: \"2. 查找模型的文档或代码\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"如果模型是从某个知名的代码库或论文中获得的，你可以尝试查找原始的模型定义代码。通常，论文的附录或代码库的 README 文件会包含模型的定义。\"\n    }), \"\\n\", _jsx(_components.h3, {\n      id: \"3-使用第三方库\",\n      children: _jsx(_components.a, {\n        href: \"#3-使用第三方库\",\n        children: \"3. 使用第三方库\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"有些第三方库可能提供了预定义的模型结构，你可以尝试使用这些库来加载模型。\\n例如，如果你有一个在 torchvision 中定义的模型，你可以这样做：\"\n    }), \"\\n\", _jsx(_components.figure, {\n      \"data-rehype-pretty-code-figure\": \"\",\n      children: _jsx(_components.pre, {\n        tabIndex: \"0\",\n        \"data-language\": \"python\",\n        \"data-theme\": \"plastic\",\n        children: _jsxs(_components.code, {\n          \"data-language\": \"python\",\n          \"data-theme\": \"plastic\",\n          style: {\n            display: \"grid\"\n          },\n          children: [_jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"import\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \" torch\"\n            })]\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"import\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \" torchvision.models \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"as\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \" models\"\n            })]\n          }), \"\\n\", _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 假设你知道模型是 torchvision 中的某个模型\"\n            })\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"model \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \" models.resnet50(\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#C6CCD7\"\n              },\n              children: \"pretrained\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#56B6C2\"\n              },\n              children: \"False\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \")\"\n            })]\n          }), \"\\n\", _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 加载权重\"\n            })\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"model.load_state_dict(torch.load(\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#98C379\"\n              },\n              children: \"001.pth\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"))\"\n            })]\n          })]\n        })\n      })\n    }), \"\\n\", _jsx(_components.h3, {\n      id: \"4-反序列化状态字典\",\n      children: _jsx(_components.a, {\n        href: \"#4-反序列化状态字典\",\n        children: \"4. 反序列化状态字典\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"如果你只是丢失了模型定义，但你有状态字典，你可以尝试反序列化状态字典来重建模型结构。\"\n    }), \"\\n\", _jsx(_components.figure, {\n      \"data-rehype-pretty-code-figure\": \"\",\n      children: _jsx(_components.pre, {\n        tabIndex: \"0\",\n        \"data-language\": \"python\",\n        \"data-theme\": \"plastic\",\n        children: _jsxs(_components.code, {\n          \"data-language\": \"python\",\n          \"data-theme\": \"plastic\",\n          style: {\n            display: \"grid\"\n          },\n          children: [_jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"import\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \" torch\"\n            })]\n          }), \"\\n\", _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 加载状态字典\"\n            })\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"state_dict \"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#E06C75\"\n              },\n              children: \"=\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \" torch.load(\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#98C379\"\n              },\n              children: \"001.pth\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \"'\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#A9B2C3\"\n              },\n              children: \")\"\n            })]\n          }), \"\\n\", _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 假设你知道模型结构，可以创建一个空的模型实例，然后加载状态字典\"\n            })\n          }), \"\\n\", _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# model = ...  # 创建模型实例\"\n            })\n          }), \"\\n\", _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# model.load_state_dict(state_dict)\"\n            })\n          })]\n        })\n      })\n    }), \"\\n\", _jsx(_components.h3, {\n      id: \"5-使用模型架构搜索工具\",\n      children: _jsx(_components.a, {\n        href: \"#5-使用模型架构搜索工具\",\n        children: \"5. 使用模型架构搜索工具\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"有一些工具和库可以帮助你根据权重文件推断出模型结构。例如，\", _jsx(_components.span, {\n        \"data-rehype-pretty-code-figure\": \"\",\n        children: _jsx(_components.code, {\n          \"data-language\": \"plaintext\",\n          \"data-theme\": \"plastic\",\n          children: _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              children: \"netron\"\n            })\n          })\n        })\n      }), \" 是一个可视化神经网络工具，可以显示 \", _jsx(_components.span, {\n        \"data-rehype-pretty-code-figure\": \"\",\n        children: _jsx(_components.code, {\n          \"data-language\": \"plaintext\",\n          \"data-theme\": \"plastic\",\n          children: _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              children: \".pth\"\n            })\n          })\n        })\n      }), \" 文件中的模型结构。\"]\n    }), \"\\n\", _jsx(_components.figure, {\n      \"data-rehype-pretty-code-figure\": \"\",\n      children: _jsx(_components.pre, {\n        tabIndex: \"0\",\n        \"data-language\": \"bash\",\n        \"data-theme\": \"plastic\",\n        children: _jsxs(_components.code, {\n          \"data-language\": \"bash\",\n          \"data-theme\": \"plastic\",\n          style: {\n            display: \"grid\"\n          },\n          children: [_jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 安装 netron\"\n            })\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#B57EDC\"\n              },\n              children: \"pip\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#98C379\"\n              },\n              children: \" install\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#98C379\"\n              },\n              children: \" netron\"\n            })]\n          }), \"\\n\", _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              style: {\n                color: \"#5F6672\",\n                fontStyle: \"italic\"\n              },\n              children: \"# 使用 netron 可视化模型\"\n            })\n          }), \"\\n\", _jsxs(_components.span, {\n            \"data-line\": \"\",\n            children: [_jsx(_components.span, {\n              style: {\n                color: \"#B57EDC\"\n              },\n              children: \"netron\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#98C379\"\n              },\n              children: \" start\"\n            }), _jsx(_components.span, {\n              style: {\n                color: \"#98C379\"\n              },\n              children: \" 001.pth\"\n            })]\n          })]\n        })\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"通过这些方法，你应该能够找到或重建模型的结构。一旦你有了模型定义，你可以使用前面提供的代码示例来将 \", _jsx(_components.span, {\n        \"data-rehype-pretty-code-figure\": \"\",\n        children: _jsx(_components.code, {\n          \"data-language\": \"plaintext\",\n          \"data-theme\": \"plastic\",\n          children: _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              children: \".pth\"\n            })\n          })\n        })\n      }), \" 文件转换为 \", _jsx(_components.span, {\n        \"data-rehype-pretty-code-figure\": \"\",\n        children: _jsx(_components.code, {\n          \"data-language\": \"plaintext\",\n          \"data-theme\": \"plastic\",\n          children: _jsx(_components.span, {\n            \"data-line\": \"\",\n            children: _jsx(_components.span, {\n              children: \".onnx\"\n            })\n          })\n        })\n      }), \" 格式。如果你无法确定模型结构，你可能需要联系模型的原始作者或查找相关的文档来获取模型定义。\"]\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = {\n    ..._provideComponents(),\n    ...props.components\n  };\n  return MDXLayout ? _jsx(MDXLayout, {\n    ...props,\n    children: _jsx(_createMdxContent, {\n      ...props\n    })\n  }) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}},"capturedResult":{"trees":[{"key":"pytorch-保存的-pth-文件里都保存了些什么东西","href":"#pytorch-保存的-pth-文件里都保存了些什么东西","heading":2,"title":"pytorch 保存的 .pth 文件里都保存了些什么东西？","children":[],"id":"pytorch-保存的-pth-文件里都保存了些什么东西"},{"key":"safetensor-文件中又保存了什么东西","href":"#safetensor-文件中又保存了什么东西","heading":2,"title":".safetensor 文件中又保存了什么东西？","children":[],"id":"safetensor-文件中又保存了什么东西"},{"key":"onnx-文件中又保存了什么信息","href":"#onnx-文件中又保存了什么信息","heading":2,"title":".onnx 文件中又保存了什么信息？","children":[],"id":"onnx-文件中又保存了什么信息"},{"key":"简述-pth--safetensor--onnx-保存的信息中有哪些是相同的有哪些有区别","href":"#简述-pth--safetensor--onnx-保存的信息中有哪些是相同的有哪些有区别","heading":2,"title":"简述 .pth ， .safetensor ， .onnx 保存的信息中，有哪些是相同的？有哪些有区别？","children":[],"id":"简述-pth--safetensor--onnx-保存的信息中有哪些是相同的有哪些有区别"},{"key":"简述-pth--safetensor--onnx-保存的信息中有哪些是相同的保存的信息中又有哪些有区别","href":"#简述-pth--safetensor--onnx-保存的信息中有哪些是相同的保存的信息中又有哪些有区别","heading":2,"title":"简述 .pth ， .safetensor ， .onnx 保存的信息中有哪些是相同的？保存的信息中又有哪些有区别？","children":[],"id":"简述-pth--safetensor--onnx-保存的信息中有哪些是相同的保存的信息中又有哪些有区别"},{"key":"pth--safetensor--onnx-三种格式各自能否用于模型的-finetunning-为什么","href":"#pth--safetensor--onnx-三种格式各自能否用于模型的-finetunning-为什么","heading":2,"title":".pth ， .safetensor ， .onnx 三种格式，各自能否用于模型的 finetunning ？为什么？","children":[],"id":"pth--safetensor--onnx-三种格式各自能否用于模型的-finetunning-为什么"},{"key":"pth--safetensor--onnx-三种格式各自能否用于训练-lora-为什么","href":"#pth--safetensor--onnx-三种格式各自能否用于训练-lora-为什么","heading":2,"title":".pth ， .safetensor ， .onnx 三种格式，各自能否用于训练 LoRA ？为什么？","children":[],"id":"pth--safetensor--onnx-三种格式各自能否用于训练-lora-为什么"},{"key":"pth--safetensor--onnx-三种格式如何两两转换","href":"#pth--safetensor--onnx-三种格式如何两两转换","heading":2,"title":"pth ， safetensor ， onnx ，三种格式如何两两转换？","children":[{"key":"pth-到-safetensor-的转换","href":"#pth-到-safetensor-的转换","heading":3,"title":".pth 到 .safetensor 的转换","children":[],"id":"pth-到-safetensor-的转换"},{"key":"safetensor-到-pth-的转换","href":"#safetensor-到-pth-的转换","heading":3,"title":".safetensor 到 .pth 的转换","children":[],"id":"safetensor-到-pth-的转换"},{"key":"pth-到-onnx-的转换","href":"#pth-到-onnx-的转换","heading":3,"title":".pth 到 .onnx 的转换","children":[],"id":"pth-到-onnx-的转换"},{"key":"onnx-到-pth-的转换","href":"#onnx-到-pth-的转换","heading":3,"title":".onnx 到 .pth 的转换","children":[],"id":"onnx-到-pth-的转换"},{"key":"safetensor-到-onnx-的转换","href":"#safetensor-到-onnx-的转换","heading":3,"title":".safetensor 到 .onnx 的转换","children":[],"id":"safetensor-到-onnx-的转换"},{"key":"onnx-到-safetensor-的转换","href":"#onnx-到-safetensor-的转换","heading":3,"title":".onnx 到 .safetensor 的转换","children":[],"id":"onnx-到-safetensor-的转换"}],"id":"pth--safetensor--onnx-三种格式如何两两转换"},{"key":"我有一个从网络上下载的-pth-文件-001pth-给我-python-代码将其转换为-onnx-格式","href":"#我有一个从网络上下载的-pth-文件-001pth-给我-python-代码将其转换为-onnx-格式","heading":2,"title":"我有一个从网络上下载的 .pth 文件 001.pth 。给我 Python 代码，将其转换为 onnx 格式。","children":[],"id":"我有一个从网络上下载的-pth-文件-001pth-给我-python-代码将其转换为-onnx-格式"},{"key":"我没有对应的-pytorch-模型定义我要如何获得","href":"#我没有对应的-pytorch-模型定义我要如何获得","heading":2,"title":"我没有对应的 PyTorch 模型定义。我要如何获得？","children":[{"key":"1-使用-pytorch-的-torchjitload","href":"#1-使用-pytorch-的-torchjitload","heading":3,"title":"1. 使用 PyTorch 的 torch.jit.load","children":[],"id":"1-使用-pytorch-的-torchjitload"},{"key":"2-查找模型的文档或代码","href":"#2-查找模型的文档或代码","heading":3,"title":"2. 查找模型的文档或代码","children":[],"id":"2-查找模型的文档或代码"},{"key":"3-使用第三方库","href":"#3-使用第三方库","heading":3,"title":"3. 使用第三方库","children":[],"id":"3-使用第三方库"},{"key":"4-反序列化状态字典","href":"#4-反序列化状态字典","heading":3,"title":"4. 反序列化状态字典","children":[],"id":"4-反序列化状态字典"},{"key":"5-使用模型架构搜索工具","href":"#5-使用模型架构搜索工具","heading":3,"title":"5. 使用模型架构搜索工具","children":[],"id":"5-使用模型架构搜索工具"}],"id":"我没有对应的-pytorch-模型定义我要如何获得"}]},"meta":{"content":"\n\u003e 本页面介绍了三种机器学习模型文件格式：.pth、.safetensor 和 .onnx。主要内容包括每种格式的定义、保存的内容、用途以及它们之间的区别和转换方法。\n\n## pytorch 保存的 .pth 文件里都保存了些什么东西？\n\nPyTorch 中的`.pth`文件通常用于保存模型的权重（parameters）和训练过程中的优化器状态（optimizer state）。具体来说，一个`.pth`文件可能包含以下内容：\n\n1. **模型状态字典（Model state dictionary）**：\n   - 这是`.pth`文件中最主要的部分，它包含了模型的所有权重（即神经网络的参数），包括卷积层的滤波器、全连接层的权重和偏置等。\n   - 状态字典是一个简单的 Python 字典对象，其键是层的名字，值是相应的参数张量。\n2. **优化器状态字典（Optimizer state dictionary）**：\n   - 当保存模型时，通常也会保存优化器的状态，这样可以在模型训练中断后，从上次停止的地方继续训练。\n   - 优化器状态字典通常包含每个参数的梯度、动量（momentum）和其他与优化器相关的状态信息（例如 Adam 优化器的矩估计）。\n3. **其他可选信息**：\n   - 有时候，`.pth`文件可能还会包含其他辅助信息，比如训练的损失值、额外的元数据或者批处理大小等，但这些信息不是必须的。\n     以下是一个简单的例子，展示如何在 PyTorch 中保存和加载`.pth`文件：\n\n```python\n# 保存模型和优化器状态\ntorch.save({\n    'epoch': epoch,\n    'model_state_dict': model.state_dict(),\n    'optimizer_state_dict': optimizer.state_dict(),\n    'loss': loss,\n    ...\n}, 'model.pth')\n# 加载模型和优化器状态\ncheckpoint = torch.load('model.pth')\nmodel.load_state_dict(checkpoint['model_state_dict'])\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\nepoch = checkpoint['epoch']\nloss = checkpoint['loss']\n...\n```\n\n在这个例子中，`model`是你要保存的模型对象，`optimizer`是训练该模型使用的优化器。通过`torch.save`函数，你可以将模型的状态字典和优化器的状态字典保存到文件中。之后，可以使用`torch.load`函数来恢复这些状态，以便继续训练或者进行推理。\n\n## .safetensor 文件中又保存了什么东西？\n\n`.safetensor` 文件格式是由 Hugging Face 的 Safety Checker 工具引入的，它是为了在模型推理时提供一个额外的安全层。`.safetensor` 文件中保存的内容主要包括：\n\n1. **模型权重**：\n   - 这是最核心的部分，与 PyTorch 的 `.pth` 文件类似，`.safetensor` 文件也保存了模型的权重，即神经网络中的参数。\n2. **元数据**：\n   - `.safetensor` 文件包含了一些元数据，这些数据描述了模型的架构、权重形状、数据类型等信息，这样可以在加载模型时进行验证和适配。\n3. **安全性信息**：\n   - `.safetensor` 文件可能会包含与模型安全性相关的信息，例如哪些层或参数可能需要特别的安全检查，以及可能的阈值设置等。\n     具体来说，`.safetensor` 文件的内容结构可能如下：\n\n- `weights`: 包含模型权重的字典，通常是以张量的形式存储。\n- `metadata`: 包含模型的元数据，如版本号、架构信息等。\n- `config`: 包含模型配置信息，如模型类型、类名等。\n- `safety`: 包含模型安全性相关的信息。\n  使用 `.safetensor` 文件的目的之一是为了确保在模型部署时能够进行有效的安全检查，特别是在处理生成型模型（如文本生成、图像生成等）时，可以防止生成不适当的内容。\n  请注意，`.safetensor` 文件格式并不是 PyTorch 的标准保存格式，而是 Hugging Face 的特定实现。因此，它可能不如 `.pth` 文件那样被广泛使用。如果你在使用 Hugging Face 的模型和工具，可能会遇到 `.safetensor` 文件。在使用时，需要确保你的环境支持这种格式。\n\n## .onnx 文件中又保存了什么信息？\n\n`.onnx`（Open Neural Network Exchange）文件是一个开放格式，用于表示机器学习模型。它旨在提供一种标准的方式来表示深度学习模型，使得模型可以在不同的框架和工具之间进行转换和互操作。一个`.onnx`文件中通常包含以下信息：\n\n1. **模型图（Model Graph）**：\n   - 模型图定义了模型的计算流程，它由节点（nodes）和边（edges）组成。\n   - 节点代表计算操作，如卷积、矩阵乘法、激活函数等。\n   - 边代表节点之间的数据流，即张量（tensors）的流动。\n2. **初始值（Initializers）**：\n   - 初始值包含了模型的权重、偏置等参数的值。\n   - 这些参数是在模型图执行之前就已经确定的。\n3. **模型属性（Attributes）**：\n   - 每个节点可能有与之关联的属性，这些属性定义了节点的具体行为，例如卷积操作中的步长（stride）和填充（padding）。\n4. **输入和输出（Inputs and Outputs）**：\n   - 定义了模型的输入和输出张量的名称、数据类型和形状。\n   - 这有助于理解模型期望的输入格式以及它将产生的输出格式。\n5. **元数据（Metadata）**：\n   - 包括模型的名称、版本、作者、生产日期等信息。\n   - 这些信息有助于模型的追踪和管理。\n6. **优化信息（Optimization Information）**（可选）：\n   - 一些`.onnx`文件可能包含用于优化模型执行的额外信息，如融合操作或特定硬件上的优化指令。\n     `.onnx`文件的结构大致如下：\n\n- `ir_version`: ONNX 格式的版本号。\n- `opset_import`: 模型使用的操作集版本。\n- `producer_name`: 生成该 ONNX 模型的工具或库的名称。\n- `producer_version`: 生成该 ONNX 模型的工具或库的版本。\n- `graph`: 包含模型图的结构和属性。\n  - `node`: 计算节点列表。\n  - `input`: 输入列表。\n  - `output`: 输出列表。\n  - `initializer`: 初始化参数列表。\n  - `value_info`: 提供额外的张量信息。\n    使用`.onnx`文件，可以轻松地将模型从 PyTorch、TensorFlow、Caffe2 等框架转换到 ONNX 格式，然后再部署到不同的推理引擎或硬件平台上，例如使用 ONNX Runtime 进行推理。这种格式提高了模型的便携性和互操作性。\n\n## 简述 .pth ， .safetensor ， .onnx 保存的信息中，有哪些是相同的？有哪些有区别？\n\n.pth, .safetensor, 和 .onnx 文件格式都用于保存机器学习模型的相关信息，但它们的设计目的、兼容性和包含的具体内容有所不同。以下是它们之间相同点和区别的概述：\n**相同点：**\n\n1. **模型参数/权重**：\n   - 所有三种格式都保存了模型的参数或权重，这些是训练过程中学习到的数值，对于模型的预测能力至关重要。\n2. **元数据**：\n   - 它们都可能包含一些元数据，如模型的版本、创建日期或其他描述性信息，尽管具体的元数据内容和格式可能有所不同。\n     **区别：**\n3. **格式和兼容性**：\n   - `.pth` 是 PyTorch 的原生格式，专门用于保存和加载 PyTorch 模型的状态字典，包括模型权重和优化器状态。\n   - `.safetensor` 是 Hugging Face 的 Safety Checker 工具使用的格式，除了模型权重，还包含了安全性相关的信息。\n   - `.onnx` 是一个开放的、跨框架的格式，用于在不同的深度学习框架之间交换模型，不仅包含模型结构和参数，还定义了模型计算图。\n4. **包含内容**：\n   - `.pth` 文件通常包含模型的状态字典和优化器的状态字典，以及可选的其他训练信息（如损失值、迭代次数等）。\n   - `.safetensor` 文件包含模型权重、元数据以及与模型安全性相关的信息。\n   - `.onnx` 文件包含模型计算图、节点定义、边的连接、初始值（模型权重）、输入输出定义以及可选的优化信息。\n5. **使用场景**：\n   - `.pth` 文件主要用于 PyTorch 模型的训练和推理。\n   - `.safetensor` 文件用于在 Hugging Face 的生态系统中进行模型的安全检查。\n   - `.onnx` 文件用于模型在不同框架之间的转换和部署，特别是在需要跨平台或硬件优化的场景中。\n6. **开放性和互操作性**：\n   - `.onnx` 格式的设计重点在于开放性和互操作性，使其成为不同框架和工具之间模型交换的桥梁。\n   - `.pth` 和 `.safetensor` 更专注于特定框架或工具链内的使用。\n     总结来说，这三种格式都用于保存模型权重，但它们在格式兼容性、包含的额外信息和使用场景上存在明显差异。`.onnx` 格式更加开放和通用，而 `.pth` 和 `.safetensor` 更专注于特定的框架或应用需求。\n\n## 简述 .pth ， .safetensor ， .onnx 保存的信息中有哪些是相同的？保存的信息中又有哪些有区别？\n\n.pth、.safetensor 和.onnx 文件格式虽然都是为了保存机器学习模型的相关信息，但它们在保存的内容上存在相同点和差异。\n**相同点：**\n\n1. **模型参数/权重**：这三种文件格式都会保存模型的参数或权重，这些权重是模型在训练过程中学习到的，对模型的预测能力至关重要。\n2. **元数据**：它们都可能包含一些元数据，例如模型的版本、创建日期或其他描述性信息，尽管具体的元数据和格式可能因文件格式而异。\n   **区别：**\n3. **格式和兼容性**：\n   - .pth 文件是 PyTorch 的原生格式，主要用于保存和加载 PyTorch 模型的状态字典，包括模型权重和优化器状态。\n   - .safetensor 文件是 Hugging Face 的 Safety Checker 工具使用的格式，除了模型权重，还包括安全性相关的信息。\n   - .onnx 文件是一种开放的、跨框架的格式，用于在不同深度学习框架之间交换模型，包含模型结构和参数以及模型计算图。\n4. **包含内容**：\n   - .pth 文件通常包含模型的状态字典和优化器的状态字典，可能还包括其他训练信息，如损失值、迭代次数等。\n   - .safetensor 文件包含模型权重、元数据以及与模型安全性相关的信息。\n   - .onnx 文件包含模型计算图、节点定义、边的连接、初始值（模型权重）、输入输出定义以及可选的优化信息。\n5. **使用场景**：\n   - .pth 文件主要用于 PyTorch 模型的训练和推理。\n   - .safetensor 文件用于 Hugging Face 生态系统中的模型安全检查。\n   - .onnx 文件用于模型在不同框架之间的转换和部署，特别是在需要跨平台或硬件优化的场景中。\n6. **开放性和互操作性**：\n   - .onnx 格式重点在于开放性和互操作性，便于不同框架和工具之间模型交换。\n   - .pth 和.safetensor 文件更专注于特定框架或工具链内的使用。\n     总结来说，这三种文件格式都保存模型权重，但在格式兼容性、包含的额外信息和使用场景上存在明显差异。.onnx 格式更开放和通用，而.pth 和.safetensor 则更专注于特定框架或应用需求。\n\n## .pth ， .safetensor ， .onnx 三种格式，各自能否用于模型的 finetunning ？为什么？\n\n.pth、.safetensor 和 .onnx 三种格式在模型微调（finetuning）方面的适用性各有不同，以下是各自的适用性分析：\n**.pth 格式：**\n.pth 文件可以用于模型的微调。原因如下：\n\n- .pth 文件是 PyTorch 的原生格式，它保存了模型的状态字典，包括模型的权重和可选的优化器状态。\n- 在微调过程中，可以加载 .pth 文件中的模型权重，然后根据新的数据集对模型进行进一步的训练。\n- 如果 .pth 文件中包含了优化器状态，那么可以从中断点继续训练，这对于微调过程是有帮助的。\n  **.safetensor 格式：**\n  .safetensor 文件也可以用于模型的微调，但有一些限制：\n- .safetensor 文件主要是由 Hugging Face 的 Safety Checker 工具使用的，它保存了模型权重和与安全性相关的信息。\n- 虽然这个格式主要用于安全检查，但它仍然包含了模型权重，因此理论上可以用于微调。\n- 但是，由于 .safetensor 文件格式可能不如 .pth 那样被广泛支持，因此在微调时可能需要额外的步骤来转换格式或加载权重。\n  **.onnx 格式：**\n  .onnx 文件在微调方面的适用性较低，原因如下：\n- .onnx 文件是一个开放的、跨框架的格式，它不仅包含模型权重，还定义了模型计算图。\n- 虽然 .onnx 格式支持在不同的框架之间转换模型，但它不是为了微调而设计的。计算图是固定的，不易于修改。\n- 如果需要微调 .onnx 格式的模型，通常需要先将模型转换回原始框架（如 PyTorch 或 TensorFlow），然后再进行微调。\n- 因此，直接在 .onnx 格式上进行微调通常不切实际，除非有特定的工具或库支持这种操作。\n  总结来说，.pth 格式最适合用于 PyTorch 模型的微调，因为它直接与 PyTorch 的训练和推理流程兼容。.safetensor 格式也可以用于微调，但可能需要额外的步骤来处理。而 .onnx 格式通常不直接用于微调，需要转换为其他框架格式后才能进行微调。\n\n## .pth ， .safetensor ， .onnx 三种格式，各自能否用于训练 LoRA ？为什么？\n\nLoRA（Low-Rank Adaptation）是一种用于微调大型预训练模型的技术，它通过引入低秩分解来减少微调所需的参数数量，从而减少存储和计算需求。以下是关于 .pth、.safetensor 和 .onnx 格式在训练 LoRA 时的适用性分析：\n**.pth 格式：**\n.pth 文件可以用于训练 LoRA。原因如下：\n\n- .pth 文件是 PyTorch 的原生格式，可以直接保存和加载模型的权重，包括 LoRA 引入的低秩矩阵。\n- 在训练 LoRA 时，通常需要在原始预训练模型的基础上添加额外的参数（即低秩矩阵），这些参数可以在 PyTorch 中通过自定义层或修改现有层来实现。\n- 由于 .pth 文件与 PyTorch 框架紧密集成，因此可以轻松地保存和加载 LoRA 的参数，并进行训练。\n  **.safetensor 格式：**\n  .safetensor 文件也可以用于训练 LoRA，但可能有一些限制：\n- .safetensor 文件是为了提高模型使用的安全性而设计的，它保存了模型权重和其他与安全性相关的信息。\n- 如果 LoRA 的参数被包含在 .safetensor 文件中，那么理论上可以用于训练。\n- 然而，由于 .safetensor 文件格式可能不如 .pth 那样被广泛支持，因此在训练 LoRA 时可能需要额外的步骤来处理文件格式。\n  **.onnx 格式：**\n  .onnx 文件在训练 LoRA 方面通常不适用。原因如下：\n- .onnx 文件定义了模型的计算图和权重，但它是一个静态的模型描述格式，不适合动态修改模型结构，如添加 LoRA 层。\n- LoRA 需要在预训练模型的特定层中插入低秩矩阵，这通常需要对模型结构进行修改，而 .onnx 格式不支持这种修改。\n- 如果需要使用 .onnx 文件中的模型来训练 LoRA，通常需要先将模型转换回 PyTorch 或其他支持动态图修改的框架，然后再进行训练。\n  总结来说，.pth 格式最适合用于训练 LoRA，因为它与 PyTorch 框架紧密集成，支持动态图和自定义层的添加。.safetensor 格式在理论上也是可行的，但可能需要额外的处理步骤。而 .onnx 格式由于不支持动态修改模型结构，因此不适合直接用于训练 LoRA。\n\n## pth ， safetensor ， onnx ，三种格式如何两两转换？\n\n.pth、.safetensor 和 .onnx 文件格式之间的转换通常需要通过特定的工具和库来实现。以下是如何在这三种格式之间进行两两转换的概述：\n\n### .pth 到 .safetensor 的转换\n\n目前，并没有直接的标准工具来将 .pth 文件转换为 .safetensor 文件。但是，可以手动加载 .pth 文件中的权重，并将其保存为 .safetensor 格式。以下是一个示例步骤：\n\n1. 使用 PyTorch 加载 .pth 文件。\n2. 提取模型权重。\n3. 使用 Hugging Face 的 `transformers` 库或其他相关工具将权重保存为 .safetensor 文件。\n\n### .safetensor 到 .pth 的转换\n\n同样地，将 .safetensor 文件转换为 .pth 文件也没有直接的转换工具。以下是手动转换的步骤：\n\n1. 使用 Hugging Face 的 `transformers` 库或其他相关工具加载 .safetensor 文件。\n2. 提取模型权重。\n3. 使用 PyTorch 将权重保存为 .pth 文件。\n\n### .pth 到 .onnx 的转换\n\nPyTorch 提供了直接将模型转换为 .onnx 格式的工具：\n\n```python\nimport torch\nimport torch.onnx\n# 假设 model 是一个 PyTorch 模型\nmodel = ...  # 加载或定义模型\n# 假设输入是一个张量，其形状与模型输入兼容\ninput_sample = torch.randn(batch_size, channels, height, width)\n# 将模型转换为 ONNX 格式\ntorch.onnx.export(model,               # 模型\n                  input_sample,        # 模型输入（或一个包含输入的元组）\n                  \"model.onnx\",       # 输出文件名\n                  export_params=True,  # 是否导出参数\n                  opset_version=10,    # ONNX 算子集版本\n                  do_constant_folding=True,  # 是否执行常量折叠优化\n                  input_names=['input'],   # 输入名\n                  output_names=['output'], # 输出名\n                  dynamic_axes={'input': {0: 'batch_size'},  # 动态轴\n                                'output': {0: 'batch_size'}})\n```\n\n### .onnx 到 .pth 的转换\n\n将 .onnx 文件转换为 .pth 文件通常不直接进行，因为 .onnx 文件包含了模型的结构信息，而 .pth 文件只包含权重。如果需要，可以重新创建 PyTorch 模型结构，然后加载 .onnx 文件中的权重：\n\n1. 定义与 .onnx 文件对应的 PyTorch 模型结构。\n2. 使用 `onnx.load` 加载 .onnx 文件。\n3. 提取权重并将其加载到 PyTorch 模型中。\n\n### .safetensor 到 .onnx 的转换\n\n目前没有直接的方法将 .safetensor 文件转换为 .onnx 文件。如果需要，可以先将 .safetensor 文件转换为 .pth 文件，然后再按照上述方法将 .pth 文件转换为 .onnx 文件。\n\n### .onnx 到 .safetensor 的转换\n\n同样地，将 .onnx 文件转换为 .safetensor 文件也没有直接的转换工具。如果需要，可以先将 .onnx 文件转换为 .pth 文件，然后再将 .pth 文件转换为 .safetensor 文件。\n在进行这些转换时，需要注意的是，转换过程中可能会丢失一些特定的信息，如优化器状态或模型配置，因此在转换后可能需要额外的步骤来确保模型的完整性和正确性。\n\n## 我有一个从网络上下载的 .pth 文件 `001.pth` 。给我 Python 代码，将其转换为 onnx 格式。\n\n要将一个 `.pth` 文件转换为 `.onnx` 格式，你需要首先加载 `.pth` 文件中的模型，然后使用 PyTorch 的 `torch.onnx.export` 函数来进行转换。以下是一个 Python 代码示例，展示了如何进行这一转换过程。假设你已经有了对应的 PyTorch 模型定义，并且 `.pth` 文件中包含的是该模型的权重。\n请注意，以下代码假设你的模型是一个标准的 PyTorch 模型，并且你知道模型的输入尺 ��。你需要根据你的模型实际情况来调整输入尺寸和模型结构。\n\n```python\nimport torch\nimport torch.onnx\n# 假设模型结构和输入尺寸已知\n# 这里是示例模型结构和输入尺寸，你需要根据你的模型进行修改\nclass MyModel(torch.nn.Module):\n    def __init__(self):\n        super(MyModel, self).__init__()\n        # 定义模型结构\n        self.conv1 = torch.nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n        self.relu = torch.nn.ReLU()\n        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        # ... 添加更多层 ...\n    def forward(self, x):\n        # 定义前向传播\n        x = self.conv1(x)\n        x = self.relu(x)\n        x = self.pool(x)\n        # ... 应用更多层 ...\n        return x\n# 创建模型实例\nmodel = MyModel()\n# 加载.pth文件中的权重\nmodel.load_state_dict(torch.load('001.pth'))\n# 设置模型为评估模式（如果适用）\nmodel.eval()\n# 创建一个符合模型输入尺寸的示例输入\n# 假设输入是单张图片，通道数为3，高和宽分别为224和224\n# 你需要根据你的模型调整输入尺寸\ninput_sample = torch.randn(1, 3, 224, 224)\n# 指定ONNX模型的输出文件名\noutput_file = 'model.onnx'\n# 导出模型为ONNX格式\ntorch.onnx.export(model,               # 模型\n                  input_sample,        # 模型输入（或一个包含输入的元组）\n                  output_file,         # 输出文件名\n                  export_params=True,  # 是否导出参数\n                  opset_version=10,    # ONNX 算子集版本\n                  do_constant_folding=True,  # 是否执行常量折叠优化\n                  input_names=['input'],   # 输入名\n                  output_names=['output'], # 输出名\n                  dynamic_axes={'input': {0: 'batch_size'},  # 动态轴\n                                'output': {0: 'batch_size'}})\n```\n\n在运行这段代码之前，请确保：\n\n- 你的环境中已经安装了 PyTorch 和 onnx。\n- 你已经根据你的模型结构正确地定义了 `MyModel` 类。\n- 你已经根据你的模型输入尺寸正确地设置了 `input_sample`。\n  运行上述代码后，你应该会在当前目录下得到一个名为 `model.onnx` 的文件，这就是转换后的 ONNX 格式的模型。\n\n## 我没有对应的 PyTorch 模型定义。我要如何获得？\n\n如果你没有模型的 PyTorch 定义，但你有一个 `.pth` 文件，你可以尝试以下几种方法来获取或重建模型的结构：\n\n### 1. 使用 PyTorch 的 `torch.jit.load`\n\n如果你的 `.pth` 文件是一个 JIT traced 的模型，你可以使用 `torch.jit.load` 来加载它，这样就不需要原始的模型定义。\n\n```python\nimport torch\n# 加载JIT traced模型\ntraced_model = torch.jit.load('001.pth')\n# 使用模型（例如进行推理）\n# input_sample = ...  # 创建一个符合模型输入尺寸的示例输入\n# output = traced_model(input_sample)\n```\n\n### 2. 查找模型的文档或代码\n\n如果模型是从某个知名的代码库或论文中获得的，你可以尝试查找原始的模型定义代码。通常，论文的附录或代码库的 README 文件会包含模型的定义。\n\n### 3. 使用第三方库\n\n有些第三方库可能提供了预定义的模型结构，你可以尝试使用这些库来加载模型。\n例如，如果你有一个在 torchvision 中定义的模型，你可以这样做：\n\n```python\nimport torch\nimport torchvision.models as models\n# 假设你知道模型是 torchvision 中的某个模型\nmodel = models.resnet50(pretrained=False)\n# 加载权重\nmodel.load_state_dict(torch.load('001.pth'))\n```\n\n### 4. 反序列化状态字典\n\n如果你只是丢失了模型定义，但你有状态字典，你可以尝试反序列化状态字典来重建模型结构。\n\n```python\nimport torch\n# 加载状态字典\nstate_dict = torch.load('001.pth')\n# 假设你知道模型结构，可以创建一个空的模型实例，然后加载状态字典\n# model = ...  # 创建模型实例\n# model.load_state_dict(state_dict)\n```\n\n### 5. 使用模型架构搜索工具\n\n有一些工具和库可以帮助你根据权重文件推断出模型结构。例如，`netron` 是一个可视化神经网络工具，可以显示 `.pth` 文件中的模型结构。\n\n```bash\n# 安装 netron\npip install netron\n# 使用 netron 可视化模型\nnetron start 001.pth\n```\n\n通过这些方法，你应该能够找到或重建模型的结构。一旦你有了模型定义，你可以使用前面提供的代码示例来将 `.pth` 文件转换为 `.onnx` 格式。如果你无法确定模型结构，你可能需要联系模型的原始作者或查找相关的文档来获取模型定义。\n","title":"深度学习模型文件格式对比：pth、safetensor 与 onnx","abstract":"\u003e 本页面介绍了三种机器学习模型文件格式：.pth、.safetensor 和 .onnx。主要内容包括每种格式的定义、保存的内容、用途以及它们之间的区别和转换方法。\nPyTorch 中的`.pth`文件通常用于保存模型的权重（parameters）和训练过程中的优化器状态（optimizer state）。具体来说，一个`.pth`文件可能包含以下内容：\n1. **模型状态字典（Model state dictionary）**：","length":365,"created_at":"2024-11-29T02:00:00.000Z","updated_at":"2024-11-29T02:00:00.000Z","tags":["PyTorch","ONNX","深度学习","模型部署","学习笔记"],"license":true},"prevNextInfo":{"prevInfo":{"pathMapping":{"filePath":"public/content/learn_from_ai/2024-11-29-opencv-coordinate-system-conventions.md","pagePath":"/learn_from_ai/opencv-coordinate-system-conventions","slug":"opencv-coordinate-system-conventions"},"meta":{"content":"\n\u003e 📝 本文是我在学习 OpenCV 时遇到的一个问题。问题的解答和中文翻译均由 AI 生成。\n\n## OpenCV 坐标表示：理解 (y, x) 与 (x, y) 的区别\n\n## Q\n\nWhy sometimes opencv represent a point coordinate as (y,x) (e.g. the result of cv2.findContours) , and sometimes it represent as (x, y) (e.g. the arg `center` of cv2.circle)?\n\n\u003e 为什么 OpenCV 有时用 (y,x) 表示坐标点（比如 cv2.findContours 的返回值），有时又用 (x,y) 表示（比如 cv2.circle 函数的 `center` 参数）？\n\n## A\n\nOpenCV uses different conventions for different functions based on their specific requirements and historical reasons:\n\n\u003e OpenCV 基于不同函数的具体需求和历史原因，使用了不同的坐标表示约定：\n\n1. **(y, x) Convention**: This is often used when dealing with image matrices directly. In image processing, images are typically represented as 2D arrays where the first dimension is the row (height, y-coordinate) and the second dimension is the column (width, x-coordinate). Functions like `cv2.findContours` return coordinates in this order to match the array indexing.\n\n\u003e 1. **(y, x) 约定**：这种表示方法通常用于直接处理图像矩阵时。在图像处理中，图像通常表示为二维数组，其中第一维是行（高度，y 坐标），第二维是列（宽度，x 坐标）。像 `cv2.findContours` 这样的函数返回这种顺序的坐标是为了匹配数组索引方式。\n\n2. **(x, y) Convention**: This is used in functions that deal with geometric shapes or points in a more traditional Cartesian coordinate system, where `x` is the horizontal axis and `y` is the vertical axis. Functions like `cv2.circle` use this convention to specify the center of the circle.\n\n\u003e 2. **(x, y) 约定**：这种表示方法用于处理几何图形或在传统笛卡尔坐标系中的点，其中 `x` 是水平轴，`y` 是垂直轴。像 `cv2.circle` 这样的函数使用这种约定来指定圆心位置。\n\nThe inconsistency arises because OpenCV aims to balance between image matrix operations and geometric operations, each having their own conventional coordinate systems.\n\n\u003e 这种不一致性的出现是因为 OpenCV 需要在图像矩阵运算和几何运算之间取得平衡，而这两种运算各自有其传统的坐标系统表示方法。\n","title":"OpenCV 坐标表示：理解 (y, x) 与 (x, y) 的区别","abstract":"\u003e 📝 本文是我在学习 OpenCV 时遇到的一个问题。问题的解答和中文翻译均由 AI 生成。\nWhy sometimes opencv represent a point coordinate as (y,x) (e.g. the result of cv2.findContours) , and sometimes it represent as (x, y) (e.g. the arg `center` of cv2.circle)?\n\u003e 为什么 OpenCV 有时用 (y,x) 表示坐标点（比如 cv2.findContours 的返回值），有时又用 (x,y) 表示（比如 cv2.circle 函数的 `center` 参数）？","length":29,"created_at":"2024-11-29T03:00:00.000Z","updated_at":"2024-11-29T03:00:00.000Z","tags":["OpenCV","图像处理","学习笔记"],"license":true}},"nextInfo":null}},"__N_SSG":true},"page":"/learn_from_ai/[slug]","query":{"slug":"deep-learning-model-formats"},"buildId":"OwkYdUeC5nrv7JKUkxwdh","assetPrefix":"/blog-next","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>