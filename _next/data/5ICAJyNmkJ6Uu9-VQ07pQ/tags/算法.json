{"pageProps":{"allTagInfos":[{"tag":"杂技","slug":"杂技","path":"/tags/杂技","postSlugs":[{"postType":"articles","postSlug":"Building-this-blog","postPagePath":"/articles/Building-this-blog"},{"postType":"articles","postSlug":"hello-world","postPagePath":"/articles/hello-world"},{"postType":"articles","postSlug":"the-using-in-cpp","postPagePath":"/articles/the-using-in-cpp"}]},{"tag":"Blog","slug":"blog","path":"/tags/blog","postSlugs":[{"postType":"articles","postSlug":"Building-this-blog","postPagePath":"/articles/Building-this-blog"},{"postType":"articles","postSlug":"init-a-new-hexo-project","postPagePath":"/articles/init-a-new-hexo-project"},{"postType":"articles","postSlug":"create-blog-cicd-by-github","postPagePath":"/articles/create-blog-cicd-by-github"},{"postType":"articles","postSlug":"use-paste-image-and-vscode-memo","postPagePath":"/articles/use-paste-image-and-vscode-memo"},{"postType":"ideas","postSlug":"blog-in-next","postPagePath":"/ideas/blog-in-next"},{"postType":"ideas","postSlug":"blog-syntax","postPagePath":"/ideas/blog-syntax"}]},{"tag":"杂谈","slug":"杂谈","path":"/tags/杂谈","postSlugs":[{"postType":"articles","postSlug":"hello-world","postPagePath":"/articles/hello-world"},{"postType":"articles","postSlug":"try-cursor-and-thinking","postPagePath":"/articles/try-cursor-and-thinking"}]},{"tag":"C++","slug":"c++","path":"/tags/c++","postSlugs":[{"postType":"articles","postSlug":"the-using-in-cpp","postPagePath":"/articles/the-using-in-cpp"},{"postType":"learn_from_ai","postSlug":"cpp-rvo-and-rust-move-semantics","postPagePath":"/learn_from_ai/cpp-rvo-and-rust-move-semantics"}]},{"tag":"Python","slug":"python","path":"/tags/python","postSlugs":[{"postType":"articles","postSlug":"python-dict","postPagePath":"/articles/python-dict"}]},{"tag":"数据结构","slug":"数据结构","path":"/tags/数据结构","postSlugs":[{"postType":"articles","postSlug":"python-dict","postPagePath":"/articles/python-dict"},{"postType":"articles","postSlug":"Sort-algorithm","postPagePath":"/articles/Sort-algorithm"},{"postType":"articles","postSlug":"Handy-heap-cheat-sheet","postPagePath":"/articles/Handy-heap-cheat-sheet"}]},{"tag":"算法","slug":"算法","path":"/tags/算法","postSlugs":[{"postType":"articles","postSlug":"Sort-algorithm","postPagePath":"/articles/Sort-algorithm"},{"postType":"articles","postSlug":"Handy-heap-cheat-sheet","postPagePath":"/articles/Handy-heap-cheat-sheet"}]},{"tag":"排序","slug":"排序","path":"/tags/排序","postSlugs":[{"postType":"articles","postSlug":"Sort-algorithm","postPagePath":"/articles/Sort-algorithm"}]},{"tag":"算法竞赛","slug":"算法竞赛","path":"/tags/算法竞赛","postSlugs":[{"postType":"articles","postSlug":"Handy-heap-cheat-sheet","postPagePath":"/articles/Handy-heap-cheat-sheet"}]},{"tag":"设计模式","slug":"设计模式","path":"/tags/设计模式","postSlugs":[{"postType":"articles","postSlug":"The-beauty-of-design-parten","postPagePath":"/articles/The-beauty-of-design-parten"}]},{"tag":"笔记","slug":"笔记","path":"/tags/笔记","postSlugs":[{"postType":"articles","postSlug":"The-beauty-of-design-parten","postPagePath":"/articles/The-beauty-of-design-parten"}]},{"tag":"GitHub","slug":"github","path":"/tags/github","postSlugs":[{"postType":"articles","postSlug":"create-blog-cicd-by-github","postPagePath":"/articles/create-blog-cicd-by-github"}]},{"tag":"AWS","slug":"aws","path":"/tags/aws","postSlugs":[{"postType":"articles","postSlug":"create-blog-cicd-by-github","postPagePath":"/articles/create-blog-cicd-by-github"}]},{"tag":"CI/CD","slug":"ci-cd","path":"/tags/ci-cd","postSlugs":[{"postType":"articles","postSlug":"create-blog-cicd-by-github","postPagePath":"/articles/create-blog-cicd-by-github"}]},{"tag":"IaC","slug":"iac","path":"/tags/iac","postSlugs":[{"postType":"articles","postSlug":"create-blog-cicd-by-github","postPagePath":"/articles/create-blog-cicd-by-github"}]},{"tag":"DevOps","slug":"devops","path":"/tags/devops","postSlugs":[{"postType":"articles","postSlug":"create-blog-cicd-by-github","postPagePath":"/articles/create-blog-cicd-by-github"},{"postType":"articles","postSlug":"introduction-for-k8s","postPagePath":"/articles/introduction-for-k8s"},{"postType":"articles","postSlug":"introduction-for-k8s-2","postPagePath":"/articles/introduction-for-k8s-2"},{"postType":"ideas","postSlug":"newest","postPagePath":"/ideas/newest"}]},{"tag":"VSCode","slug":"vscode","path":"/tags/vscode","postSlugs":[{"postType":"articles","postSlug":"use-paste-image-and-vscode-memo","postPagePath":"/articles/use-paste-image-and-vscode-memo"}]},{"tag":"Hexo","slug":"hexo","path":"/tags/hexo","postSlugs":[{"postType":"articles","postSlug":"use-paste-image-and-vscode-memo","postPagePath":"/articles/use-paste-image-and-vscode-memo"}]},{"tag":"JavaScript","slug":"javascript","path":"/tags/javascript","postSlugs":[{"postType":"articles","postSlug":"use-paste-image-and-vscode-memo","postPagePath":"/articles/use-paste-image-and-vscode-memo"}]},{"tag":"Kubernetes","slug":"kubernetes","path":"/tags/kubernetes","postSlugs":[{"postType":"articles","postSlug":"introduction-for-k8s","postPagePath":"/articles/introduction-for-k8s"},{"postType":"articles","postSlug":"introduction-for-k8s-2","postPagePath":"/articles/introduction-for-k8s-2"},{"postType":"ideas","postSlug":"newest","postPagePath":"/ideas/newest"}]},{"tag":"Docker","slug":"docker","path":"/tags/docker","postSlugs":[{"postType":"articles","postSlug":"introduction-for-k8s","postPagePath":"/articles/introduction-for-k8s"},{"postType":"articles","postSlug":"introduction-for-k8s-2","postPagePath":"/articles/introduction-for-k8s-2"},{"postType":"ideas","postSlug":"newest","postPagePath":"/ideas/newest"}]},{"tag":"Cloud Native","slug":"cloud-native","path":"/tags/cloud-native","postSlugs":[{"postType":"articles","postSlug":"introduction-for-k8s","postPagePath":"/articles/introduction-for-k8s"},{"postType":"articles","postSlug":"introduction-for-k8s-2","postPagePath":"/articles/introduction-for-k8s-2"},{"postType":"ideas","postSlug":"newest","postPagePath":"/ideas/newest"}]},{"tag":"Cursor","slug":"cursor","path":"/tags/cursor","postSlugs":[{"postType":"articles","postSlug":"try-cursor-and-thinking","postPagePath":"/articles/try-cursor-and-thinking"}]},{"tag":"Nextjs","slug":"nextjs","path":"/tags/nextjs","postSlugs":[{"postType":"ideas","postSlug":"blog-in-next","postPagePath":"/ideas/blog-in-next"},{"postType":"ideas","postSlug":"blog-syntax","postPagePath":"/ideas/blog-syntax"}]},{"tag":"Linux","slug":"linux","path":"/tags/linux","postSlugs":[{"postType":"ideas","postSlug":"Linux Systemd","postPagePath":"/ideas/Linux Systemd"},{"postType":"ideas","postSlug":"Linux 信号处理 —— Signal","postPagePath":"/ideas/Linux 信号处理 —— Signal"},{"postType":"ideas","postSlug":"Linux 内存 —— 内存分页、分段","postPagePath":"/ideas/Linux 内存 —— 内存分页、分段"},{"postType":"ideas","postSlug":"Linux 内存 —— 堆和栈","postPagePath":"/ideas/Linux 内存 —— 堆和栈"},{"postType":"ideas","postSlug":"Linux 内存 —— 虚拟内存","postPagePath":"/ideas/Linux 内存 —— 虚拟内存"},{"postType":"ideas","postSlug":"Linux 调度 —— 进程与线程","postPagePath":"/ideas/Linux 调度 —— 进程与线程"},{"postType":"learn_from_ai","postSlug":"executable-file-formats","postPagePath":"/learn_from_ai/executable-file-formats"}]},{"tag":"systemctl","slug":"systemctl","path":"/tags/systemctl","postSlugs":[{"postType":"ideas","postSlug":"Linux Systemd","postPagePath":"/ideas/Linux Systemd"}]},{"tag":"journalctl","slug":"journalctl","path":"/tags/journalctl","postSlugs":[{"postType":"ideas","postSlug":"Linux Systemd","postPagePath":"/ideas/Linux Systemd"}]},{"tag":"timedatectl","slug":"timedatectl","path":"/tags/timedatectl","postSlugs":[{"postType":"ideas","postSlug":"Linux Systemd","postPagePath":"/ideas/Linux Systemd"}]},{"tag":"BasicKnowledge","slug":"basicknowledge","path":"/tags/basicknowledge","postSlugs":[{"postType":"ideas","postSlug":"Linux Systemd","postPagePath":"/ideas/Linux Systemd"},{"postType":"ideas","postSlug":"Linux 信号处理 —— Signal","postPagePath":"/ideas/Linux 信号处理 —— Signal"},{"postType":"ideas","postSlug":"Linux 内存 —— 内存分页、分段","postPagePath":"/ideas/Linux 内存 —— 内存分页、分段"},{"postType":"ideas","postSlug":"Linux 内存 —— 堆和栈","postPagePath":"/ideas/Linux 内存 —— 堆和栈"},{"postType":"ideas","postSlug":"Linux 内存 —— 虚拟内存","postPagePath":"/ideas/Linux 内存 —— 虚拟内存"},{"postType":"ideas","postSlug":"Linux 调度 —— 进程与线程","postPagePath":"/ideas/Linux 调度 —— 进程与线程"}]},{"tag":"Operation","slug":"operation","path":"/tags/operation","postSlugs":[{"postType":"ideas","postSlug":"Linux Systemd","postPagePath":"/ideas/Linux Systemd"},{"postType":"ideas","postSlug":"Linux 信号处理 —— Signal","postPagePath":"/ideas/Linux 信号处理 —— Signal"},{"postType":"ideas","postSlug":"Linux 内存 —— 内存分页、分段","postPagePath":"/ideas/Linux 内存 —— 内存分页、分段"},{"postType":"ideas","postSlug":"Linux 内存 —— 虚拟内存","postPagePath":"/ideas/Linux 内存 —— 虚拟内存"}]},{"tag":"Signal","slug":"signal","path":"/tags/signal","postSlugs":[{"postType":"ideas","postSlug":"Linux 信号处理 —— Signal","postPagePath":"/ideas/Linux 信号处理 —— Signal"}]},{"tag":"memory","slug":"memory","path":"/tags/memory","postSlugs":[{"postType":"ideas","postSlug":"Linux 内存 —— 内存分页、分段","postPagePath":"/ideas/Linux 内存 —— 内存分页、分段"},{"postType":"ideas","postSlug":"Linux 内存 —— 堆和栈","postPagePath":"/ideas/Linux 内存 —— 堆和栈"},{"postType":"ideas","postSlug":"Linux 内存 —— 虚拟内存","postPagePath":"/ideas/Linux 内存 —— 虚拟内存"}]},{"tag":"schedule","slug":"schedule","path":"/tags/schedule","postSlugs":[{"postType":"ideas","postSlug":"Linux 调度 —— 进程与线程","postPagePath":"/ideas/Linux 调度 —— 进程与线程"}]},{"tag":"Cloud Computing","slug":"cloud-computing","path":"/tags/cloud-computing","postSlugs":[{"postType":"ideas","postSlug":"newest","postPagePath":"/ideas/newest"}]},{"tag":"Deep Learning","slug":"deep-learning","path":"/tags/deep-learning","postSlugs":[{"postType":"learn_from_ai","postSlug":"resnet-math-and-gradient-vanishing","postPagePath":"/learn_from_ai/resnet-math-and-gradient-vanishing"}]},{"tag":"Neural Networks","slug":"neural-networks","path":"/tags/neural-networks","postSlugs":[{"postType":"learn_from_ai","postSlug":"resnet-math-and-gradient-vanishing","postPagePath":"/learn_from_ai/resnet-math-and-gradient-vanishing"}]},{"tag":"ResNet","slug":"resnet","path":"/tags/resnet","postSlugs":[{"postType":"learn_from_ai","postSlug":"resnet-math-and-gradient-vanishing","postPagePath":"/learn_from_ai/resnet-math-and-gradient-vanishing"}]},{"tag":"Mathematics","slug":"mathematics","path":"/tags/mathematics","postSlugs":[{"postType":"learn_from_ai","postSlug":"resnet-math-and-gradient-vanishing","postPagePath":"/learn_from_ai/resnet-math-and-gradient-vanishing"}]},{"tag":"PyTorch","slug":"pytorch","path":"/tags/pytorch","postSlugs":[{"postType":"learn_from_ai","postSlug":"deep-learning-model-formats","postPagePath":"/learn_from_ai/deep-learning-model-formats"},{"postType":"learn_from_ai","postSlug":"pytorch-backpropagation-mechanism","postPagePath":"/learn_from_ai/pytorch-backpropagation-mechanism"}]},{"tag":"ONNX","slug":"onnx","path":"/tags/onnx","postSlugs":[{"postType":"learn_from_ai","postSlug":"deep-learning-model-formats","postPagePath":"/learn_from_ai/deep-learning-model-formats"}]},{"tag":"深度学习","slug":"深度学习","path":"/tags/深度学习","postSlugs":[{"postType":"learn_from_ai","postSlug":"deep-learning-model-formats","postPagePath":"/learn_from_ai/deep-learning-model-formats"},{"postType":"learn_from_ai","postSlug":"lora-matrix-initialization-strategy","postPagePath":"/learn_from_ai/lora-matrix-initialization-strategy"},{"postType":"learn_from_ai","postSlug":"pytorch-backpropagation-mechanism","postPagePath":"/learn_from_ai/pytorch-backpropagation-mechanism"}]},{"tag":"模型部署","slug":"模型部署","path":"/tags/模型部署","postSlugs":[{"postType":"learn_from_ai","postSlug":"deep-learning-model-formats","postPagePath":"/learn_from_ai/deep-learning-model-formats"}]},{"tag":"学习笔记","slug":"学习笔记","path":"/tags/学习笔记","postSlugs":[{"postType":"learn_from_ai","postSlug":"deep-learning-model-formats","postPagePath":"/learn_from_ai/deep-learning-model-formats"},{"postType":"learn_from_ai","postSlug":"opencv-coordinate-system-conventions","postPagePath":"/learn_from_ai/opencv-coordinate-system-conventions"},{"postType":"learn_from_ai","postSlug":"executable-file-formats","postPagePath":"/learn_from_ai/executable-file-formats"},{"postType":"learn_from_ai","postSlug":"lora-matrix-initialization-strategy","postPagePath":"/learn_from_ai/lora-matrix-initialization-strategy"},{"postType":"learn_from_ai","postSlug":"pytorch-backpropagation-mechanism","postPagePath":"/learn_from_ai/pytorch-backpropagation-mechanism"}]},{"tag":"OpenCV","slug":"opencv","path":"/tags/opencv","postSlugs":[{"postType":"learn_from_ai","postSlug":"opencv-coordinate-system-conventions","postPagePath":"/learn_from_ai/opencv-coordinate-system-conventions"}]},{"tag":"图像处理","slug":"图像处理","path":"/tags/图像处理","postSlugs":[{"postType":"learn_from_ai","postSlug":"opencv-coordinate-system-conventions","postPagePath":"/learn_from_ai/opencv-coordinate-system-conventions"}]},{"tag":"Rust","slug":"rust","path":"/tags/rust","postSlugs":[{"postType":"learn_from_ai","postSlug":"cpp-rvo-and-rust-move-semantics","postPagePath":"/learn_from_ai/cpp-rvo-and-rust-move-semantics"}]},{"tag":"编程语言","slug":"编程语言","path":"/tags/编程语言","postSlugs":[{"postType":"learn_from_ai","postSlug":"cpp-rvo-and-rust-move-semantics","postPagePath":"/learn_from_ai/cpp-rvo-and-rust-move-semantics"}]},{"tag":"Windows","slug":"windows","path":"/tags/windows","postSlugs":[{"postType":"learn_from_ai","postSlug":"executable-file-formats","postPagePath":"/learn_from_ai/executable-file-formats"}]},{"tag":"macOS","slug":"macos","path":"/tags/macos","postSlugs":[{"postType":"learn_from_ai","postSlug":"executable-file-formats","postPagePath":"/learn_from_ai/executable-file-formats"}]},{"tag":"可执行文件","slug":"可执行文件","path":"/tags/可执行文件","postSlugs":[{"postType":"learn_from_ai","postSlug":"executable-file-formats","postPagePath":"/learn_from_ai/executable-file-formats"}]},{"tag":"LoRA","slug":"lora","path":"/tags/lora","postSlugs":[{"postType":"learn_from_ai","postSlug":"lora-matrix-initialization-strategy","postPagePath":"/learn_from_ai/lora-matrix-initialization-strategy"}]},{"tag":"参数高效微调","slug":"参数高效微调","path":"/tags/参数高效微调","postSlugs":[{"postType":"learn_from_ai","postSlug":"lora-matrix-initialization-strategy","postPagePath":"/learn_from_ai/lora-matrix-initialization-strategy"}]},{"tag":"模型训练","slug":"模型训练","path":"/tags/模型训练","postSlugs":[{"postType":"learn_from_ai","postSlug":"lora-matrix-initialization-strategy","postPagePath":"/learn_from_ai/lora-matrix-initialization-strategy"}]},{"tag":"反向传播","slug":"反向传播","path":"/tags/反向传播","postSlugs":[{"postType":"learn_from_ai","postSlug":"pytorch-backpropagation-mechanism","postPagePath":"/learn_from_ai/pytorch-backpropagation-mechanism"}]},{"tag":"自动微分","slug":"自动微分","path":"/tags/自动微分","postSlugs":[{"postType":"learn_from_ai","postSlug":"pytorch-backpropagation-mechanism","postPagePath":"/learn_from_ai/pytorch-backpropagation-mechanism"}]}],"selectedTagInfo":{"tag":"算法","slug":"算法","path":"/tags/算法","postSlugs":[{"postType":"articles","postSlug":"Sort-algorithm","postPagePath":"/articles/Sort-algorithm"},{"postType":"articles","postSlug":"Handy-heap-cheat-sheet","postPagePath":"/articles/Handy-heap-cheat-sheet"}]},"posts":[{"pathMapping":{"filePath":"public/content/articles/2021-03-21-Handy-heap-cheat-sheet.md","pagePath":"/articles/Handy-heap-cheat-sheet","slug":"Handy-heap-cheat-sheet"},"meta":{"content":"\n# 如何手撕一个堆\n\n# 写在前面\n\n在参加如AtCoder等算法竞技，或是刷Leetcode等算法题时，我们总是不可避免地遇到堆这种数据结构。\n\n当然，一般来说我们只要理解堆，知道堆的性质，知道怎么样用堆就足够了。在做题时只需要调用系统类库即可——在参加AtCoder时你甚至不会有时间去自己实现一个堆。\n\n但是，如果哪一天你把编程语言的类库全忘光了，又遇到一题需要频繁求最值的题目——你明知这里要用堆，却又忘记该调用的类名了，咋办？我还真遇到过这问题：三年没刷算法，只能对着一道自己明显会的题干着急，愣是想不起PriorityQueue的名字。这时候，只能自己实现一个堆出来了。\n\n# 首先要理解，然后才能实现\n\n就像人总不会忘记自行车怎么骑一样，只要理解了数据结构的原理，身体就会自动来帮我们记忆，总不会忘。那要怎么理解一个堆呢？\n\n## 先抓住重点：堆是一种树结构\n\n首先最重要的，要理解堆是一种树结构。不管实际是基于数组实现还是别的什么实现，逻辑结构是树结构没变的。\n\n再进一步，在堆这种树结构中，最重要的约束就是：**对于树中的每个节点，总有父节点大于两个子节点**（以大顶堆为例，下同）。\n\n如此一来，大小关系在树中层层传递，最终可得树的根节点（堆顶）就是整个堆的最大节点，读取堆中最大值的时间复杂度为O(1)。而我们使用堆也一般是为了利用这种堆顶元素就是最大值的特点，读取、删除操作一般会限制为只允许读取、删除堆顶元素。\n\n而且我们可以注意到，与二叉查找树比起来，堆的约束十分之弱：堆只约束父节点与子节点的大小关系，而不需要管左右子树的大小关系，甚至不需要管左右两个子节点之间谁大谁小。这样一来堆就有很多很好的性质了：\n\n1. 堆并不关注左右子树之间的大小情况，那么**要维护一个堆，基本只需要做交换父节点与子节点的操作**，而不需要像二叉查找树那样做各种旋转操作。\n2. 因为维护一个堆不需要做旋转操作，那么几乎不需要花任何代价，就可以把堆的树结构维持在完全二叉树状态。因此堆的物理结构可以设计得很紧凑，**可以使用数组进行实现**。\n3. 因为堆可以维持在完全二叉树状态，那么堆的树结构的高度就可以控制为O(logn)范围内。而如上所述，要维护一个堆我们不需要关注左右子树的关系。因此我们要在堆上做增删操作，都只需要上下交换若干次父子节点。而交换次数最多时，也只是从树根一直交换到树叶，或是从树叶一直交换到树根，最多交换logn次。那么我们可得：**堆的增删操作最坏时间复杂度为O(logn)**。\n\n## 再抓基本操作：上浮与下沉\n\n上面也提到，要维护一个堆，我们只需要上下交换若干次父子节点即可。若一个节点**过大**，就跟他的父节点**向上交换**；若一个节点**过小**，就跟他的子节点**向下交换**。\n\n假设p节点过大破坏了堆结构，即p节点比其父节点g还要大，向上交换如下图：\n\n![p与g交换](/img/in-post/2021-03-21-Handly-heap-cheat-sheet/change.png)\n\n由于除了p过大破坏堆结构以外，其他节点都符合堆结构，则有：\n\n1. p > g > p2\n2. g > 原p > c1与c2\n\n则向上交换后有只有一种破坏堆结构的可能性：p节点过大，比gg节点还要大。而解决方法也很简单，就是递归地进行向上交换，最坏情况下一直交换到堆根节点为止。\n\n同理可得，p节点过小，小于他的子节点时，向下交换后有可能需要递归地向下交换，最坏情况下一直交换到叶子节点为止。要注意向下交换时需要先比较一下两个子节点的大小，再跟较大的子节点交换，才能交换后的大小关系符合堆的要求。\n\n为了简化，我们把前面那种递归地向上交换称为**上浮操作**，把后面这种递归地向下交换称为**下沉操作**。所有需要维护堆结构的操作：增、删、建堆，都可以拆分为上浮操作或是下沉操作的组合。\n\n# 各种接口的逻辑\n\n## 插入元素——入堆\n\n把一个元素p加入堆中，我们可以先把p加到堆尾，然后对p做上浮操作。\n\n虽然堆是一个树结构，但由于堆可以用数组实现，那我们只要用O(1)的时间就可以找到堆尾。而如上面所述上浮操作最多交换到根节点 。由于用数组实现的堆是完全二叉树，交换到根节点时间复杂度为O(logn)。因此我们可得入堆的最坏时间复杂度为O(logn)。\n\n## 删除堆顶元素——出堆\n\n我们从堆中删除元素时，一般只会删除堆顶元素。\n\n删除堆顶元素时，我们可以摘出堆尾元素p填到堆顶的空缺中，再对p做下沉操作。找到堆尾元素需要O(1)时间，下沉操作最多交换到叶子节点，时间复杂度为O(logn)。因此出堆最坏时间复杂度为O(logn)。\n\n这里加点餐：出堆时把堆尾元素p放到堆顶后下沉，而p原先在堆中的最下层，一般在整个堆中都算较小的元素。因此下沉p时有较大概率需要一直把p下沉到最下层或是倒数第二层，即出堆时最坏情况出现概率较高。\n\n## 堆的初始化——建堆\n\n建立一个堆，我们有两种思路：\n\n1. 将元素一个一个插入，即对每个元素都做一次入堆操作。\n2. 当节点p左子树和右子树都各自为一个堆时，只要把p下沉就可以把左右两个堆合并成一个更大的堆。即不断地进行堆合并操作。\n\n下面我们来分析这两种建堆策略。\n\n### 元素逐个入堆\n\n上面说到，入堆就是把元素加到堆尾，再做上浮操作。把元素逐个入堆，就是把元素逐个上浮。\n\n插入第i个元素时，堆的大小为$i$（在不影响计算情况下的近似，下同），则有堆的高度为，则上浮时间复杂度为：\n\n$$T(i) = logi$$\n\n那么把所有元素上浮，则总时间复杂度为：\n\n$$\n\\begin{aligned}\nT(n) &= \\sum_{i=1}^{n}logi\\\\\n&= 1\\times0 + 2\\times1 + ... + 2^{logn}\\times{logn} \\\\\n&=O(nlogn)\n\\end{aligned}\n$$\n\n通过把元素逐个入堆来建堆时，元素的时间复杂度可以用下图直观显示：\n\n![](/img/in-post/2021-03-21-Handly-heap-cheat-sheet/insert-length.png)\n\n（每条红线的长度就是插入该元素所需的时间，红线的总长度就是建堆所需的总时间复杂度）\n\n### 堆合并\n\n我们就可以从树结构的最底层出发不断进行堆合并，小堆合并成大堆，最后合并到根节点就建成整个堆结构。\n\n当节点的左右两个子树都是堆时，只需要对该节点进行下沉操作就可以合并左右两个堆。 不断进行堆合并，就是从下层开始把元素逐个下沉。\n\n下沉第i个元素（从顶到底数）时，以其为顶点的树高度约为$logn-logi$，则有下沉时间复杂度为：\n\n$$\nT(i) = logn-logi\n$$\n\n那么把所有元素下沉，则总时间复杂度为：\n\n$$\n\\begin{aligned}\nT(n) &= \\sum_{i=1}^{n}logn-logi \\\\\n&= \\frac{n}{2^{logn}}\\times{logn}+ ... + \\frac{n}{4}\\times2+\\frac{n}{2}\\times1 \\\\\n&= O(n)\n\\end{aligned}\n$$\n\n同样的，我们也可以把逐个元素下沉所耗费的时间用下图来示意：\n\n![](/img/in-post/2021-03-21-Handly-heap-cheat-sheet/merge-length.png)\n\n### 两种策略的比较与理解\n\n逐个元素入堆的策略时间复杂度为$O(logn)$，堆合并策略的时间复杂度为$O(n)$，为什么会出现差异呢？我们可以从两个角度来理解：\n\n1. 从元素移动路径的角度\n\n    我们从前一小节的两幅图中可发现，元素入堆策略的图中根节点附近红线十分密集。而堆合并策略的红线则整体来说比较稀疏。\n\n    这说明元素入堆策略中，在根节点附近元素做了较多重复无效的移动——也就是说插入一个元素时上浮到了根节点附近，然后又被其他后来的元素顶替下来。一上一下自然消耗了多余的时间，而这种消耗在元素入堆策略中出现频率高，无可忽视。\n\n2. 从元素移动数量与移动距离的角度\n\n    我们知道一般来说树的越下层节点数量越多。特别是用数组实现的堆是个完全二叉树，最下层节点数量占了总数的一半。 因此**建堆的时间复杂度主要取决于底层元素**的移动距离。\n\n    用元素入堆策略需要每个元素进行上浮操作，而偏偏元素数量最多的底层移动距离最长，$O(n)$个元素需要移动$O(logn)$的距离，因此时间复杂度较高。\n\n    而堆合并策略则反过来，需要每个元素进行下沉操作。移动距离最长的只有一个根元素，底层元素几乎不需要移动，因此时间复杂度加起来只有$O(n)$。\n\n    如图所示，颜色越深代表移动距离越长。颜色深度对面积的积分即为建堆时间复杂度。\n\n    ![](/img/in-post/2021-03-21-Handly-heap-cheat-sheet/move-length.png)\n\n综上分析我们可以得出，通过堆合并策略建堆较优，时间复杂度只需$O(n)$。因此我们建堆一般采用堆合并策略，从下往上逐个元素下沉。\n\n# 代码实现\n\n其实理解了上面这些，要写一个堆出来也已经是水到渠成了。但正如Linus所说，Talk is cheap, show me the code。我们还是要亲手写一段，才能知道堆到底长啥样。\n\n```python\nT = TypeVar(\"T\")\nclass Heap(Generic[T]):\n    '''堆结构\n\n    有两个成员：\n    self.A: List[T] # 堆内元素集合，元素类型为T，储存为数组\n    self.fCompare: Callable[[T,T],bool] # 比较函数\n    \n    下面假设堆为大顶堆\n    即有self.fCompare = lambda a,b: a>b\n    '''\n```\n\n## 实现树结构\n\n堆可以实现为基于数组的完全二叉树，以下标为零的节点为树根节点。\n\n对于下标为i的节点，其左子节点、右子节点、父节点的下标分别如下所示：\n\n```python\ndef lfChildOf(i:int):\n    return (i + 1) << 1 - 1\n\ndef rtChildOf(i:int):\n    return (i + 1) << 1\n\ndef parentOf(i:int):\n    return (i - 1) >> 1\n```\n\n至于为什么是这样，是因为完全二叉树与数组的对应规则如下图所示。这三个函数也没必要记住，到时候纸上画一画就记起来了。\n\n![](/img/in-post/2021-03-21-Handly-heap-cheat-sheet/tree-struct-function.png)\n\n## 实现基本操作——上浮与下沉\n\n### 上浮\n\n上浮就是递归地进行向上交换，下沉就是递归地进行向下交换。\n\n```python\ndef floatUp(self, i:int):\n    '''上浮操作\n\n    对下标为i的元素递归地进行上浮操作\n    直到该元素小于其父节点或该元素上浮到根节点\n    '''\n    # 元素i上浮到根节点时结束递归\n    if i <= 0:\n        return\n    \n    # 当元素i小于其父节点时符合堆结构，结束递归\n    pr = parentOf(i)\n    if self.fCompare(self.A[pr], self.A[i]):\n        return\n    \n    # 元素i大于其父节点，交换i与其父节点并继续上浮\n    self.A[pr], self.A[i] = self.A[i], self.A[pr]\n    self.floatUp(pr)\n```\n\n### 下沉\n\n而下沉要稍微比上浮复杂。向下交换时，需要先找出较大的子节点，再跟较大的子节点进行交互。还要考虑左右子节点不存在的情况：当子节点下标超出堆大小时，子节点不存在。\n\n```python\ndef size(self):\n    '''返回堆大小\n    '''\n    return len(self.A)\n\ndef sinkDown(self, i:int):\n    '''下沉操作\n\n    对下标为i的元素递归地进行下沉操作\n    直到该元素大于其两个子节点或该元素下沉到叶子节点\n    '''\n    lc = lfChildOf(i)\n    rc = rtChildOf(i)\n\n    # 比较元素i与其两个子节点，获取三个元素中存在且最大的元素\n    larger = i\n    if lc < self.size() and self.fCompare(self.A[lc], self.A[larger]):\n        larger = lc\n    if rc < self.size() and self.fCompare(self.A[rc], self.A[larger]):\n        larger = rc\n    \n    # 当元素i大于其两个子节点时符合堆结构，结束递归\n    # 当元素i下沉到叶子节点时，左右子节点不存在，也会在此结束递归\n    if larger == i:\n        return\n    \n    # 元素i小于其中一个子节点，交换i与较大子节点并继续下沉\n    self.A[larger], self.A[i] = self.A[i], self.A[larger]\n    self.sinkDown(larger)\n```\n\n注意这里上浮和下沉操作使用了递归，会占用递归栈空间，因此额外空间复杂度并不是$O(1)$。\n\n但上浮和下沉都可以改为循环迭代实现，迭代实现时额外空间复杂度为$O(1)$。要改成迭代实现并不困难，还请大家尝试自己实现。\n\n## 实现各种借口——读、增、删、初始化\n\n### 读取堆顶\n\n堆一般只允许读取堆顶，即全堆最大元素。\n\n```python\ndef top(self):\n    '''返回堆顶\n    '''\n    return self.A[0]\n```\n\n### 入堆\n\n入堆时，把元素加到堆尾，再做上浮操作。\n\n```python\ndef insert(self, v:T):\n    '''入堆\n    '''\n    # 将元素加到堆尾并做上浮操作\n    self.A.append(v)\n    self.floatUp(len(self.A) - 1)\n```\n\n### 出堆\n\n出堆时，取出堆顶，把堆尾元素填到堆顶后，再做下沉操作。\n\n```python\ndef pop(self)->T:\n    '''出堆\n    '''\n    # 取出堆顶元素\n    res = self.A[0]\n\n    # 将堆尾元素填到堆顶并做下沉操作\n    self.A[0] = self.A[len(self.A) - 1]\n    self.A.pop()\n    self.sinkDown(0)\n\n    return res\n```\n\n注意入堆与出堆操作都要保证堆的大小会相应变化。\n\n### 堆初始化\n\n堆的初始化采用堆合并策略，从堆尾到堆顶逐个元素做下沉操作。\n\n```python\ndef __init__(self, A:List[T]=[], \n             fCompare:Callable[[T,T],bool]=lambda a,b:a>b\n             ) -> None:\n    '''堆初始化\n\n    :param A: 在数组A上进行初始化\n    :param fCompare: 比较函数，对堆中节点p与子节点c，有fCompare(p,c)==True\n    '''\n    self.A = A\n    self.fCompare = fCompare\n    for i in reversed(range(len(A))):\n        self.sinkDown(i)\n```\n\n## 整体代码\n\n### 堆的整体实现\n\n综上，堆的整体代码实现如下：\n\n```python\nfrom typing import Any, Callable, Generic, List, TypeVar\n\nT = TypeVar(\"T\")\n\ndef lfChildOf(i:int):\n    return (i + 1) << 1 - 1\n\ndef rtChildOf(i:int):\n    return (i + 1) << 1\n\ndef parentOf(i:int):\n    return (i - 1) >> 1\n\nclass Heap(Generic[T]):\n    '''堆结构\n\n    有两个成员：\n    self.A: List[T] # 堆内元素集合，元素类型为T，储存为数组\n    self.fCompare: Callable[[T,T],bool] # 比较函数\n    \n    下面假设堆为大顶堆\n    即有self.fCompare = lambda a,b: a>b\n    '''\n    def __init__(self, A:List[T]=[], \n                 fCompare:Callable[[T,T],bool]=lambda a,b:a>b\n                 ) -> None:\n        '''堆初始化\n\n        :param A: 在数组A上进行初始化\n        :param fCompare: 比较函数，对堆中节点p与子节点c，有fCompare(p,c)==True\n        '''\n        self.A = A\n        self.fCompare = fCompare\n        for i in reversed(range(len(A))):\n            self.sinkDown(i)\n    \n    def size(self):\n        '''返回堆大小\n        '''\n        return len(self.A)\n    \n    def top(self):\n        '''返回堆顶\n        '''\n        return self.A[0]\n    \n    def sinkDown(self, i:int):\n        '''下沉操作\n\n        对下标为i的元素递归地进行下沉操作\n        直到该元素大于其两个子节点或该元素下沉到叶子节点\n        '''\n        lc = lfChildOf(i)\n        rc = rtChildOf(i)\n\n        # 比较元素i与其两个子节点，获取三个元素中存在且最大的元素\n        larger = i\n        if lc < self.size() and self.fCompare(self.A[lc], self.A[larger]):\n            larger = lc\n        if rc < self.size() and self.fCompare(self.A[rc], self.A[larger]):\n            larger = rc\n        \n        # 当元素i大于其两个子节点时符合堆结构，结束递归\n        # 当元素i下沉到叶子节点时，左右子节点不存在，也会在此结束递归\n        if larger == i:\n            return\n        \n        # 元素i小于其中一个子节点，交换i与较大子节点并继续下沉\n        self.A[larger], self.A[i] = self.A[i], self.A[larger]\n        self.sinkDown(larger)\n\n    def floatUp(self, i:int):\n        '''上浮操作\n\n        对下标为i的元素递归地进行上浮操作\n        直到该元素小于其父节点或该元素上浮到根节点\n        '''\n        # 元素i上浮到根节点时结束递归\n        if i <= 0:\n            return\n        \n        # 当元素i小于其父节点时符合堆结构，结束递归\n        pr = parentOf(i)\n        if self.fCompare(self.A[pr], self.A[i]):\n            return\n        \n        # 元素i大于其父节点，交换i与其父节点并继续上浮\n        self.A[pr], self.A[i] = self.A[i], self.A[pr]\n        self.floatUp(pr)\n    \n    def insert(self, v:T):\n        '''入堆\n        '''\n        # 将元素加到堆尾并做上浮操作\n        self.A.append(v)\n        self.floatUp(len(self.A) - 1)\n\n    def pop(self)->T:\n        '''出堆\n        '''\n        # 取出堆顶元素\n        res = self.A[0]\n\n        # 将堆尾元素填到堆顶并做下沉操作\n        self.A[0] = self.A[len(self.A) - 1]\n        self.A.pop()\n        self.sinkDown(0)\n\n        return res\n```\n\n### 单元测试\n\n入堆、出堆等操作的简单单元测试如下：\n\n```python\nimport pytest\nimport heap\n\n@pytest.fixture\ndef initHeap():\n    return heap.Heap([1,3,4,7,2,6,5,9,0,8], \n                     lambda a,b:a>b)\n\nclass Test_TestHeap:\n    def test_init_notNull(self, initHeap:heap.Heap):\n        assert initHeap.size() == 10\n        assert initHeap.top() == 9\n    \n    def test_insert_notTop(self, initHeap:heap.Heap):\n        initHeap.insert(6)\n        assert initHeap.size() == 11\n        assert initHeap.top() == 9\n    \n    def test_insert_top(self, initHeap:heap.Heap):\n        initHeap.insert(10)\n        assert initHeap.size() == 11\n        assert initHeap.top() == 10\n    \n    def test_pop(self, initHeap:heap.Heap):\n        p = initHeap.pop()\n        assert p == 9\n        assert initHeap.size() == 9\n        assert initHeap.top() == 8\n```\n\n# 关于堆排序\n\n算法竞赛中除了原生使用堆结构以外，还有一个使用到堆的地方——堆排序。堆排序有原地排序、最坏时间复杂度为$O(nlogn)$等优秀的性质，是比较常用的一个排序算法。\n\n然而，手写堆排序要注意的地方与手写堆结构有比较大的不同。堆排序时要注意的点如下：\n\n1. 堆排序时一般要求在给入数组上原地排序，不需要内部维护一个数组结构，反之，需要记录堆结构的大小。\n2. 堆结构一般占用数组前端，因此从小到大排序时，有序部分从数组末尾开始扩张，建立的堆为大顶堆。\n3. 堆排序只需要建堆与出堆操作，因此只需要实现下沉操作。\n\n关于堆排序的具体讨论，有机会的话我会另外写一篇来讲解。","title":"如何手撕一个堆","abstract":"在参加如AtCoder等算法竞技，或是刷Leetcode等算法题时，我们总是不可避免地遇到堆这种数据结构。\n当然，一般来说我们只要理解堆，知道堆的性质，知道怎么样用堆就足够了。在做题时只需要调用系统类库即可——在参加AtCoder时你甚至不会有时间去自己实现一个堆。\n但是，如果哪一天你把编程语言的类库全忘光了，又遇到一题需要频繁求最值的题目——你明知这里要用堆，却又忘记该调用的类名了，咋办？我还真遇到过这问题：三年没刷算法，只能对着一道自己明显会的题干着急，愣是想不起PriorityQueue的名字。这时候，只能自己实现一个堆出来了。","length":483,"created_at":"2021-08-28T23:09:14.000Z","updated_at":"2024-04-14T13:30:33.000Z","tags":["数据结构","算法","算法竞赛"],"license":false}},{"pathMapping":{"filePath":"public/content/articles/2021-01-11-Sort-algorithm.md","pagePath":"/articles/Sort-algorithm","slug":"Sort-algorithm"},"meta":{"content":"\n# 序言\n\n我们知道排序是算法入门基本功，排序算法有多重要想必也不需要我在这里说明了。因此这一篇就按着我的理解，聊一聊排序算法。\n\n当然我不打算随便弄个什么十大排序算法或是经典排序总结之类响当当的名头，各个算法走马看花一样拉出来遛一遍，最后变得跟网上搜索到的其他讲排序的文章一样换汤不换药。你会发现这篇文章的结构跟在网上搜索到的任何讲排序的文章都有所不同：\n\n在这篇文章里，你会发现你找不到冒泡排序——因为我认为冒泡排序只不过是一种低效率的选择排序。\n\n你会发现堆排序被当成是选择排序的一种优化——因为我认为堆排序主要在于使用了堆这种数据结构，而总体思想与选择排序相比没有太大变化。\n\n你还会找到其他与别的文章不一样的地方。因为这篇文章是我按照自己的理解来写的，我脑子里是这样想的，那文章里就是这样写的。我会按照我的理解，从纵向与横向两个维度，来理清楚各个排序算法的特性与异同。\n\n# 整篇文章的要点\n\n整篇文章以纵向——算法分类、以及横向——算法评价两个维度来进行组织。\n\n排序算法可以按照以下方式来进行分类：\n\n- 基于比较的排序算法\n    - 基于分治思想\n        - 快速排序\n        - 归并排序\n    - 基于有序区域扩展\n        - 插入排序\n        - 选择排序\n- 不基于比较的排序算法\n    - 计数排序\n    - 桶排序\n    - 基数排序\n\n文章中还会讲一讲为什么会这么分，每种分类有什么共性，分类之间有什么差异。此外，在最后还会稍微提一提外部排序与适用于并行运算的排序等。\n\n而对于纵向分类中的每一个端点，我们又会从以下五个方面，来对各个算法进行一个总体评价：\n\n- 时间复杂度（最坏，最好，平均※）\n- 空间复杂度\n- 是否原地排序\n- 是否稳定排序\n- 能否用于链表排序\n\n而由于复杂度主要只关注数量级，因此在这篇文章里会在不影响计算结果的前提下对复杂度计算进行适当的近似与简化。\n\n# 快排\n\n## 思想\n\n分治法：先把序列分为小的部分和大的部分，再将两部分分别排序。即：复杂分割，简单合并，主要操作在于分割。\n\n## 要点\n\n### 时间复杂度\n\n推导式：T(n) = T(找) + T(左) + T(右) = O(n) + 两个子问题时间复杂度。\n\n- 最好时间复杂度为每次都正好找到最中间的一个数时时间复杂度为O（nlogn）。证明略。\n- 最坏时间复杂度为每次都正好找到最旁边的数时时间复杂度为O(n^2)。证明略。\n- 平均时间复杂度为O（nlogn），推导式如下：\n\n    快速排序每一步中，将元素分为左右两边需要遍历整个列表，耗时T(n)。假设最后定位的元素为最终第i个元素，则两个子问题复杂度分别为T(i)和T(n-i-1)。\n\n    则有：\n\n    $$\n    \\begin{aligned}\n    T(n) &= n + \\frac{\\sum_{i=0}^{n-1}{T(i)+T(n-i-1)}}{n} \\\\\n    &=n + \\frac{2}{n}\\times\\sum_{i=0}^{n-1}{T(i)} \\\\\n    \\end{aligned}\n    $$\n\n    令 $$\\sum_{i=0}^{n}T(i) = Sum(n)$$ ，即有：\n\n    $$\n    \\begin{aligned}\n    T(n) &= n + \\frac{2}{n} \\times Sum(n-1) \\\\\n    Sum(n) &= \\frac{n+1}{2}T(n+1) - \\frac{n+1}{2}(n+1)\n    \\end{aligned}\n    $$\n\n    错位相减：\n\n    $$\n    \\begin{aligned}\n    Sum(n) - Sum(n-1) &= \\frac{n+1}{2}T(n+1) - \\frac{n+1}{2}(n+1) - \\frac{n}{2}T(n) + \\frac{n}{2}(n) \n    \\\\\n    T(n) &= \\frac{n+1}{2}T(n+1) - \\frac{n}{2}T(n) - \\frac{2n+1}{2} \n    \\\\\n    \\frac{T(n+1)}{n+2} &= \\frac{T(n)}{n+1}+\\frac{2n+1}{(n+1)(n+2)} \n    \\\\\n    &= \\frac{T(n)}{n+1}+\\frac{1}{n}+\\frac{1}{n+1} \n    \\\\\n    &=...\n    \\\\\n    &= \\frac{T(1)}{2}+1+2\\times(\\frac{1}{2}+\\frac{1}{3}+...+\\frac{1}{n})+\\frac{1}{n+1}\n    \\\\\n    \\\\\n    \\frac{T(n)}{n+1}&=\\frac{T(1)}{2}+1+2\\times(\\frac{1}{2}+...+\\frac{1}{n-1})+\\frac{1}{n}\n    \\\\\n    &= O(1)+O(1)+O(logn)+O(\\frac{1}{n})\n    \\\\\n    &= O(logn)\n    \\end{aligned}\n    $$\n\n    其中由于 $$\\frac{1}{x}=\\frac{d(logx)}{dx}$$ ，因此 $$\\frac{1}{2}+...+\\frac{1}{n-1}=O(logn)$$ 。\n\n    则有：\n\n    $$\n    \\begin{aligned}\n    T(n)&=(n+1)\\times O(logn)\\\\\n    &=O(n)\\times O(logn)\\\\\n    &=O(nlogn)\n    \\end{aligned}\n    $$\n\n### 额外空间复杂度\n\n考虑栈深度，额外空间复杂度为O（logn）。由于快速排序主要步骤在于分，因此必须自上而下的进行递归，无法避免栈深度。\n\n### 原地排序\n\n虽然快速排序有额外空间复杂度，但并不妨碍它是一个原地排序。\n\n### 不稳定\n\n堆排序在分操作时将元素左右交换，会破坏稳定性。\n\n### 链表形式特点\n\n- 时间复杂度不变\n- 空间复杂度不变\n- 变为稳定排序※\n\n## 手写时的易错点\n\n- 分成左右子序列时最好完全分开（一边用`<=`一边用`>`），不然容易造成死循环。\n- 分左右子序列时仔细考虑最初下标位置与最终下标位置，以及对应位置的值的大小。\n- 不要忘记递归的结束条件。\n\n# 归并排序\n\n## 思想\n\n分治法：先把两个子序列各自排好序，然后再合并两个子序列。即：简单分割，复杂合并。主要步骤在于合并。\n\n## 要点\n\n- 时间复杂度推导式：T(n) = 2T(n/2) + T(合)\n- 平均、最好、最坏时间复杂度都是O（nlogn），推导过程略。\n- 额外空间复杂度为O（n），合并时必须准备额外空间。但由于主要步骤在于合并，可以自下而上地进行迭代合并，可以不使用栈。\n- 非原地排序\n- 稳定排序\n\n### 链表形式\n\n- 时间复杂度不变\n- 额外空间复杂度变为O(1)※\n- 稳定排序\n- 只能使用迭代形式，不能使用递归形式\n\n## 易错点\n\n- 合并时一边结束时另一边还未结束，需要把那一边也放入合并后序列中\n- 保持稳定排序：合并时左序列等于右序列时也采用左序列\n- 不要忘记递归结束条件\n- 不要忘记循环递进条件\n\n## 进阶\n\n- 原地归并排序：时间复杂度为O（log^2n），牺牲合并的时间复杂度进行原地排序。\n- 多路归并排序：使用竞标树，多路归并，用于磁盘IO。\n\n# 插入排序\n\n## 思想\n\n有序序列不断扩张，每次从无序序列中取出元素加入有序序列，直至长度为N则完成排序。\n\n每次将无序序列当前元素插入有序序列，复杂度取决于有序序列。\n\n## 要点\n\n- 最坏、平均时间复杂度：O（n2）\n- 最好时间复杂度：基本有序情况下，O（n）\n- 额外空间复杂度：O（1）\n- 原地排序\n- 稳定排序\n- 每次插入时都要移动序列，写次数较多\n- 若查找插入位置时使用二分法查找，则可加快时间。（但不足以对时间复杂度造成影响，且最好时间复杂度也会上升为O(nlogn)）\n\n### 链表形式\n\n- 最好，最坏，平均时间复杂度不变\n- 额外空间复杂度不变\n- 稳定排序\n- 插入时不再需要移动序列，但也不能使用二分法查找\n\n## 进阶——希尔排序\n\n- 要点：\n\n    插入排序的优点在于当序列基本有序时，时间复杂度可逼近为O(n)。\n\n    但插入时移动有序序列中元素所耗时间较多，而每次只移动一步。但实际上当序列分布均匀时，有序序列中排靠后的元素在整个序列中也会排靠后。\n\n    可以把序列分为几个大步长序列，在最初的几次插入放开移动步长，让大的元素直接移动到较后位置。再往后慢慢缩小步长，此时序列基本有序，可以利用基本有序时插入排序的优势。\n\n- 时间复杂度\n    1. 当步长为2^i时，不能使时间复杂度缩短为O(nlogn)。因为一个子序列所有元素有可能比另一个子序列最大元素都要大，这时插入排序仍需进行约n^2次操作\n    2. 当步长为2^i时效率较低，因为当步长为4已经有序时，步长为2再比较是无用比较。但由于1.的问题，不能节省比较时间。\n    3. 当步长之间最小公约数较少，甚至互质时，无用比较次数会降低。\n    4. 最坏时间复杂度下限为 $$O(nlog^2n)$$ （当步长采用 $$2^i3^j$$ 时），但一般希尔排序平均时间复杂度都为 $$O(n^{\\frac{3}{2}})$$\n- 额外空间复杂度O(1)\n- 原地排序\n- 不稳定排序：希尔排序步长较大时会发生前后跳转。\n- 不能写为链表形式\n\n# 选择排序\n\n## 思想\n\n有序序列不断扩张，每次从无序序列中取出元素加入有序序列，直至长度为N则完成排序。\n\n每次将选无序序列中最小元素加到有序序列末尾，复杂度取决于无序序列。\n\n## 要点\n\n- 最坏、平均时间复杂度：O（n2）\n- 最好时间复杂度：O（n2），如能保证无序部分的最小元素所在位置一定（堆排序），能降低时间复杂度\n- 额外空间复杂度：O（1）\n- 原地排序\n- 不稳定排序（采用元素交换策略时）\n- 每次找到最小元素后，只需交换一次位置即可，写次数较少。\n- 若找到最小元素后，不直接交换而是进行数组移动，则可进行稳定排序，但写次数变多，与插入排序相比没有优势，也不能使用二分查找进行简化。\n\n### 链表形式\n\n- 最好，最坏，平均时间复杂度不变\n- 额外空间复杂度不变\n- 变为稳定排序※（因为链表不需要数组移动，稳定排序方式的缺点得以消除）\n\n## 进阶——堆排序\n\n- 要点：\n\n    选择排序中耗时最多的是取出无序序列中最小值的时间，需要遍历整个无序序列。\n\n    但实际上我们只关心无序序列中的最小值，而不关心其他值的位置。通过将无序序列建为堆，减少选择时间，降低总的时间复杂度。\n\n- 时间复杂度O（nlogn）\n- 额外空间复杂度O（1）\n- 原地排序\n- 不稳定排序\n- 操作时间复杂度：每次向下比较关注一个节点与其左右子堆顶元素，每次向上比较只关注节点与其父元素（大顶堆，堆大小为n）\n    - 下沉：向下比较，若顶元素不是最大，将顶元素与较大的子堆堆顶元素交换。递归处理该子堆顶元素，直到向下比较顶元素最大。\n\n        最好时间复杂度O（1），最坏时间复杂度为O（h）=O（logn），平均O（logn）\n\n    - 上浮：向上比较，若元素比其上层要大，交换该元素与其上层元素。递归处理其上层元素，直到向上比较不比上层要大。\n\n        最好时间复杂度O（1），最坏时间复杂度O（h）=O（logn），平均O（logn）\n\n    - 入堆：堆扩容一位，将新元素插到尾部，将该元素上浮，最坏、平均时间复杂度O（logn）\n    - 出堆：取出堆顶元素，将尾部放到堆顶，将该元素下沉，最坏、平均时间复杂度O（logn）\n    - 缺点：通常堆尾元素较小，出堆时将堆尾元素放到堆顶再下沉基本要沉到堆底，无用比较较多\n- 建堆时间复杂度O（n）\n    - 策略1：从头开始建堆，逐个元素插入，时间复杂度取决于最后一层，时间复杂度为O（nlogn）\n        - 每次将堆扩容一位，将末尾元素上浮。\n        - 时间复杂度推导：\n\n            每次插入时间：\n\n            $$\n            \\begin{aligned} T(i) &= h\\\\\n            &= logi\n            \\end{aligned}\n            $$\n\n            则有总时间：\n\n            $$\n            \\begin{aligned}\n            T(n) &= \\sum_{i=0}^{n}logi\\\\\n            &= 1\\times1 + 2\\times2+ 3\\times4 + ...+h\\times \\frac{n}{2} \\\\\n            \\\\\n            2T(n) &= 1\\times2 + 2\\times4+ 3\\times8 + ...+h\\times n \\\\\n            \\\\\n            2T(n)-T(n) &= h\\times n - (1+2+4+...+2^{h-1}) \\\\\n            &= h\\times n - O(2^h) \\\\\n            \\\\\n            T(n) &= nlogn - O(2^h) \\\\\n            &= O(nlogn)\n            \\end{aligned}\n            $$\n\n            即时间复杂度为 $$O(nlogn)$$\n\n    - 策略2：从后开始建堆，小堆合并（逐个元素下沉），时间复杂度为O（n）\n        - 每次堆合并时，有三部分：左子堆，右子堆，顶元素。下沉顶元素。\n        - 时间复杂度推导：\n\n            第i个元素合并时，时间为：\n\n            $$\n            \\begin{aligned}\n            T(i) &= h_{子堆}\n            \\end{aligned}\n            $$\n\n            则有总时间：\n\n            $$\n            \\begin{aligned}\n            T(n) &= \\sum_{i=0}^{n} (h_{子堆}) \\\\\n            &= h + (h-1)\\times2 + ... + 2 \\times \\frac{n}{4} + 1 \\times\\frac{n}{2}\\\\\n            \\\\\n            2T(n) &= h \\times 2 + (h-1) \\times 4 + ... + 2 \\times \\frac{n}{2} + n \\\\\n            \\\\\n            2T(n) - T(n) &= n + \\frac{n}{2} + ... + 2 - h \\\\\n            \\\\\n            T(n) &= O(n) - h \\\\ \n            &= O(n)\n            \\end{aligned}\n            $$\n\n            即时间复杂度为 $$O(n)$$ \n\n        - 虽说每步是做一个小堆合并，但实际上从堆尾到堆头遍历，相当于仅关注元素没有稳定，相当于可以直接使用下沉操作。\n\n# 基于比较的排序算法时间复杂度下限：逆序对思想\n\n基于比较的排序算法可以看作序列逆序对的消除。完全随机序列逆序对数量为O(n^2)，若一次元操作只消除一个逆序对，则时间复杂度不会低于O(n^2)。降低时间复杂度关键在于一次消除多个逆序对。\n\n1. 希尔排序通过增大最初的步长来企图一次消除多个逆序对。\n2. 归并排序消除逆序对最主要在于归并步骤。最后几次合并每个子步骤用O(1)时间消除O(n)个逆序对。\n3. 快速排序消除逆序对最主要在于划分步骤。每个划分步骤用O(n)时间消除O(n)+O(左长度×右长度)个逆序对。\n4. 堆排序逆序对消除方式比较Tricky，但可以看出消除逆序对大致在于出堆步骤，通过O(logn)时间复杂度消除O(n)个逆序对。（左小右大排序时需要建立左大右小的大顶堆，建堆时基本没有消除逆序对）\n\n# 最后\n\n这篇文章我们主要关注了排序算法中的大头——基于比较的排序算法。在下篇文章，我们再来看一下不基于比较的排序算法，以及外排序与并行排序。","title":"排序算法","abstract":"我们知道排序是算法入门基本功，排序算法有多重要想必也不需要我在这里说明了。因此这一篇就按着我的理解，聊一聊排序算法。\n当然我不打算随便弄个什么十大排序算法或是经典排序总结之类响当当的名头，各个算法走马看花一样拉出来遛一遍，最后变得跟网上搜索到的其他讲排序的文章一样换汤不换药。你会发现这篇文章的结构跟在网上搜索到的任何讲排序的文章都有所不同：\n在这篇文章里，你会发现你找不到冒泡排序——因为我认为冒泡排序只不过是一种低效率的选择排序。","length":342,"created_at":"2021-01-11T22:57:10.000Z","updated_at":"2024-04-14T13:30:33.000Z","tags":["数据结构","算法","排序"],"license":false}}]},"__N_SSG":true}