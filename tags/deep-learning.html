<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="width=device-width, initial-scale=1" data-next-head=""/><meta name="description" content="The blog owned by Ryo, about Programing, Painting, and Gaming." data-next-head=""/><meta property="og:description" content="The blog owned by Ryo, about Programing, Painting, and Gaming." data-next-head=""/><meta name="twitter:description" content="The blog owned by Ryo, about Programing, Painting, and Gaming." data-next-head=""/><meta property="og:image" content="https://ryojerryyu.github.io/blog-next/img/home-bg-kasumi-hanabi.jpg" data-next-head=""/><meta name="twitter:image" content="https://ryojerryyu.github.io/blog-next/img/home-bg-kasumi-hanabi.jpg" data-next-head=""/><meta property="og:type" content="website" data-next-head=""/><meta property="og:url" content="https://blog.ryo-okami.xyz/tags/deep-learning" data-next-head=""/><meta name="twitter:card" content="summary_large_image" data-next-head=""/><meta name="twitter:site" content="@ryo_okami" data-next-head=""/><meta name="twitter:creator" content="@ryo_okami" data-next-head=""/><link rel="icon" href="/blog-next/favicon.ico" data-next-head=""/><meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests" data-next-head=""/><title data-next-head="">Deep Learning | Ryo&#x27;s Blog</title><meta property="og:title" content="Deep Learning" data-next-head=""/><meta property="og:site_name" content="Ryo&#x27;s Blog" data-next-head=""/><meta name="twitter:title" content="Deep Learning | Ryo&#x27;s Blog" data-next-head=""/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><link rel="apple-touch-icon" href="/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="192x192" href="/android-chrome-192x192.png"/><link rel="manifest" href="/site.webmanifest"/><meta name="msapplication-TileColor" content="#da532c"/><meta name="theme-color" content="#ffffff"/><link data-next-font="" rel="preconnect" href="/" crossorigin="anonymous"/><link rel="preload" href="/blog-next/_next/static/css/8bc897d2815c155b.css" as="style"/><link rel="preload" href="/blog-next/_next/static/css/50b775b74e204f8b.css" as="style"/><link rel="stylesheet" href="/blog-next/_next/static/css/8bc897d2815c155b.css" data-n-g=""/><link rel="stylesheet" href="/blog-next/_next/static/css/50b775b74e204f8b.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" noModule="" src="/blog-next/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/blog-next/_next/static/chunks/webpack-0838eb7d41561e24.js" defer=""></script><script src="/blog-next/_next/static/chunks/framework-d33e0fe36067854f.js" defer=""></script><script src="/blog-next/_next/static/chunks/main-dea36a7529be985a.js" defer=""></script><script src="/blog-next/_next/static/chunks/pages/_app-0fb7c4bae3c90fb5.js" defer=""></script><script src="/blog-next/_next/static/chunks/5342-0e842ae0467f6356.js" defer=""></script><script src="/blog-next/_next/static/chunks/pages/tags/%5Btag%5D-7b4b79abeb276f0b.js" defer=""></script><script src="/blog-next/_next/static/EJw7StVO_ba3erNzBj1ZM/_buildManifest.js" defer=""></script><script src="/blog-next/_next/static/EJw7StVO_ba3erNzBj1ZM/_ssgManifest.js" defer=""></script></head><body><div id="__next"><style data-emotion="css czlpqi">.css-czlpqi{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;width:100%;box-sizing:border-box;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;position:fixed;z-index:1100;top:0;left:auto;right:0;--AppBar-background:#1976d2;--AppBar-color:#fff;background-color:var(--AppBar-background);color:var(--AppBar-color);background-color:rgba(15, 23, 42, 0.75);}@media print{.css-czlpqi{position:absolute;}}</style><style data-emotion="css 1cmpeoq">.css-1cmpeoq{background-color:#fff;color:rgba(0, 0, 0, 0.87);-webkit-transition:box-shadow 300ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:box-shadow 300ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;box-shadow:var(--Paper-shadow);background-image:var(--Paper-overlay);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;width:100%;box-sizing:border-box;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;position:fixed;z-index:1100;top:0;left:auto;right:0;--AppBar-background:#1976d2;--AppBar-color:#fff;background-color:var(--AppBar-background);color:var(--AppBar-color);background-color:rgba(15, 23, 42, 0.75);}@media print{.css-1cmpeoq{position:absolute;}}</style><header class="MuiPaper-root MuiPaper-elevation MuiPaper-elevation4 MuiAppBar-root MuiAppBar-colorPrimary MuiAppBar-positionFixed mui-fixed css-1cmpeoq" style="--Paper-shadow:0px 2px 4px -1px rgba(0,0,0,0.2),0px 4px 5px 0px rgba(0,0,0,0.14),0px 1px 10px 0px rgba(0,0,0,0.12)"><style data-emotion="css awgou1">.css-awgou1{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-left:16px;padding-right:16px;min-height:56px;}@media (min-width:600px){.css-awgou1{padding-left:24px;padding-right:24px;}}@media (min-width:0px){@media (orientation: landscape){.css-awgou1{min-height:48px;}}}@media (min-width:600px){.css-awgou1{min-height:64px;}}</style><div class="MuiToolbar-root MuiToolbar-gutters MuiToolbar-regular css-awgou1"><style data-emotion="css 1guk29">@media (min-width:0px){.css-1guk29{display:none;}}@media (min-width:900px){.css-1guk29{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}</style><div class="ml-2 w-24 mr-4 MuiBox-root css-1guk29"><a class="DefaultLayout_textlink__W55gl" href="/blog-next">Ryo&#x27;s Blog</a></div><style data-emotion="css 1m04nb5">@media (min-width:0px){.css-1m04nb5{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}@media (min-width:900px){.css-1m04nb5{display:none;}}</style><div class="ml-2 mr-4 MuiBox-root css-1m04nb5"><a title="Ryo&#x27;s Blog" href="/blog-next"><style data-emotion="css q7mezt">.css-q7mezt{-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;width:1em;height:1em;display:inline-block;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;-webkit-transition:fill 200ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:fill 200ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;fill:currentColor;font-size:1.5rem;}</style><svg class="MuiSvgIcon-root MuiSvgIcon-fontSizeMedium h-6 w-6 text-gray-300 hover:text-white css-q7mezt" focusable="false" aria-hidden="true" viewBox="0 0 24 24"><path d="M10 20v-6h4v6h5v-8h3L12 3 2 12h3v8z"></path></svg></a></div><style data-emotion="css nznm6s">.css-nznm6s{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex:1;-ms-flex:1;flex:1;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}</style><div class="MuiBox-root css-nznm6s"><div class="DefaultLayoutMenu bg-transparent min-w-full"><ul class="rc-menu-overflow rc-menu rc-menu-root rc-menu-horizontal" role="menu" tabindex="0" data-menu-list="true"><li class="rc-menu-overflow-item rc-menu-item" style="opacity:1;order:0" role="menuitem" tabindex="-1"><a class="DefaultLayout_textlink__W55gl" href="/blog-next/articles">Articles</a></li><li class="rc-menu-overflow-item rc-menu-item" style="opacity:1;order:1" role="menuitem" tabindex="-1"><a class="DefaultLayout_textlink__W55gl" href="/blog-next/learn_from_ai">Learn from AI</a></li><li class="rc-menu-overflow-item rc-menu-item" style="opacity:1;order:2" role="menuitem" tabindex="-1"><a class="DefaultLayout_textlink__W55gl" href="/blog-next/tags">Tags</a></li><li class="rc-menu-overflow-item rc-menu-submenu rc-menu-submenu-horizontal" style="opacity:1;order:3" role="none"><div role="menuitem" class="rc-menu-submenu-title" tabindex="-1" aria-expanded="false" aria-haspopup="true"><span class="DefaultLayout_textlink__W55gl">More</span><i class="rc-menu-submenu-arrow"></i></div></li><li class="rc-menu-overflow-item rc-menu-overflow-item-rest rc-menu-submenu rc-menu-submenu-horizontal" style="opacity:0;height:0;overflow-y:hidden;order:9007199254740991;pointer-events:none;position:absolute" aria-hidden="true" role="none"><div role="menuitem" class="rc-menu-submenu-title" tabindex="-1" title="..." aria-expanded="false" aria-haspopup="true">...<i class="rc-menu-submenu-arrow"></i></div></li></ul><div style="display:none" aria-hidden="true"></div></div></div><style data-emotion="css k008qs">.css-k008qs{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}</style><div class="MuiBox-root css-k008qs"><a title="Twitter" href="https://twitter.com/ryo_okami"><svg class="h-6 w-6 fill-gray-300 hover:fill-white mx-1 sm:mx-2" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a><a title="GitHub" href="https://github.com/RyoJerryYu"><svg class="h-6 w-6 fill-gray-300 hover:fill-white mx-1 sm:mx-2" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a><a title="Pixiv" href="https://www.pixiv.net/users/9159893"><svg class="h-6 w-6 fill-gray-300 hover:fill-white mx-1 sm:mx-2" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4.935 0A4.924 4.924 0 0 0 0 4.935v14.13A4.924 4.924 0 0 0 4.935 24h14.13A4.924 4.924 0 0 0 24 19.065V4.935A4.924 4.924 0 0 0 19.065 0zm7.81 4.547c2.181 0 4.058.676 5.399 1.847a6.118 6.118 0 0 1 2.116 4.66c.005 1.854-.88 3.476-2.257 4.563-1.375 1.092-3.225 1.697-5.258 1.697-2.314 0-4.46-.842-4.46-.842v2.718c.397.116 1.048.365.635.779H5.79c-.41-.41.19-.65.644-.779V7.666c-1.053.81-1.593 1.51-1.868 2.031.32 1.02-.284.969-.284.969l-1.09-1.73s3.868-4.39 9.553-4.39zm-.19.971c-1.423-.003-3.184.473-4.27 1.244v8.646c.988.487 2.484.832 4.26.832h.01c1.596 0 2.98-.593 3.93-1.533.952-.948 1.486-2.183 1.492-3.683-.005-1.54-.504-2.864-1.42-3.86-.918-.992-2.274-1.645-4.002-1.646Z"></path></svg></a></div></div></header><style data-emotion="css awgou1">.css-awgou1{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-left:16px;padding-right:16px;min-height:56px;}@media (min-width:600px){.css-awgou1{padding-left:24px;padding-right:24px;}}@media (min-width:0px){@media (orientation: landscape){.css-awgou1{min-height:48px;}}}@media (min-width:600px){.css-awgou1{min-height:64px;}}</style><div class="MuiToolbar-root MuiToolbar-gutters MuiToolbar-regular css-awgou1"></div><style data-emotion="css vktxal">.css-vktxal{--Grid-columns:12;--Grid-columnSpacing:0px;--Grid-rowSpacing:0px;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;min-width:0;box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;gap:var(--Grid-rowSpacing) var(--Grid-columnSpacing);width:100%;max-width:80rem;margin-left:auto;margin-right:auto;padding:0.5rem;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;}.css-vktxal >*{--Grid-parent-columns:12;}.css-vktxal >*{--Grid-parent-columnSpacing:0px;}.css-vktxal >*{--Grid-parent-rowSpacing:0px;}</style><div class="MuiGrid-root MuiGrid-container MuiGrid-direction-xs-row css-vktxal"><style data-emotion="css 9gdssj">.css-9gdssj{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 0 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 0) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));min-width:0;box-sizing:border-box;}@media (min-width:900px){.css-9gdssj{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 0 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 0) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}@media (min-width:1200px){.css-9gdssj{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 2 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 2) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}</style><div class="MuiGrid-root MuiGrid-direction-xs-row MuiGrid-grid-xs-0 MuiGrid-grid-md-0 MuiGrid-grid-lg-2 css-9gdssj"></div><style data-emotion="css 9h67uz">.css-9h67uz{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 12 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 12) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));min-width:0;box-sizing:border-box;}@media (min-width:900px){.css-9h67uz{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 9 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 9) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}@media (min-width:1200px){.css-9h67uz{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 8 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 8) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}</style><div class="MuiGrid-root MuiGrid-direction-xs-row MuiGrid-grid-xs-12 MuiGrid-grid-md-9 MuiGrid-grid-lg-8 css-9h67uz"><div class="DefaultLayout_contentHeight__RDRZE"><div class="p-2"><div class="TagsBox_tagsBox__WzhAf"><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E6%9D%82%E6%8A%80">#<!-- -->杂技</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/blog">#<!-- -->Blog</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E6%9D%82%E8%B0%88">#<!-- -->杂谈</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/c++">#<!-- -->C++</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/python">#<!-- -->Python</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84">#<!-- -->数据结构</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E7%AE%97%E6%B3%95">#<!-- -->算法</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E6%8E%92%E5%BA%8F">#<!-- -->排序</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B">#<!-- -->算法竞赛</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F">#<!-- -->设计模式</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E7%AC%94%E8%AE%B0">#<!-- -->笔记</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/github">#<!-- -->GitHub</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/aws">#<!-- -->AWS</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/ci-cd">#<!-- -->CI/CD</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/iac">#<!-- -->IaC</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/devops">#<!-- -->DevOps</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/vscode">#<!-- -->VSCode</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/hexo">#<!-- -->Hexo</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/javascript">#<!-- -->JavaScript</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/kubernetes">#<!-- -->Kubernetes</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/docker">#<!-- -->Docker</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/cloud-native">#<!-- -->Cloud Native</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/cursor">#<!-- -->Cursor</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E5%8F%AF%E8%A7%86%E5%8C%96">#<!-- -->可视化</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E6%95%B0%E5%AD%A6">#<!-- -->数学</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E5%B7%A5%E5%85%B7">#<!-- -->工具</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/nextjs">#<!-- -->Nextjs</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/linux">#<!-- -->Linux</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/systemctl">#<!-- -->systemctl</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/journalctl">#<!-- -->journalctl</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/timedatectl">#<!-- -->timedatectl</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/basicknowledge">#<!-- -->BasicKnowledge</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/operation">#<!-- -->Operation</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/signal">#<!-- -->Signal</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/memory">#<!-- -->memory</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/schedule">#<!-- -->schedule</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/cloud-computing">#<!-- -->Cloud Computing</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/pytorch">#<!-- -->PyTorch</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/onnx">#<!-- -->ONNX</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0">#<!-- -->深度学习</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2">#<!-- -->模型部署</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0">#<!-- -->学习笔记</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/opencv">#<!-- -->OpenCV</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86">#<!-- -->图像处理</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/rust">#<!-- -->Rust</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80">#<!-- -->编程语言</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/windows">#<!-- -->Windows</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/macos">#<!-- -->macOS</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E5%8F%AF%E6%89%A7%E8%A1%8C%E6%96%87%E4%BB%B6">#<!-- -->可执行文件</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/lora">#<!-- -->LoRA</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83">#<!-- -->参数高效微调</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83">#<!-- -->模型训练</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD">#<!-- -->反向传播</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86">#<!-- -->自动微分</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/golang">#<!-- -->GoLang</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/memory-management">#<!-- -->Memory Management</a><a class="tag-word TagsBox_highlightedTag__cLTHz" href="/blog-next/tags/deep-learning">#<!-- -->Deep Learning</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/model-management">#<!-- -->Model Management</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/neural-networks">#<!-- -->Neural Networks</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/resnet">#<!-- -->ResNet</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/mathematics">#<!-- -->Mathematics</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E5%8D%8F%E8%AE%AE">#<!-- -->协议</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/iot">#<!-- -->IoT</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E7%89%A9%E8%81%94%E7%BD%91">#<!-- -->物联网</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97">#<!-- -->消息队列</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/stable-diffusion">#<!-- -->Stable Diffusion</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/concurrency">#<!-- -->Concurrency</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/scheduler">#<!-- -->Scheduler</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/goroutine">#<!-- -->Goroutine</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/test">#<!-- -->test</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/wiki">#<!-- -->wiki</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/page1">#<!-- -->page1</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/subpage1">#<!-- -->subpage1</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/page2">#<!-- -->page2</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/subpage2">#<!-- -->subpage2</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/subpage3">#<!-- -->subpage3</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/subpage34">#<!-- -->subpage34</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/page3">#<!-- -->page3</a></div></div><div class="PostList_postList__Tuobz"><div class="PostList_postListElement__qi6kp"><a href="/blog-next/learn_from_ai/pytorch-model-save-and-load"><h6 class="PostList_postTitle__vveJr">PyTorch 模型的保存与加载机制详解</h6><div class="PostList_postDate__z_XQh"><time dateTime="2025-03-07T13:00:00.000Z">2025-03-07</time></div><div class="PostList_postAbstract__HtPA1"><p class="py-1">&gt; 本文为与 DeepSeek 对话记录，深入探讨 PyTorch 中模型的保存和加载机制，包括不同的保存方式、最佳实践以及常见问题的解决方案。</p><p class="py-1">&gt; [!reasoning]-</p><p class="py-1">&gt;</p></div></a><div class="TagsBox_tagsBox__WzhAf py-4 md:py-1"><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/deep-learning">#<!-- -->Deep Learning</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/pytorch">#<!-- -->PyTorch</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/model-management">#<!-- -->Model Management</a></div></div><div class="PostList_postListElement__qi6kp"><a href="/blog-next/learn_from_ai/resnet-math-and-gradient-vanishing"><h6 class="PostList_postTitle__vveJr">ResNet 的数学原理与梯度消失问题分析</h6><div class="PostList_postDate__z_XQh"><time dateTime="2025-03-07T10:00:00.000Z">2025-03-07</time></div><div class="PostList_postAbstract__HtPA1"><p class="py-1">&gt; 本文深入探讨了 ResNet 的数学原理，分析了深度神经网络中的梯度消失问题及其解决方案。通过数学推导和直观解释，帮助读者理解残差连接的作用机制，以及它如何有效地解决了深度神经网络训练中的关键问题。</p><p class="py-1">&gt; [!query]</p><p class="py-1">&gt;</p></div></a><div class="TagsBox_tagsBox__WzhAf py-4 md:py-1"><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/deep-learning">#<!-- -->Deep Learning</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/neural-networks">#<!-- -->Neural Networks</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/resnet">#<!-- -->ResNet</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/mathematics">#<!-- -->Mathematics</a></div></div></div></div></div><style data-emotion="css vkdybf">.css-vkdybf{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 0 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 0) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));min-width:0;box-sizing:border-box;}@media (min-width:900px){.css-vkdybf{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 3 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 3) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}@media (min-width:1200px){.css-vkdybf{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 2 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 2) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}</style><div class="MuiGrid-root MuiGrid-direction-xs-row MuiGrid-grid-xs-0 MuiGrid-grid-md-3 MuiGrid-grid-lg-2 css-vkdybf"></div></div><footer class="DefaultLayout_footer__aWV4u"><style data-emotion="css vktxal">.css-vktxal{--Grid-columns:12;--Grid-columnSpacing:0px;--Grid-rowSpacing:0px;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;min-width:0;box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;gap:var(--Grid-rowSpacing) var(--Grid-columnSpacing);width:100%;max-width:80rem;margin-left:auto;margin-right:auto;padding:0.5rem;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;}.css-vktxal >*{--Grid-parent-columns:12;}.css-vktxal >*{--Grid-parent-columnSpacing:0px;}.css-vktxal >*{--Grid-parent-rowSpacing:0px;}</style><div class="MuiGrid-root MuiGrid-container MuiGrid-direction-xs-row css-vktxal"><style data-emotion="css 9gdssj">.css-9gdssj{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 0 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 0) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));min-width:0;box-sizing:border-box;}@media (min-width:900px){.css-9gdssj{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 0 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 0) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}@media (min-width:1200px){.css-9gdssj{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 2 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 2) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}</style><div class="MuiGrid-root MuiGrid-direction-xs-row MuiGrid-grid-xs-0 MuiGrid-grid-md-0 MuiGrid-grid-lg-2 css-9gdssj"></div><style data-emotion="css 9h67uz">.css-9h67uz{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 12 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 12) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));min-width:0;box-sizing:border-box;}@media (min-width:900px){.css-9h67uz{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 9 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 9) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}@media (min-width:1200px){.css-9h67uz{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 8 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 8) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}</style><div class="MuiGrid-root MuiGrid-direction-xs-row MuiGrid-grid-xs-12 MuiGrid-grid-md-9 MuiGrid-grid-lg-8 css-9h67uz"><div class="flex flex-row justify-center items-center"><div class="DefaultLayout_footerLeft__Qn_VV">© 2023 Ryo Jerry Yu. All rights reserved.</div><div class="DefaultLayout_footerRight__GlReP"><a title="Twitter" href="https://twitter.com/ryo_okami"><svg class="h-6 w-6 fill-gray-300 hover:fill-white transition-all ease-in-out mx-1 md:mx-2" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a><a title="GitHub" href="https://github.com/RyoJerryYu"><svg class="h-6 w-6 fill-gray-300 hover:fill-white transition-all ease-in-out mx-1 md:mx-2" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a><a title="Pixiv" href="https://www.pixiv.net/users/9159893"><svg class="h-6 w-6 fill-gray-300 hover:fill-white transition-all ease-in-out mx-1 md:mx-2" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4.935 0A4.924 4.924 0 0 0 0 4.935v14.13A4.924 4.924 0 0 0 4.935 24h14.13A4.924 4.924 0 0 0 24 19.065V4.935A4.924 4.924 0 0 0 19.065 0zm7.81 4.547c2.181 0 4.058.676 5.399 1.847a6.118 6.118 0 0 1 2.116 4.66c.005 1.854-.88 3.476-2.257 4.563-1.375 1.092-3.225 1.697-5.258 1.697-2.314 0-4.46-.842-4.46-.842v2.718c.397.116 1.048.365.635.779H5.79c-.41-.41.19-.65.644-.779V7.666c-1.053.81-1.593 1.51-1.868 2.031.32 1.02-.284.969-.284.969l-1.09-1.73s3.868-4.39 9.553-4.39zm-.19.971c-1.423-.003-3.184.473-4.27 1.244v8.646c.988.487 2.484.832 4.26.832h.01c1.596 0 2.98-.593 3.93-1.533.952-.948 1.486-2.183 1.492-3.683-.005-1.54-.504-2.864-1.42-3.86-.918-.992-2.274-1.645-4.002-1.646Z"></path></svg></a></div></div></div><style data-emotion="css vkdybf">.css-vkdybf{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 0 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 0) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));min-width:0;box-sizing:border-box;}@media (min-width:900px){.css-vkdybf{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 3 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 3) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}@media (min-width:1200px){.css-vkdybf{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 2 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 2) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}</style><div class="MuiGrid-root MuiGrid-direction-xs-row MuiGrid-grid-xs-0 MuiGrid-grid-md-3 MuiGrid-grid-lg-2 css-vkdybf"></div></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"allTagInfos":[{"tag":"杂技","slug":"杂技","path":"/tags/杂技","postSlugs":[{"postType":"articles","postPagePath":"/articles/Building-this-blog"},{"postType":"articles","postPagePath":"/articles/hello-world"},{"postType":"articles","postPagePath":"/articles/the-using-in-cpp"}]},{"tag":"Blog","slug":"blog","path":"/tags/blog","postSlugs":[{"postType":"articles","postPagePath":"/articles/Building-this-blog"},{"postType":"articles","postPagePath":"/articles/init-a-new-hexo-project"},{"postType":"articles","postPagePath":"/articles/create-blog-cicd-by-github"},{"postType":"articles","postPagePath":"/articles/use-paste-image-and-vscode-memo"},{"postType":"ideas","postPagePath":"/ideas/blog-in-next"},{"postType":"ideas","postPagePath":"/ideas/blog-syntax"}]},{"tag":"杂谈","slug":"杂谈","path":"/tags/杂谈","postSlugs":[{"postType":"articles","postPagePath":"/articles/hello-world"},{"postType":"articles","postPagePath":"/articles/try-cursor-and-thinking"}]},{"tag":"C++","slug":"c++","path":"/tags/c++","postSlugs":[{"postType":"articles","postPagePath":"/articles/the-using-in-cpp"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/cpp-rvo-and-rust-move-semantics"}]},{"tag":"Python","slug":"python","path":"/tags/python","postSlugs":[{"postType":"articles","postPagePath":"/articles/python-dict"}]},{"tag":"数据结构","slug":"数据结构","path":"/tags/数据结构","postSlugs":[{"postType":"articles","postPagePath":"/articles/python-dict"},{"postType":"articles","postPagePath":"/articles/Sort-algorithm"},{"postType":"articles","postPagePath":"/articles/Handy-heap-cheat-sheet"}]},{"tag":"算法","slug":"算法","path":"/tags/算法","postSlugs":[{"postType":"articles","postPagePath":"/articles/Sort-algorithm"},{"postType":"articles","postPagePath":"/articles/Handy-heap-cheat-sheet"}]},{"tag":"排序","slug":"排序","path":"/tags/排序","postSlugs":[{"postType":"articles","postPagePath":"/articles/Sort-algorithm"}]},{"tag":"算法竞赛","slug":"算法竞赛","path":"/tags/算法竞赛","postSlugs":[{"postType":"articles","postPagePath":"/articles/Handy-heap-cheat-sheet"}]},{"tag":"设计模式","slug":"设计模式","path":"/tags/设计模式","postSlugs":[{"postType":"articles","postPagePath":"/articles/The-beauty-of-design-parten"}]},{"tag":"笔记","slug":"笔记","path":"/tags/笔记","postSlugs":[{"postType":"articles","postPagePath":"/articles/The-beauty-of-design-parten"}]},{"tag":"GitHub","slug":"github","path":"/tags/github","postSlugs":[{"postType":"articles","postPagePath":"/articles/create-blog-cicd-by-github"}]},{"tag":"AWS","slug":"aws","path":"/tags/aws","postSlugs":[{"postType":"articles","postPagePath":"/articles/create-blog-cicd-by-github"}]},{"tag":"CI/CD","slug":"ci-cd","path":"/tags/ci-cd","postSlugs":[{"postType":"articles","postPagePath":"/articles/create-blog-cicd-by-github"}]},{"tag":"IaC","slug":"iac","path":"/tags/iac","postSlugs":[{"postType":"articles","postPagePath":"/articles/create-blog-cicd-by-github"}]},{"tag":"DevOps","slug":"devops","path":"/tags/devops","postSlugs":[{"postType":"articles","postPagePath":"/articles/create-blog-cicd-by-github"},{"postType":"articles","postPagePath":"/articles/introduction-for-k8s"},{"postType":"articles","postPagePath":"/articles/introduction-for-k8s-2"},{"postType":"ideas","postPagePath":"/ideas/newest"}]},{"tag":"VSCode","slug":"vscode","path":"/tags/vscode","postSlugs":[{"postType":"articles","postPagePath":"/articles/use-paste-image-and-vscode-memo"}]},{"tag":"Hexo","slug":"hexo","path":"/tags/hexo","postSlugs":[{"postType":"articles","postPagePath":"/articles/use-paste-image-and-vscode-memo"}]},{"tag":"JavaScript","slug":"javascript","path":"/tags/javascript","postSlugs":[{"postType":"articles","postPagePath":"/articles/use-paste-image-and-vscode-memo"}]},{"tag":"Kubernetes","slug":"kubernetes","path":"/tags/kubernetes","postSlugs":[{"postType":"articles","postPagePath":"/articles/introduction-for-k8s"},{"postType":"articles","postPagePath":"/articles/introduction-for-k8s-2"},{"postType":"ideas","postPagePath":"/ideas/newest"}]},{"tag":"Docker","slug":"docker","path":"/tags/docker","postSlugs":[{"postType":"articles","postPagePath":"/articles/introduction-for-k8s"},{"postType":"articles","postPagePath":"/articles/introduction-for-k8s-2"},{"postType":"ideas","postPagePath":"/ideas/newest"}]},{"tag":"Cloud Native","slug":"cloud-native","path":"/tags/cloud-native","postSlugs":[{"postType":"articles","postPagePath":"/articles/introduction-for-k8s"},{"postType":"articles","postPagePath":"/articles/introduction-for-k8s-2"},{"postType":"ideas","postPagePath":"/ideas/newest"}]},{"tag":"Cursor","slug":"cursor","path":"/tags/cursor","postSlugs":[{"postType":"articles","postPagePath":"/articles/try-cursor-and-thinking"}]},{"tag":"可视化","slug":"可视化","path":"/tags/可视化","postSlugs":[{"postType":"ideas","postPagePath":"/ideas/blog 画图 Iframe 测试"}]},{"tag":"数学","slug":"数学","path":"/tags/数学","postSlugs":[{"postType":"ideas","postPagePath":"/ideas/blog 画图 Iframe 测试"}]},{"tag":"工具","slug":"工具","path":"/tags/工具","postSlugs":[{"postType":"ideas","postPagePath":"/ideas/blog 画图 Iframe 测试"}]},{"tag":"Nextjs","slug":"nextjs","path":"/tags/nextjs","postSlugs":[{"postType":"ideas","postPagePath":"/ideas/blog-in-next"},{"postType":"ideas","postPagePath":"/ideas/blog-syntax"}]},{"tag":"Linux","slug":"linux","path":"/tags/linux","postSlugs":[{"postType":"ideas","postPagePath":"/ideas/Linux Systemd"},{"postType":"ideas","postPagePath":"/ideas/Linux 信号处理 —— Signal"},{"postType":"ideas","postPagePath":"/ideas/Linux 内存 —— 内存分页、分段"},{"postType":"ideas","postPagePath":"/ideas/Linux 内存 —— 堆和栈"},{"postType":"ideas","postPagePath":"/ideas/Linux 内存 —— 虚拟内存"},{"postType":"ideas","postPagePath":"/ideas/Linux 调度 —— 进程与线程"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/executable-file-formats"}]},{"tag":"systemctl","slug":"systemctl","path":"/tags/systemctl","postSlugs":[{"postType":"ideas","postPagePath":"/ideas/Linux Systemd"}]},{"tag":"journalctl","slug":"journalctl","path":"/tags/journalctl","postSlugs":[{"postType":"ideas","postPagePath":"/ideas/Linux Systemd"}]},{"tag":"timedatectl","slug":"timedatectl","path":"/tags/timedatectl","postSlugs":[{"postType":"ideas","postPagePath":"/ideas/Linux Systemd"}]},{"tag":"BasicKnowledge","slug":"basicknowledge","path":"/tags/basicknowledge","postSlugs":[{"postType":"ideas","postPagePath":"/ideas/Linux Systemd"},{"postType":"ideas","postPagePath":"/ideas/Linux 信号处理 —— Signal"},{"postType":"ideas","postPagePath":"/ideas/Linux 内存 —— 内存分页、分段"},{"postType":"ideas","postPagePath":"/ideas/Linux 内存 —— 堆和栈"},{"postType":"ideas","postPagePath":"/ideas/Linux 内存 —— 虚拟内存"},{"postType":"ideas","postPagePath":"/ideas/Linux 调度 —— 进程与线程"}]},{"tag":"Operation","slug":"operation","path":"/tags/operation","postSlugs":[{"postType":"ideas","postPagePath":"/ideas/Linux Systemd"},{"postType":"ideas","postPagePath":"/ideas/Linux 信号处理 —— Signal"},{"postType":"ideas","postPagePath":"/ideas/Linux 内存 —— 内存分页、分段"},{"postType":"ideas","postPagePath":"/ideas/Linux 内存 —— 虚拟内存"}]},{"tag":"Signal","slug":"signal","path":"/tags/signal","postSlugs":[{"postType":"ideas","postPagePath":"/ideas/Linux 信号处理 —— Signal"}]},{"tag":"memory","slug":"memory","path":"/tags/memory","postSlugs":[{"postType":"ideas","postPagePath":"/ideas/Linux 内存 —— 内存分页、分段"},{"postType":"ideas","postPagePath":"/ideas/Linux 内存 —— 堆和栈"},{"postType":"ideas","postPagePath":"/ideas/Linux 内存 —— 虚拟内存"}]},{"tag":"schedule","slug":"schedule","path":"/tags/schedule","postSlugs":[{"postType":"ideas","postPagePath":"/ideas/Linux 调度 —— 进程与线程"}]},{"tag":"Cloud Computing","slug":"cloud-computing","path":"/tags/cloud-computing","postSlugs":[{"postType":"ideas","postPagePath":"/ideas/newest"}]},{"tag":"PyTorch","slug":"pytorch","path":"/tags/pytorch","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/deep-learning-model-formats"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/pytorch-backpropagation-mechanism"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/pytorch-model-save-and-load"}]},{"tag":"ONNX","slug":"onnx","path":"/tags/onnx","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/deep-learning-model-formats"}]},{"tag":"深度学习","slug":"深度学习","path":"/tags/深度学习","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/deep-learning-model-formats"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/lora-matrix-initialization-strategy"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/pytorch-backpropagation-mechanism"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/stable-diffusion-unet-structure"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/stable-diffusion-lora-training-methods"}]},{"tag":"模型部署","slug":"模型部署","path":"/tags/模型部署","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/deep-learning-model-formats"}]},{"tag":"学习笔记","slug":"学习笔记","path":"/tags/学习笔记","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/deep-learning-model-formats"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/opencv-coordinate-system-conventions"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/executable-file-formats"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/lora-matrix-initialization-strategy"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/pytorch-backpropagation-mechanism"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/mqtt-protocol-principles-applications"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/stable-diffusion-unet-structure"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/stable-diffusion-lora-training-methods"}]},{"tag":"OpenCV","slug":"opencv","path":"/tags/opencv","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/opencv-coordinate-system-conventions"}]},{"tag":"图像处理","slug":"图像处理","path":"/tags/图像处理","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/opencv-coordinate-system-conventions"}]},{"tag":"Rust","slug":"rust","path":"/tags/rust","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/cpp-rvo-and-rust-move-semantics"}]},{"tag":"编程语言","slug":"编程语言","path":"/tags/编程语言","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/cpp-rvo-and-rust-move-semantics"}]},{"tag":"Windows","slug":"windows","path":"/tags/windows","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/executable-file-formats"}]},{"tag":"macOS","slug":"macos","path":"/tags/macos","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/executable-file-formats"}]},{"tag":"可执行文件","slug":"可执行文件","path":"/tags/可执行文件","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/executable-file-formats"}]},{"tag":"LoRA","slug":"lora","path":"/tags/lora","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/lora-matrix-initialization-strategy"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/stable-diffusion-unet-structure"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/stable-diffusion-lora-training-methods"}]},{"tag":"参数高效微调","slug":"参数高效微调","path":"/tags/参数高效微调","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/lora-matrix-initialization-strategy"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/stable-diffusion-unet-structure"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/stable-diffusion-lora-training-methods"}]},{"tag":"模型训练","slug":"模型训练","path":"/tags/模型训练","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/lora-matrix-initialization-strategy"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/stable-diffusion-unet-structure"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/stable-diffusion-lora-training-methods"}]},{"tag":"反向传播","slug":"反向传播","path":"/tags/反向传播","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/pytorch-backpropagation-mechanism"}]},{"tag":"自动微分","slug":"自动微分","path":"/tags/自动微分","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/pytorch-backpropagation-mechanism"}]},{"tag":"GoLang","slug":"golang","path":"/tags/golang","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/golang-new-and-memory-management"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/golang-scheduler-preemption"}]},{"tag":"Memory Management","slug":"memory-management","path":"/tags/memory-management","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/golang-new-and-memory-management"}]},{"tag":"Deep Learning","slug":"deep-learning","path":"/tags/deep-learning","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/pytorch-model-save-and-load"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/resnet-math-and-gradient-vanishing"}]},{"tag":"Model Management","slug":"model-management","path":"/tags/model-management","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/pytorch-model-save-and-load"}]},{"tag":"Neural Networks","slug":"neural-networks","path":"/tags/neural-networks","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/resnet-math-and-gradient-vanishing"}]},{"tag":"ResNet","slug":"resnet","path":"/tags/resnet","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/resnet-math-and-gradient-vanishing"}]},{"tag":"Mathematics","slug":"mathematics","path":"/tags/mathematics","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/resnet-math-and-gradient-vanishing"}]},{"tag":"协议","slug":"协议","path":"/tags/协议","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/mqtt-protocol-principles-applications"}]},{"tag":"IoT","slug":"iot","path":"/tags/iot","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/mqtt-protocol-principles-applications"}]},{"tag":"物联网","slug":"物联网","path":"/tags/物联网","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/mqtt-protocol-principles-applications"}]},{"tag":"消息队列","slug":"消息队列","path":"/tags/消息队列","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/mqtt-protocol-principles-applications"}]},{"tag":"Stable Diffusion","slug":"stable-diffusion","path":"/tags/stable-diffusion","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/stable-diffusion-unet-structure"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/stable-diffusion-lora-training-methods"}]},{"tag":"Concurrency","slug":"concurrency","path":"/tags/concurrency","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/golang-scheduler-preemption"}]},{"tag":"Scheduler","slug":"scheduler","path":"/tags/scheduler","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/golang-scheduler-preemption"}]},{"tag":"Goroutine","slug":"goroutine","path":"/tags/goroutine","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/golang-scheduler-preemption"}]},{"tag":"test","slug":"test","path":"/tags/test","postSlugs":[{"postType":"testwiki","postPagePath":"/testwiki/page1"},{"postType":"testwiki","postPagePath":"/testwiki/page1/subpage1"},{"postType":"testwiki","postPagePath":"/testwiki/page2"},{"postType":"testwiki","postPagePath":"/testwiki/page2/subpage2"},{"postType":"testwiki","postPagePath":"/testwiki/page2/subpage3"},{"postType":"testwiki","postPagePath":"/testwiki/page2/subpage3/subpage34"},{"postType":"testwiki","postPagePath":"/testwiki/page3/subpage1"},{"postType":"testwiki","postPagePath":"/testwiki/page3/subpage2"},{"postType":"testwiki","postPagePath":"/testwiki/page3/subpage3"}]},{"tag":"wiki","slug":"wiki","path":"/tags/wiki","postSlugs":[{"postType":"testwiki","postPagePath":"/testwiki/page1"},{"postType":"testwiki","postPagePath":"/testwiki/page1/subpage1"},{"postType":"testwiki","postPagePath":"/testwiki/page2"},{"postType":"testwiki","postPagePath":"/testwiki/page2/subpage2"},{"postType":"testwiki","postPagePath":"/testwiki/page2/subpage3"},{"postType":"testwiki","postPagePath":"/testwiki/page2/subpage3/subpage34"},{"postType":"testwiki","postPagePath":"/testwiki/page3/subpage1"},{"postType":"testwiki","postPagePath":"/testwiki/page3/subpage2"},{"postType":"testwiki","postPagePath":"/testwiki/page3/subpage3"}]},{"tag":"page1","slug":"page1","path":"/tags/page1","postSlugs":[{"postType":"testwiki","postPagePath":"/testwiki/page1"},{"postType":"testwiki","postPagePath":"/testwiki/page1/subpage1"}]},{"tag":"subpage1","slug":"subpage1","path":"/tags/subpage1","postSlugs":[{"postType":"testwiki","postPagePath":"/testwiki/page1/subpage1"},{"postType":"testwiki","postPagePath":"/testwiki/page3/subpage1"}]},{"tag":"page2","slug":"page2","path":"/tags/page2","postSlugs":[{"postType":"testwiki","postPagePath":"/testwiki/page2"},{"postType":"testwiki","postPagePath":"/testwiki/page2/subpage2"},{"postType":"testwiki","postPagePath":"/testwiki/page2/subpage3"},{"postType":"testwiki","postPagePath":"/testwiki/page2/subpage3/subpage34"}]},{"tag":"subpage2","slug":"subpage2","path":"/tags/subpage2","postSlugs":[{"postType":"testwiki","postPagePath":"/testwiki/page2/subpage2"},{"postType":"testwiki","postPagePath":"/testwiki/page3/subpage2"}]},{"tag":"subpage3","slug":"subpage3","path":"/tags/subpage3","postSlugs":[{"postType":"testwiki","postPagePath":"/testwiki/page2/subpage3"},{"postType":"testwiki","postPagePath":"/testwiki/page2/subpage3/subpage34"},{"postType":"testwiki","postPagePath":"/testwiki/page3/subpage3"}]},{"tag":"subpage34","slug":"subpage34","path":"/tags/subpage34","postSlugs":[{"postType":"testwiki","postPagePath":"/testwiki/page2/subpage3/subpage34"}]},{"tag":"page3","slug":"page3","path":"/tags/page3","postSlugs":[{"postType":"testwiki","postPagePath":"/testwiki/page3/subpage1"},{"postType":"testwiki","postPagePath":"/testwiki/page3/subpage2"},{"postType":"testwiki","postPagePath":"/testwiki/page3/subpage3"}]}],"selectedTagInfo":{"tag":"Deep Learning","slug":"deep-learning","path":"/tags/deep-learning","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/pytorch-model-save-and-load"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/resnet-math-and-gradient-vanishing"}]},"posts":[{"pathMapping":{"filePath":"public/content/learn_from_ai/2025-03-07-pytorch-model-save-and-load.md","pagePath":"/learn_from_ai/pytorch-model-save-and-load","slug":"pytorch-model-save-and-load"},"meta":{"content":"\n\u003e 本文为与 DeepSeek 对话记录，深入探讨 PyTorch 中模型的保存和加载机制，包括不同的保存方式、最佳实践以及常见问题的解决方案。\n\n## Q: PyTorch 中所谓的保存模型/加载模型，指的是保存/加载什么？是 state_dict 吗？\n\n\u003e [!reasoning]-\n\u003e\n\u003e 嗯，我现在要弄清楚 PyTorch 中保存和加载模型到底是怎么回事。用户问是不是保存和加载 state_dict，我需要仔细想一想这个问题。\n\u003e\n\u003e 首先，我记得在 PyTorch 里训练模型的时候，模型的可学习参数，比如各层的权重和偏置，是存放在模型的 parameters 中的。而 state_dict 应该是一个保存这些参数的东西。对，每个 torch.nn.Module 都有 state_dict，它是一个字典，将每个层映射到对应的参数张量。\n\u003e\n\u003e 那保存模型的时候，有两种常见的方法。一种是直接保存整个模型，使用 torch.save(model, 'model.pth')。这样的话，保存的是整个模型对象，包括结构定义和参数。不过这种方法可能有缺点，比如当模型定义所在的文件路径变化时，加载的时候可能会找不到类定义，导致错误。所以通常更推荐另一种方法，就是只保存 state_dict，这样需要的时候再加载到一个定义好的模型结构中。\n\u003e\n\u003e 所以用户的问题是说保存模型是不是保存 state_dict，对吧？是的，通常最佳做法是保存 state_dict，而不是整个模型对象。因为 state_dict 只包含参数，不包含模型结构，这样在加载的时候更灵活。比如，当你想在不同项目中使用同一个模型参数，或者模型类有修改时，加载 state_dict 会更方便。\n\u003e\n\u003e 那加载的时候，就需要先实例化模型，然后用 load_state_dict 方法加载参数。比如：\n\u003e\n\u003e model = MyModelClass(\\*args, \\*\\*kwargs)\n\u003e\n\u003e model.load_state_dict(torch.load('model.pth'))\n\u003e\n\u003e 这样参数就被正确加载到模型里了。而如果保存的是整个模型，加载的时候可以直接用 model = torch.load('model.pth')，但这时候模型类必须在当前作用域可访问，否则会出错。\n\u003e\n\u003e 所以总结一下，保存模型通常指的是保存 state_dict，而加载模型就是加载这个 state_dict 到已经定义好的模型结构中。当然，PyTorch 也允许保存整个模型，但不够灵活，所以推荐用 state_dict 的方式。\n\u003e\n\u003e 另外，可能还有其他需要保存的内容，比如优化器的 state_dict，这样在恢复训练的时候可以接着之前的优化器状态继续训练。这时候保存的 checkpoint 可能包括 model_state_dict、optimizer_state_dict、epoch、loss 等信息。加载的时候需要分别处理这些部分。\n\u003e\n\u003e 但用户的问题主要是关于保存和加载模型本身，所以核心答案应该是 state_dict。不过要说明保存整个模型的情况也存在，但 state_dict 更推荐。所以回答的时候应该涵盖这两种情况，但强调 state_dict 是更常用的方法。\n\n在 PyTorch 中，保存和加载模型的**核心是 `state_dict`**，但具体操作可以灵活选择。以下是详细说明：\n\n---\n\n### 1. **`state_dict` 是什么？**\n\n- **`state_dict`** 是一个 Python 字典对象，它将模型的每一层（如卷积层、全连接层等）映射到对应的参数张量（权重和偏置）。\n- 例如，一个简单的神经网络可能包含：\n  ```python\n  model.state_dict() = {\n      'conv1.weight': tensor(...),\n      'conv1.bias': tensor(...),\n      'fc1.weight': tensor(...),\n      'fc1.bias': tensor(...),\n      ...\n  }\n  ```\n- **优化器**（如 `torch.optim.SGD`）也有自己的 `state_dict`，保存优化器的状态（如动量缓冲等）。\n\n---\n\n### 2. **保存模型的两种方式**\n\n#### **方式 1：仅保存 `state_dict`（推荐）**\n\n- **代码示例**：\n  ```python\n  torch.save(model.state_dict(), 'model_weights.pth')\n  ```\n- **优点**：\n  - 文件体积小，只保存参数，不保存模型结构。\n  - 加载灵活：需先实例化模型结构，再加载参数。\n  - 避免因代码变更（如类名修改）导致的加载失败。\n\n#### **方式 2：保存整个模型（不推荐）**\n\n- **代码示例**：\n  ```python\n  torch.save(model, 'entire_model.pth')\n  ```\n- **缺点**：\n  - 文件体积大，包含模型结构和参数。\n  - 依赖原始代码环境（模型类的定义必须存在），否则加载时会报错。\n\n---\n\n### 3. **加载模型的对应方法**\n\n#### **加载 `state_dict`（需先构建模型结构）**\n\n```python\nmodel = MyModelClass()  # 必须与保存时的模型结构一致\nmodel.load_state_dict(torch.load('model_weights.pth'))\nmodel.eval()  # 切换到推理模式（关闭 dropout 等）\n```\n\n#### **加载整个模型（直接使用）**\n\n```python\nmodel = torch.load('entire_model.pth')\nmodel.eval()\n```\n\n---\n\n### 4. **实际场景中的最佳实践**\n\n- **保存训练检查点（Checkpoint）**：\n  通常需要保存 `state_dict` 之外的信息（如优化器状态、训练步数等）：\n\n  ```python\n  checkpoint = {\n      'model_state_dict': model.state_dict(),\n      'optimizer_state_dict': optimizer.state_dict(),\n      'epoch': 100,\n      'loss': loss,\n  }\n  torch.save(checkpoint, 'checkpoint.pth')\n  ```\n\n- **加载检查点**：\n  ```python\n  checkpoint = torch.load('checkpoint.pth')\n  model.load_state_dict(checkpoint['model_state_dict'])\n  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n  epoch = checkpoint['epoch']\n  ```\n\n---\n\n### 5. **关键总结**\n\n- **保存模型**：本质是保存模型的 `state_dict`（推荐），但也可以保存整个模型。\n- **加载模型**：\n  - 若保存的是 `state_dict`，需先实例化模型结构，再加载参数。\n  - 若保存的是整个模型，直接加载但需保证代码兼容性。\n- **灵活性**：使用 `state_dict` 更安全、更灵活，适合跨项目或模型结构可能变化的场景。\n\n## Q: model 的 config 又是什么东西？是超参吗？\n\n\u003e [!reasoning]-\n\u003e\n\u003e 嗯，用户之前问过 PyTorch 中保存和加载模型的概念，现在又接着问\"model 的 config 是什么东西？是超参吗？\"我需要仔细分析这个问题，确保理解用户的真实需求。\n\u003e\n\u003e 首先，用户已经了解 state_dict，现在转向模型配置（config）。可能他们在实际项目中遇到了需要保存或管理模型结构的情况，或者在阅读代码时遇到了 config 这个术语。用户想知道 config 具体指什么，是否包括超参数。\n\u003e\n\u003e 接下来，我需要明确\"model config\"的定义。在机器学习中，模型配置通常指的是定义模型结构的参数，比如神经网络的层数、每层的神经元数量、激活函数类型等。而超参数可能包括学习率、批量大小、优化器类型等训练过程中的设置。但有时候这两者之间的界限并不严格，特别是当某些结构参数也被视为超参数时。\n\u003e\n\u003e 用户可能混淆了模型配置和超参数，需要区分这两者。需要举例说明，比如在 Transformer 模型中，config 可能包含隐藏层大小、头数等，而超参数则是训练时的设置。但有时，例如在 HuggingFace 的库中，模型配置类（如 BertConfig）确实包含了模型结构的所有参数，这可能让用户产生疑问。\n\u003e\n\u003e 另外，用户可能想知道为什么需要单独保存 config。可能他们在保存模型时，除了 state_dict 之外，还需要保存模型结构的信息，以便重新实例化模型。比如，如果只保存 state_dict，加载时需要先有模型类的定义和 config 参数，才能正确创建模型实例，然后加载权重。\n\u003e\n\u003e 需要解释 config 的作用：它定义了模型的结构，是重建模型实例的必要信息。与超参数不同，config 主要涉及模型架构，而超参数涉及训练过程。但有些情况下，两者可能有重叠，比如学习率可能被包含在训练配置中，而层数在模型配置中。\n\u003e\n\u003e 还需要考虑用户可能的实际应用场景。比如，使用 HuggingFace 的 Transformers 库时，模型配置被明确分离，用户需要保存 config.json 和 model.bin。这时候，config 保存模型结构，model.bin 保存 state_dict。用户可能在这种情况下遇到 config 的概念，需要解释这种设计的原因和好处。\n\u003e\n\u003e 此外，用户可能想知道如何管理 config，比如使用 YAML 或 JSON 文件来存储模型结构参数，方便版本控制和实验复现。这也是为什么分开保存 config 和 state_dict 更灵活，因为修改结构时只需调整 config 而不影响训练好的权重。\n\u003e\n\u003e 最后，要确保回答结构清晰，分点说明，给出代码示例，并比较 config 与超参数的区别和联系。同时，注意用户可能的技术水平，避免使用过于专业的术语，保持解释的易懂性。\n\n在机器学习中，**模型的 `config`（配置）** 通常指**定义模型结构的所有参数**，而超参（Hyperparameters）更多指**控制训练过程的参数**。这两者有时会有重叠，但核心区别在于作用对象。以下是详细解释：\n\n---\n\n### 1. **什么是模型的 `config`？**\n\n- **模型配置**（Model Configuration）是定义**模型结构**的一组参数，例如：\n\n  - 神经网络的层数、每层的神经元数量\n  - 卷积核大小、步长（Stride）、填充（Padding）\n  - 激活函数类型（如 ReLU、Sigmoid）\n  - 注意力机制的头数（如 Transformer 中的 `num_heads`）\n  - 词嵌入维度（如 NLP 模型中的 `hidden_size`）\n\n- **示例**（以 Transformer 模型为例）：\n  ```python\n  config = {\n      \"num_layers\": 12,          # Transformer 层数\n      \"hidden_size\": 768,         # 隐藏层维度\n      \"num_attention_heads\": 12,  # 注意力头数\n      \"intermediate_size\": 3072,  # FeedForward 层维度\n      \"vocab_size\": 30522,        # 词表大小\n  }\n  ```\n\n---\n\n### 2. **模型 `config` 与超参数的区别**\n\n| **类别**     | **模型配置（Config）**                 | **超参数（Hyperparameters）**                                  |\n| ------------ | -------------------------------------- | -------------------------------------------------------------- |\n| **作用对象** | 模型结构                               | 训练过程                                                       |\n| **典型参数** | 层数、维度、注意力头数、卷积核大小     | 学习率、批量大小（Batch Size）、优化器类型、训练轮数（Epochs） |\n| **保存目的** | 重建模型结构（如加载 `state_dict` 前） | 复现训练过程（如调参、实验对比）                               |\n| **修改频率** | 低频（模型结构稳定后很少改动）         | 高频（需反复调整优化）                                         |\n\n---\n\n### 3. **为什么需要单独管理 `config`？**\n\n- **场景 1：重建模型**  \n  若仅保存 `state_dict`（模型权重），加载时必须**先根据 `config` 重建模型结构**，才能加载权重：\n\n  ```python\n  # 保存\n  torch.save(model.state_dict(), \"model_weights.pth\")\n  with open(\"model_config.json\", \"w\") as f:\n      json.dump(config, f)\n\n  # 加载\n  with open(\"model_config.json\", \"r\") as f:\n      config = json.load(f)\n  model = MyModel(**config)  # 根据 config 实例化模型\n  model.load_state_dict(torch.load(\"model_weights.pth\"))\n  ```\n\n- **场景 2：版本控制与实验复现**  \n  将 `config` 保存为 JSON/YAML 文件，便于记录不同模型结构的实验效果。\n\n- **场景 3：共享模型**  \n  开源社区常用模式（如 HuggingFace Transformers）：\n  - `config.json`：定义模型结构\n  - `pytorch_model.bin`：保存 `state_dict`\n\n---\n\n### 4. **`config` 与超参数的重叠情况**\n\n某些参数可能同时影响模型结构和训练，例如：\n\n- **Dropout 比率**：既是模型结构的一部分，也被视为超参数。\n- **词嵌入维度**：影响模型结构，但可能因训练资源调整（如显存不足时调小维度）。\n\n此时，可以**将两者统一管理**，但建议分开存储：\n\n```python\n# 统一配置文件（config.yaml）\nmodel:\n  num_layers: 12\n  hidden_size: 768\ntraining:\n  learning_rate: 1e-4\n  batch_size: 32\n```\n\n---\n\n### 5. **实际代码示例**\n\n#### 定义模型时使用 `config`：\n\n```python\nclass TransformerModel(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.embedding = nn.Embedding(config[\"vocab_size\"], config[\"hidden_size\"])\n        self.layers = nn.ModuleList([TransformerBlock(config) for _ in range(config[\"num_layers\"])])\n        # ...\n\n# 初始化模型\nconfig = {\"vocab_size\": 30000, \"hidden_size\": 512, \"num_layers\": 6}\nmodel = TransformerModel(config)\n```\n\n#### 保存与加载完整模型（含结构和权重）：\n\n```python\n# 保存（不推荐，但某些场景需要）\nfull_model = {\"config\": config, \"state_dict\": model.state_dict()}\ntorch.save(full_model, \"full_model.pth\")\n\n# 加载\nloaded = torch.load(\"full_model.pth\")\nmodel = TransformerModel(loaded[\"config\"])\nmodel.load_state_dict(loaded[\"state_dict\"])\n```\n\n---\n\n### 6. **总结**\n\n- **模型 `config`**：定义模型结构的参数（如层数、维度），是**重建模型**的必需信息。\n- **超参数**：控制训练过程的参数（如学习率、批量大小），影响模型如何学习。\n- **最佳实践**：\n  - 始终保存 `config`（如 JSON 文件），确保模型可复现。\n  - 分开管理模型配置和训练超参数，避免混淆。\n\n\u003e [!info] 亮曰\n\u003e\n\u003e - Config 主要是定义模型结构。会根据 Config 决定有多少层等。\n\u003e - 超参主要是训练过程中的学习率、 Epochs 等，复现训练过程时需要，但与模型结构无关，只与训练过程有关。\n\n## Q: 所谓\"权重\"就是指 state_dict 中的内容吗？\n\n\u003e [!reasoning]-\n\u003e\n\u003e 嗯，用户问：\"所谓'权重'就是指 state_dict 中的内容吗？\"这个问题看起来是想确认 PyTorch 中的权重和 state_dict 之间的关系。首先，我需要回顾一下之前的对话，确保回答的一致性。\n\u003e\n\u003e 之前已经解释了 state_dict 是保存模型参数的核心，里面包含了各层的权重和偏置。用户可能现在对\"权重\"这个术语的具体指向有疑问，需要明确权重是否等同于 state_dict 中的所有内容。\n\u003e\n\u003e 首先，我应该明确\"权重\"在机器学习中的定义。通常，权重指的是模型中的可学习参数，比如线性层中的权重矩阵和偏置向量。而 state_dict 不仅包括这些权重，还可能包括其他参数，比如 BatchNorm 层的均值和方差，或者优化器的状态。因此，state_dict 的内容可能比单纯的\"权重\"更广泛。\n\u003e\n\u003e 接下来，需要区分 state_dict 中的不同部分。模型和优化器都有自己的 state_dict。模型的 state_dict 包含各层的参数，而优化器的 state_dict 包含优化器的状态，如动量缓存等。用户的问题可能集中在模型的 state_dict 中的权重部分，而是否包括其他参数需要澄清。\n\u003e\n\u003e 另外，用户可能对如何正确保存和加载模型有更深入的理解需求。比如，保存 state_dict 时，是否只保存了权重，还是还有其他必要的参数？需要说明 state_dict 中的内容对于模型重建的重要性，以及权重在其中的角色。\n\u003e\n\u003e 可能用户在实际操作中遇到了问题，比如加载模型时结构不匹配，或者参数未正确加载，因此需要明确 state_dict 中的内容。需要举例说明，比如一个简单的线性模型，展示其 state_dict 中的键值对，明确哪些是权重，哪些是偏置，或者其他类型的参数。\n\u003e\n\u003e 还需要考虑用户可能的误解，比如认为 state_dict 仅包含权重，而忽略了其他必要的参数，导致模型无法正确运行。因此，强调 state_dict 包含所有必要的参数，而权重是其中的一部分，但还有其他如偏置、BatchNorm 的参数等。\n\u003e\n\u003e 此外，用户可能关心如何仅保存或操作权重，比如迁移学习中的部分参数加载。这时候需要说明如何从 state_dict 中选择性地提取或加载特定的权重部分。\n\u003e\n\u003e 总结来说，回答需要明确以下几点：\n\u003e\n\u003e 1. 权重是模型中的可学习参数，如线性层的权重矩阵。\n\u003e\n\u003e 2. state_dict 包含模型的所有参数，包括权重、偏置以及其他层特定的参数。\n\u003e\n\u003e 3. 模型的 state_dict 与优化器的 state_dict 不同，后者包含优化器状态。\n\u003e\n\u003e 4. 正确加载模型需要确保 state_dict 的结构与当前模型结构匹配。\n\u003e\n\u003e 5. 示例说明 state_dict 中的具体内容，帮助用户直观理解。\n\u003e\n\u003e 同时，要注意用词准确，避免混淆，比如\"参数\"和\"权重\"的区别，确保用户能清晰理解两者的包含关系。可能还需要提到在保存和加载时的最佳实践，比如如何结合 config 来重建模型结构，再加载 state_dict 中的参数，以确保模型的正确性。\n\u003e\n\u003e 最后，检查是否有遗漏点，比如是否提到 eval()模式的影响，或者训练/推理时加载参数的注意事项，但根据问题范围，可能不需要展开，除非用户有进一步的问题。\n\n在 PyTorch 中，**\"权重\"确实是 `state_dict` 中的核心内容**，但 `state_dict` 包含的信息可能比\"权重\"更广泛。以下是详细解释：\n\n---\n\n### 1. **\"权重\"是什么？**\n\n- **权重（Weights）** 是模型中**可学习的参数**，例如：\n  - 全连接层（`nn.Linear`）中的权重矩阵（`weight`）和偏置（`bias`）。\n  - 卷积层（`nn.Conv2d`）的卷积核参数。\n  - 嵌入层（`nn.Embedding`）的词向量矩阵。\n- 这些参数通过反向传播和优化器（如 SGD、Adam）在训练过程中逐步更新。\n\n---\n\n### 2. **`state_dict` 中的内容**\n\n`state_dict` 是 PyTorch 中模型或优化器的**状态字典**，具体包含：\n\n- **对模型而言**：\n  - 所有权重（`weight`）、偏置（`bias`）。\n  - 其他**与层相关的参数**，例如：\n    - `BatchNorm` 层的 `running_mean` 和 `running_var`（在推理时使用的均值和方差）。\n    - `LSTM` 或 `GRU` 中的隐藏状态缓存（如果模型设计时显式存储了这些状态）。\n  ```python\n  # 示例：一个简单模型的 state_dict\n  model = nn.Sequential(\n      nn.Linear(10, 20),\n      nn.ReLU(),\n      nn.BatchNorm1d(20)\n  )\n  print(model.state_dict().keys())\n  # 输出：\n  # ['0.weight', '0.bias', '2.weight', '2.bias', '2.running_mean', '2.running_var', '2.num_batches_tracked']\n  ```\n- **对优化器而言**：\n  - 优化器的状态（如动量缓存、历史梯度等）。\n  ```python\n  optimizer = torch.optim.Adam(model.parameters())\n  print(optimizer.state_dict().keys())\n  # 输出：\n  # ['state', 'param_groups']\n  ```\n\n---\n\n### 3. **\"权重\"与 `state_dict` 的关系**\n\n- **`state_dict` 包含权重，但不仅限于权重**：\n  - 权重是 `state_dict` 中的一部分（如 `conv1.weight`, `fc.bias`）。\n  - `state_dict` 还可能包含**非可学习的参数**（如 `BatchNorm` 的统计量 `running_mean`）。\n  - 对于复杂模型（如 Transformer），还可能包含位置编码、注意力掩码等参数。\n- **总结**：\n  - **权重是 `state_dict` 的核心内容**，但 `state_dict` 是更全面的模型状态表示。\n\n---\n\n### 4. **为什么需要 `state_dict` 而不仅仅是权重？**\n\n- **完整恢复模型状态**：\n  如果仅保存权重，忽略 `BatchNorm` 的 `running_mean` 等参数，在推理时会导致统计量错误，影响模型性能。\n- **兼容性**：\n  加载模型时需确保 `state_dict` 的键（如层名称）与当前模型结构严格匹配，否则会报错 `Missing keys` 或 `Unexpected keys`。\n- **灵活性**：\n  可以手动修改 `state_dict`，例如迁移学习中仅加载部分层的权重。\n\n---\n\n### 5. **操作 `state_dict` 的常见场景**\n\n#### **(1) 查看模型权重**\n\n```python\nfor name, param in model.named_parameters():\n    print(f\"层名: {name}, 参数形状: {param.shape}\")\n```\n\n#### **(2) 选择性加载部分权重（迁移学习）**\n\n```python\npretrained_dict = torch.load('pretrained.pth')\nmodel_dict = model.state_dict()\n\n# 筛选出名称和形状匹配的权重\npretrained_dict = {\n    k: v for k, v in pretrained_dict.items()\n    if k in model_dict and v.shape == model_dict[k].shape\n}\nmodel_dict.update(pretrained_dict)\nmodel.load_state_dict(model_dict)\n```\n\n#### **(3) 手动修改权重**\n\n```python\n# 将第一层卷积的权重置零\nwith torch.no_grad():\n    model.conv1.weight.copy_(torch.zeros_like(model.conv1.weight))\n```\n\n---\n\n### 6. **总结**\n\n- **权重**是模型的可学习参数，是 `state_dict` 的核心内容。\n- **`state_dict`** 是模型状态的完整表示，包括：\n  - 所有权重、偏置。\n  - 非可学习的运行时参数（如 `BatchNorm` 的统计量）。\n- **最佳实践**：\n  - 保存模型时使用 `torch.save(model.state_dict(), ...)`。\n  - 加载时需先构建相同结构的模型，再调用 `model.load_state_dict()`。\n  - 若需调整模型结构，可选择性加载匹配的权重。\n\n\u003e [!info] 亮曰\n\u003e\n\u003e state_dict 包括 Parameter 与 Buffer ，模型的可学习参数——**权重**主要指其中的 Parameter 。\n","title":"PyTorch 模型的保存与加载机制详解","abstract":"\u003e 本文为与 DeepSeek 对话记录，深入探讨 PyTorch 中模型的保存和加载机制，包括不同的保存方式、最佳实践以及常见问题的解决方案。\n\u003e [!reasoning]-\n\u003e","length":433,"created_at":"2025-03-07T13:00:00.000Z","updated_at":"2025-03-07T13:00:00.000Z","tags":["Deep Learning","PyTorch","Model Management"],"license":true,"headingTrees":[{"key":"q-pytorch-中所谓的保存模型加载模型指的是保存加载什么是-state_dict-吗","href":"#q-pytorch-中所谓的保存模型加载模型指的是保存加载什么是-state_dict-吗","heading":2,"title":"Q: PyTorch 中所谓的保存模型/加载模型，指的是保存/加载什么？是 state_dict 吗？","children":[{"key":"1-state_dict-是什么","href":"#1-state_dict-是什么","heading":3,"title":"1. state_dict 是什么？","children":[],"id":"1-state_dict-是什么"},{"key":"2-保存模型的两种方式","href":"#2-保存模型的两种方式","heading":3,"title":"2. 保存模型的两种方式","children":[{"key":"方式-1仅保存-state_dict推荐","href":"#方式-1仅保存-state_dict推荐","heading":4,"title":"方式 1：仅保存 state_dict（推荐）","children":[],"id":"方式-1仅保存-state_dict推荐"},{"key":"方式-2保存整个模型不推荐","href":"#方式-2保存整个模型不推荐","heading":4,"title":"方式 2：保存整个模型（不推荐）","children":[],"id":"方式-2保存整个模型不推荐"}],"id":"2-保存模型的两种方式"},{"key":"3-加载模型的对应方法","href":"#3-加载模型的对应方法","heading":3,"title":"3. 加载模型的对应方法","children":[{"key":"加载-state_dict需先构建模型结构","href":"#加载-state_dict需先构建模型结构","heading":4,"title":"加载 state_dict（需先构建模型结构）","children":[],"id":"加载-state_dict需先构建模型结构"},{"key":"加载整个模型直接使用","href":"#加载整个模型直接使用","heading":4,"title":"加载整个模型（直接使用）","children":[],"id":"加载整个模型直接使用"}],"id":"3-加载模型的对应方法"},{"key":"4-实际场景中的最佳实践","href":"#4-实际场景中的最佳实践","heading":3,"title":"4. 实际场景中的最佳实践","children":[],"id":"4-实际场景中的最佳实践"},{"key":"5-关键总结","href":"#5-关键总结","heading":3,"title":"5. 关键总结","children":[],"id":"5-关键总结"}],"id":"q-pytorch-中所谓的保存模型加载模型指的是保存加载什么是-state_dict-吗"},{"key":"q-model-的-config-又是什么东西是超参吗","href":"#q-model-的-config-又是什么东西是超参吗","heading":2,"title":"Q: model 的 config 又是什么东西？是超参吗？","children":[{"key":"1-什么是模型的-config","href":"#1-什么是模型的-config","heading":3,"title":"1. 什么是模型的 config？","children":[],"id":"1-什么是模型的-config"},{"key":"2-模型-config-与超参数的区别","href":"#2-模型-config-与超参数的区别","heading":3,"title":"2. 模型 config 与超参数的区别","children":[],"id":"2-模型-config-与超参数的区别"},{"key":"3-为什么需要单独管理-config","href":"#3-为什么需要单独管理-config","heading":3,"title":"3. 为什么需要单独管理 config？","children":[],"id":"3-为什么需要单独管理-config"},{"key":"4-config-与超参数的重叠情况","href":"#4-config-与超参数的重叠情况","heading":3,"title":"4. config 与超参数的重叠情况","children":[],"id":"4-config-与超参数的重叠情况"},{"key":"5-实际代码示例","href":"#5-实际代码示例","heading":3,"title":"5. 实际代码示例","children":[{"key":"定义模型时使用-config","href":"#定义模型时使用-config","heading":4,"title":"定义模型时使用 config：","children":[],"id":"定义模型时使用-config"},{"key":"保存与加载完整模型含结构和权重","href":"#保存与加载完整模型含结构和权重","heading":4,"title":"保存与加载完整模型（含结构和权重）：","children":[],"id":"保存与加载完整模型含结构和权重"}],"id":"5-实际代码示例"},{"key":"6-总结","href":"#6-总结","heading":3,"title":"6. 总结","children":[],"id":"6-总结"}],"id":"q-model-的-config-又是什么东西是超参吗"},{"key":"q-所谓权重就是指-state_dict-中的内容吗","href":"#q-所谓权重就是指-state_dict-中的内容吗","heading":2,"title":"Q: 所谓\"权重\"就是指 state_dict 中的内容吗？","children":[{"key":"1-权重是什么","href":"#1-权重是什么","heading":3,"title":"1. \"权重\"是什么？","children":[],"id":"1-权重是什么"},{"key":"2-state_dict-中的内容","href":"#2-state_dict-中的内容","heading":3,"title":"2. state_dict 中的内容","children":[],"id":"2-state_dict-中的内容"},{"key":"3-权重与-state_dict-的关系","href":"#3-权重与-state_dict-的关系","heading":3,"title":"3. \"权重\"与 state_dict 的关系","children":[],"id":"3-权重与-state_dict-的关系"},{"key":"4-为什么需要-state_dict-而不仅仅是权重","href":"#4-为什么需要-state_dict-而不仅仅是权重","heading":3,"title":"4. 为什么需要 state_dict 而不仅仅是权重？","children":[],"id":"4-为什么需要-state_dict-而不仅仅是权重"},{"key":"5-操作-state_dict-的常见场景","href":"#5-操作-state_dict-的常见场景","heading":3,"title":"5. 操作 state_dict 的常见场景","children":[{"key":"1-查看模型权重","href":"#1-查看模型权重","heading":4,"title":"(1) 查看模型权重","children":[],"id":"1-查看模型权重"},{"key":"2-选择性加载部分权重迁移学习","href":"#2-选择性加载部分权重迁移学习","heading":4,"title":"(2) 选择性加载部分权重（迁移学习）","children":[],"id":"2-选择性加载部分权重迁移学习"},{"key":"3-手动修改权重","href":"#3-手动修改权重","heading":4,"title":"(3) 手动修改权重","children":[],"id":"3-手动修改权重"}],"id":"5-操作-state_dict-的常见场景"},{"key":"6-总结-1","href":"#6-总结-1","heading":3,"title":"6. 总结","children":[],"id":"6-总结-1"}],"id":"q-所谓权重就是指-state_dict-中的内容吗"}],"wikiRefAliases":[],"richRefAliases":[]}},{"pathMapping":{"filePath":"public/content/learn_from_ai/2025-03-07-resnet-math-and-gradient-vanishing.md","pagePath":"/learn_from_ai/resnet-math-and-gradient-vanishing","slug":"resnet-math-and-gradient-vanishing"},"meta":{"content":"\n\u003e 本文深入探讨了 ResNet 的数学原理，分析了深度神经网络中的梯度消失问题及其解决方案。通过数学推导和直观解释，帮助读者理解残差连接的作用机制，以及它如何有效地解决了深度神经网络训练中的关键问题。\n\n## Q: ResNet 的数学原理与作用\n\n\u003e [!query]\n\u003e\n\u003e 深入解释 ResNet 的数学原理与作用。提示：你可以使用公式、Mermaid 图表、表格等方式使内容更容易理解。\n\n\u003e [!reasoning]-\n\u003e\n\u003e 嗯，用户让我深入解释 ResNet 的数学原理和作用，还提示可以用公式、图表、表格等。我得先回忆一下 ResNet 的基本概念，然后想想怎么组织内容。\n\u003e\n\u003e 首先，ResNet 的核心是残差学习，对吧？我记得何恺明他们提出的，解决了深度网络中的梯度消失问题。那残差块的结构是关键，应该要详细解释。可能需要画个残差块的示意图，用 Mermaid 的话，应该可以画个简单的框图，比如输入分成两部分，一个经过卷积层，另一个是 shortcut，然后相加。\n\u003e\n\u003e 数学原理方面，残差块的公式是 H(x) = F(x) + x，这里 F(x)是残差函数，目标是让网络学习 F(x) = H(x) - x，而不是直接学习 H(x)。这样在深层网络中，梯度更容易回传，因为加法操作让梯度可以直接流过，对吧？这部分需要用公式展示，可能用 LaTeX 写出来。\n\u003e\n\u003e 然后，为什么残差有效？可能得从反向传播的角度分析，比如导数的计算。当损失函数对 x 求导时，会有两条路径，一个是残差层的导数，另一个是恒等映射的导数，这样即使残差层的梯度很小，至少还有 1 的部分，防止梯度消失。这点需要详细说明，可能用链式法则的公式。\n\u003e\n\u003e 作用方面，ResNet 允许训练更深的网络，比如 ResNet-152，而不会出现退化问题。传统网络层数加深时，准确率会饱和甚至下降，而 ResNet 通过残差学习解决了这个问题。可能需要用图表比较传统网络和 ResNet 在深度增加时的表现差异，或者引用论文中的实验数据。\n\u003e\n\u003e 另外，ResNet 的结构变体，比如不同的残差块设计，如 BasicBlock 和 Bottleneck。Bottleneck 用了 1x1 卷积来降维和升维，减少计算量，这里可以用表格对比两者的结构参数，比如卷积层的大小、通道数变化等。\n\u003e\n\u003e 可能用户还想知道 ResNet 的应用场景，比如在图像分类、目标检测等任务中的效果。不过问题主要是数学原理和作用，这部分可以简要提及，但重点还是原理。\n\u003e\n\u003e 需要检查有没有遗漏的关键点，比如恒等映射的重要性，如果 shortcut 需要调整维度怎么办？这时候可能用 1x1 卷积来匹配维度，这也应该在结构部分说明。\n\u003e\n\u003e 还有，初始化权重的问题，残差网络是否让初始化更容易？可能提到参数初始化的影响减小，因为残差结构本身有助于稳定训练。\n\u003e\n\u003e 总结一下，结构部分用 Mermaid 图，数学部分用公式和导数推导，作用部分用对比和实验数据，结构变体用表格。这样内容会比较全面，也符合用户的要求。\n\n好的！我将从数学原理、网络结构、作用机制等方面深入解释 ResNet，并结合公式、图表和示例进行说明。\n\n---\n\n### 1. ResNet 的核心思想：残差学习\n\nResNet（残差网络）的核心思想是通过引入 **残差块（Residual Block）** 来解决深度神经网络中的梯度消失和网络退化问题。其数学原理可以概括为：\n\n#### 残差公式\n\n假设我们希望网络学习的映射为 $$ H(x) $$，ResNet 将其拆解为：\n\n$$\nH(x) = F(x) + x\n$$\n\n其中：\n\n- $$ x $$ 是输入\n- $$ F(x) = H(x) - x $$ 是残差函数\n\n网络只需学习残差 $$ F(x) $$，而不是直接学习 $$ H(x) $$。这种设计使得深层网络的训练更加稳定。\n\n---\n\n### 2. 残差块的数学实现\n\n#### 残差块结构\n\n一个典型的残差块由以下组件构成：\n\n1. **卷积层**（用于特征提取）\n2. **跳跃连接（Shortcut Connection）**（将输入直接传递到输出）\n\n#### 结构示例（Mermaid 流程图）：\n\n```mermaid\ngraph LR\n    A[输入 x] --\u003e B[卷积层]\n    B --\u003e C[激活函数 ReLU]\n    C --\u003e D[卷积层]\n    D --\u003e E[ReLU]\n    E --\u003e F[\"残差 F(x)\"]\n    A --\u003e G[跳跃连接]\n    F --\u003e H[\"F(x) + x\"]\n    H --\u003e I[\"输出 H(x)\"]\n```\n\n#### 数学表达式\n\n对于第 $$ l $$ 层的残差块：\n\n$$\nx\\_{l+1} = f(x_l + \\mathcal{F}(x_l, W_l))\n$$\n\n其中：\n\n- $$ \\mathcal{F}(x_l, W_l) $$ 是残差函数（由卷积层和激活函数组成）\n- $$ f $$ 是激活函数（通常为 ReLU）\n\n---\n\n### 3. 为什么残差有效？\n\n#### 梯度传播分析\n\n假设损失函数为 $$ L $$，反向传播时梯度计算为：\n\n$$\n\\frac{\\partial L}{\\partial x*l} = \\frac{\\partial L}{\\partial x*{l+1}} \\cdot \\left( 1 + \\frac{\\partial \\mathcal{F}(x_l, W_l)}{\\partial x_l} \\right)\n$$\n\n- 即使 $$ \\frac{\\partial \\mathcal{F}}{\\partial x_l} $$ 趋近于 0，梯度仍然可以通过 $$ 1 $$ 传递（避免梯度消失）\n- 这种设计使得超深层网络（如 ResNet-152）的训练成为可能。\n\n#### 与传统网络的对比\n\n| 特性         | 传统网络         | ResNet           |\n| ------------ | ---------------- | ---------------- |\n| 梯度传播     | 逐层衰减         | 通过残差保持稳定 |\n| 退化问题     | 随深度增加而显著 | 显著缓解         |\n| 最大有效深度 | ~20 层           | 1000+ 层         |\n\n---\n\n### 4. ResNet 的网络结构\n\n#### 典型变体（以 ImageNet 为例）\n\n| 模型       | 层数 | 残差块类型 | 参数数量 |\n| ---------- | ---- | ---------- | -------- |\n| ResNet-18  | 18   | BasicBlock | 11.7M    |\n| ResNet-34  | 34   | BasicBlock | 21.8M    |\n| ResNet-50  | 50   | Bottleneck | 25.6M    |\n| ResNet-101 | 101  | Bottleneck | 44.5M    |\n| ResNet-152 | 152  | Bottleneck | 60.2M    |\n\n#### 两种残差块设计\n\n1. **BasicBlock**（用于浅层网络）：\n\n   ```mermaid\n   graph LR\n       A[输入] --\u003e B[3x3 卷积]\n       B --\u003e C[ReLU]\n       C --\u003e D[3x3 卷积]\n       D --\u003e E[与输入相加]\n       E --\u003e F[输出]\n   ```\n\n2. **Bottleneck**（用于深层网络，减少计算量）：\n   ```mermaid\n   graph LR\n       A[输入] --\u003e B[1x1 卷积降维]\n       B --\u003e C[3x3 卷积]\n       C --\u003e D[1x1 卷积升维]\n       D --\u003e E[与输入相加]\n       E --\u003e F[输出]\n   ```\n\n---\n\n### 5. ResNet 的作用\n\n#### 主要优势\n\n1. **解决梯度消失**：通过跳跃连接传递原始信号。\n2. **缓解网络退化**：即使网络加深，性能不会显著下降。\n3. **灵活性**：适用于多种任务（分类、检测、分割等）。\n\n#### 实验对比（ImageNet 2015）\n\n| 模型       | Top-5 错误率 | 深度 |\n| ---------- | ------------ | ---- |\n| VGG-19     | 8.43%        | 19   |\n| ResNet-34  | 5.71%        | 34   |\n| ResNet-152 | 4.49%        | 152  |\n\n---\n\n### 6. 数学扩展：残差网络的通用性\n\n残差思想可推广到其他操作：\n\n$$\nH(x) = F(x) + \\mathcal{G}(x)\n$$\n\n其中 $$ \\mathcal{G}(x) $$ 可以是：\n\n- 卷积（当输入输出维度不同时）\n- 池化（用于下采样）\n\n---\n\n### 总结\n\nResNet 通过引入残差学习，解决了深度神经网络的训练难题，其核心数学原理是通过跳跃连接保留原始信号，使网络能够高效地学习残差映射。这一设计不仅提升了模型性能，还推动了深度学习在计算机视觉领域的进一步发展。\n\n## Q: 深度网络梯度消失的原理及解决方案\n\n\u003e [!query]\n\u003e\n\u003e 深度网络中，梯度消失是指什么？为什么会出现梯度消失？深入讲述一下其原理。提示：你可以使用公式、Mermaid 图表、表格等方式使内容更容易理解。\n\n\u003e [!reasoning]-\n\u003e\n\u003e 嗯，用户问的是深度网络中的梯度消失问题，需要详细解释它的原理，还有为什么会出现。首先，我得回想一下梯度消失的基本概念。梯度消失是指在训练深度神经网络时，反向传播过程中梯度逐渐变小，导致浅层网络的权重更新缓慢甚至停止，使得模型难以训练。这可能是因为激活函数的选择，比如 sigmoid 或者 tanh，它们的导数在输入值较大或较小时会趋近于零，导致梯度逐层衰减。\n\u003e\n\u003e 接下来，我得考虑如何组织内容。用户希望深入讲解原理，可能需要用公式来说明梯度是如何在反向传播中累积的。比如，链式法则中的各层导数相乘，如果每个导数都小于 1，多次相乘后会趋近于零。这时候可以举一个具体的例子，比如用 sigmoid 激活函数，其导数最大为 0.25，所以经过多层后梯度会指数级下降。\n\u003e\n\u003e 然后，需要分析为什么会出现这种情况。可能的原因包括激活函数的选择、权重初始化不当、网络结构过深等。这里可以对比不同的激活函数，比如 ReLU 如何缓解梯度消失，因为它的导数是 1 或 0，不会导致梯度衰减。另外，初始化方法如 He 初始化也有帮助，但根本原因还是在于链式法则中的乘积效应。\n\u003e\n\u003e 用户还提到可以使用公式、图表或表格，所以可能需要画一个简单的计算图，或者用数学公式展示梯度如何逐层传递。例如，假设每一层的导数是 σ’(z)，那么经过 n 层后，梯度就是初始梯度乘以(σ’(z))^n，如果 σ’(z) \u003c 1，就会指数下降。\n\u003e\n\u003e 另外，可能需要提到 LSTM 和残差连接（ResNet）是如何解决梯度消失的。比如 LSTM 通过门控机制保持梯度流动，而残差连接提供了短路路径，使得梯度可以直接回传，减少了相乘的次数。\n\u003e\n\u003e 在结构安排上，可能需要先定义梯度消失，然后分析原因，再深入数学原理，最后讨论解决方案。需要注意用词准确，比如区分梯度消失和梯度爆炸，虽然都是梯度不稳定问题，但方向不同。\n\u003e\n\u003e 还需要检查是否有遗漏的关键点，比如网络深度的影响，或者不同优化器的效果，比如 Adam 是否有助于缓解梯度消失。不过可能主要原因是激活函数和链式法则，优化器可能影响不大，但可以简单提及。\n\u003e\n\u003e 最后，确保解释清晰，逐步引导读者理解梯度消失的机制，并通过示例或图表帮助理解。可能还需要比较不同激活函数的导数，比如 sigmoid、tanh 和 ReLU，用表格或图表显示它们的导数范围，从而说明为什么 ReLU 更适合深层网络。\n\n### 深度网络中梯度消失的原理分析\n\n#### 1. 梯度消失的定义\n\n梯度消失（Vanishing Gradient）是指深度神经网络在反向传播过程中，梯度随着层数的增加呈现指数级衰减的现象，导致浅层网络的参数更新幅度极小甚至无法更新。\n\n---\n\n#### 2. 梯度消失的数学原理\n\n**反向传播链式法则**是核心机制。假设网络有 $$ L $$ 层，损失函数为 $$ \\mathcal{L} $$，第 $$ l $$ 层的权重梯度为：\n\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial W^{(l)}} = \\frac{\\partial \\mathcal{L}}{\\partial a^{(L)}} \\cdot \\prod\\_{k=l}^{L-1} \\left( \\frac{\\partial a^{(k+1)}}{\\partial a^{(k)}} \\right) \\cdot \\frac{\\partial a^{(l)}}{\\partial W^{(l)}}\n$$\n\n其中 $$ a^{(k)} $$ 是第 $$ k $$ 层的激活值。梯度由多个雅可比矩阵乘积组成，若每项 $$ \\frac{\\partial a^{(k+1)}}{\\partial a^{(k)}} \u003c 1 $$，则梯度会指数衰减。\n\n---\n\n#### 3. 梯度消失的根源\n\n##### (1) 激活函数的选择\n\n- **Sigmoid/Tanh 函数**：导数范围分别为 $$ (0, 0.25] $$ 和 $$ (0, 1] $$，导致梯度逐层缩小。\n  $$\n  \\text{Sigmoid 导数: } \\sigma'(x) = \\sigma(x)(1-\\sigma(x))\n  $$\n  $$\n  \\text{Tanh 导数: } \\tanh'(x) = 1 - \\tanh^2(x)\n  $$\n- **ReLU 函数**：导数为 0 或 1，梯度可稳定传递（但可能引发神经元死亡）。\n\n##### (2) 权重初始化问题\n\n- 若权重 $$ W $$ 初始值过小，则 $$ \\prod W $$ 的乘积会导致输出收缩。\n- 例如：使用均值为 0、方差过小的正态分布初始化时，激活值会逐层坍缩。\n\n##### (3) 深层网络的链式乘积\n\n- 梯度计算涉及 $$ \\prod\\_{k=l}^L \\frac{\\partial a^{(k)}}{\\partial a^{(k-1)}} $$。\n- 假设每层梯度因子为 $$ \\alpha \u003c 1 $$，则总梯度为 $$ \\alpha^{L-l} $$，指数级衰减。\n\n---\n\n#### 4. 梯度消失的直观演示\n\n```mermaid\ngraph LR\n  A[输入层] --\u003e B[隐藏层1: 梯度=0.8]\n  B --\u003e C[隐藏层2: 梯度=0.6]\n  C --\u003e D[...]\n  D --\u003e E[隐藏层N: 梯度=0.2]\n  E --\u003e F[输出层]\n\n  style A fill:#f9f\n  style F fill:#f9f\n```\n\n---\n\n#### 5. 关键参数对比表\n\n| 因素             | 对梯度的影响             | 典型示例                        |\n| ---------------- | ------------------------ | ------------------------------- |\n| 激活函数导数范围 | 导数越小，梯度衰减越快   | Sigmoid（最大导数 0.25）        |\n| 网络深度         | 层数越多，乘积效应越显著 | 100 层 vs 5 层网络              |\n| 权重初始化方差   | 方差过小导致激活值坍缩   | He 初始化 vs 零均值小方差初始化 |\n\n---\n\n#### 6. 解决方案\n\n1. **激活函数优化**：使用 ReLU、Leaky ReLU 等梯度保持能力强的函数。\n2. **残差连接（ResNet）**：通过跳跃连接绕过非线性变换，直接传递梯度。\n3. **批归一化（BatchNorm）**：稳定激活值分布，减缓梯度衰减。\n4. **梯度裁剪/自适应优化器**：间接缓解梯度不稳定问题（如 Adam）。\n\n---\n\n#### 7. 数学示例\n\n假设 5 层网络使用 Sigmoid 激活，每层梯度因子为 0.25：\n\n$$\n\\text{总梯度} = \\text{初始梯度} \\times (0.25)^5 = \\text{初始梯度} \\times 0.00098\n$$\n\n浅层权重更新几乎停滞。\n\n---\n\n通过理解梯度消失的数学机制和工程优化方法，可有效设计更稳定的深度网络结构。\n","title":"ResNet 的数学原理与梯度消失问题分析","abstract":"\u003e 本文深入探讨了 ResNet 的数学原理，分析了深度神经网络中的梯度消失问题及其解决方案。通过数学推导和直观解释，帮助读者理解残差连接的作用机制，以及它如何有效地解决了深度神经网络训练中的关键问题。\n\u003e [!query]\n\u003e","length":309,"created_at":"2025-03-07T10:00:00.000Z","updated_at":"2025-03-07T10:00:00.000Z","tags":["Deep Learning","Neural Networks","ResNet","Mathematics"],"license":true,"headingTrees":[{"key":"q-resnet-的数学原理与作用","href":"#q-resnet-的数学原理与作用","heading":2,"title":"Q: ResNet 的数学原理与作用","children":[{"key":"1-resnet-的核心思想残差学习","href":"#1-resnet-的核心思想残差学习","heading":3,"title":"1. ResNet 的核心思想：残差学习","children":[{"key":"残差公式","href":"#残差公式","heading":4,"title":"残差公式","children":[],"id":"残差公式"}],"id":"1-resnet-的核心思想残差学习"},{"key":"2-残差块的数学实现","href":"#2-残差块的数学实现","heading":3,"title":"2. 残差块的数学实现","children":[{"key":"残差块结构","href":"#残差块结构","heading":4,"title":"残差块结构","children":[],"id":"残差块结构"},{"key":"结构示例mermaid-流程图","href":"#结构示例mermaid-流程图","heading":4,"title":"结构示例（Mermaid 流程图）：","children":[],"id":"结构示例mermaid-流程图"},{"key":"数学表达式","href":"#数学表达式","heading":4,"title":"数学表达式","children":[],"id":"数学表达式"}],"id":"2-残差块的数学实现"},{"key":"3-为什么残差有效","href":"#3-为什么残差有效","heading":3,"title":"3. 为什么残差有效？","children":[{"key":"梯度传播分析","href":"#梯度传播分析","heading":4,"title":"梯度传播分析","children":[],"id":"梯度传播分析"},{"key":"与传统网络的对比","href":"#与传统网络的对比","heading":4,"title":"与传统网络的对比","children":[],"id":"与传统网络的对比"}],"id":"3-为什么残差有效"},{"key":"4-resnet-的网络结构","href":"#4-resnet-的网络结构","heading":3,"title":"4. ResNet 的网络结构","children":[{"key":"典型变体以-imagenet-为例","href":"#典型变体以-imagenet-为例","heading":4,"title":"典型变体（以 ImageNet 为例）","children":[],"id":"典型变体以-imagenet-为例"},{"key":"两种残差块设计","href":"#两种残差块设计","heading":4,"title":"两种残差块设计","children":[],"id":"两种残差块设计"}],"id":"4-resnet-的网络结构"},{"key":"5-resnet-的作用","href":"#5-resnet-的作用","heading":3,"title":"5. ResNet 的作用","children":[{"key":"主要优势","href":"#主要优势","heading":4,"title":"主要优势","children":[],"id":"主要优势"},{"key":"实验对比imagenet-2015","href":"#实验对比imagenet-2015","heading":4,"title":"实验对比（ImageNet 2015）","children":[],"id":"实验对比imagenet-2015"}],"id":"5-resnet-的作用"},{"key":"6-数学扩展残差网络的通用性","href":"#6-数学扩展残差网络的通用性","heading":3,"title":"6. 数学扩展：残差网络的通用性","children":[],"id":"6-数学扩展残差网络的通用性"},{"key":"总结","href":"#总结","heading":3,"title":"总结","children":[],"id":"总结"}],"id":"q-resnet-的数学原理与作用"},{"key":"q-深度网络梯度消失的原理及解决方案","href":"#q-深度网络梯度消失的原理及解决方案","heading":2,"title":"Q: 深度网络梯度消失的原理及解决方案","children":[{"key":"深度网络中梯度消失的原理分析","href":"#深度网络中梯度消失的原理分析","heading":3,"title":"深度网络中梯度消失的原理分析","children":[{"key":"1-梯度消失的定义","href":"#1-梯度消失的定义","heading":4,"title":"1. 梯度消失的定义","children":[],"id":"1-梯度消失的定义"},{"key":"2-梯度消失的数学原理","href":"#2-梯度消失的数学原理","heading":4,"title":"2. 梯度消失的数学原理","children":[],"id":"2-梯度消失的数学原理"},{"key":"3-梯度消失的根源","href":"#3-梯度消失的根源","heading":4,"title":"3. 梯度消失的根源","children":[{"key":"1-激活函数的选择","href":"#1-激活函数的选择","heading":5,"title":"(1) 激活函数的选择","children":[],"id":"1-激活函数的选择"},{"key":"2-权重初始化问题","href":"#2-权重初始化问题","heading":5,"title":"(2) 权重初始化问题","children":[],"id":"2-权重初始化问题"},{"key":"3-深层网络的链式乘积","href":"#3-深层网络的链式乘积","heading":5,"title":"(3) 深层网络的链式乘积","children":[],"id":"3-深层网络的链式乘积"}],"id":"3-梯度消失的根源"},{"key":"4-梯度消失的直观演示","href":"#4-梯度消失的直观演示","heading":4,"title":"4. 梯度消失的直观演示","children":[],"id":"4-梯度消失的直观演示"},{"key":"5-关键参数对比表","href":"#5-关键参数对比表","heading":4,"title":"5. 关键参数对比表","children":[],"id":"5-关键参数对比表"},{"key":"6-解决方案","href":"#6-解决方案","heading":4,"title":"6. 解决方案","children":[],"id":"6-解决方案"},{"key":"7-数学示例","href":"#7-数学示例","heading":4,"title":"7. 数学示例","children":[],"id":"7-数学示例"}],"id":"深度网络中梯度消失的原理分析"}],"id":"q-深度网络梯度消失的原理及解决方案"}],"wikiRefAliases":[],"richRefAliases":[]}}]},"__N_SSG":true},"page":"/tags/[tag]","query":{"tag":"deep-learning"},"buildId":"EJw7StVO_ba3erNzBj1ZM","assetPrefix":"/blog-next","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>