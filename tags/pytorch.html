<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="width=device-width, initial-scale=1" data-next-head=""/><meta name="description" content="The blog owned by Ryo, about Programing, Painting, and Gaming." data-next-head=""/><meta property="og:description" content="The blog owned by Ryo, about Programing, Painting, and Gaming." data-next-head=""/><meta name="twitter:description" content="The blog owned by Ryo, about Programing, Painting, and Gaming." data-next-head=""/><meta property="og:image" content="https://ryojerryyu.github.io/blog-next/img/home-bg-kasumi-hanabi.jpg" data-next-head=""/><meta name="twitter:image" content="https://ryojerryyu.github.io/blog-next/img/home-bg-kasumi-hanabi.jpg" data-next-head=""/><meta property="og:type" content="website" data-next-head=""/><meta property="og:url" content="https://blog.ryo-okami.xyz/tags/pytorch" data-next-head=""/><meta name="twitter:card" content="summary_large_image" data-next-head=""/><meta name="twitter:site" content="@ryo_okami" data-next-head=""/><meta name="twitter:creator" content="@ryo_okami" data-next-head=""/><link rel="icon" href="/blog-next/favicon.ico" data-next-head=""/><meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests" data-next-head=""/><title data-next-head="">PyTorch | Ryo&#x27;s Blog</title><meta property="og:title" content="PyTorch" data-next-head=""/><meta property="og:site_name" content="Ryo&#x27;s Blog" data-next-head=""/><meta name="twitter:title" content="PyTorch | Ryo&#x27;s Blog" data-next-head=""/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><link rel="apple-touch-icon" href="/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="192x192" href="/android-chrome-192x192.png"/><link rel="manifest" href="/site.webmanifest"/><meta name="msapplication-TileColor" content="#da532c"/><meta name="theme-color" content="#ffffff"/><link data-next-font="" rel="preconnect" href="/" crossorigin="anonymous"/><link rel="preload" href="/blog-next/_next/static/css/11fec6dc40b92dec.css" as="style"/><link rel="preload" href="/blog-next/_next/static/css/1d7f07002866851a.css" as="style"/><link rel="stylesheet" href="/blog-next/_next/static/css/11fec6dc40b92dec.css" data-n-g=""/><link rel="stylesheet" href="/blog-next/_next/static/css/1d7f07002866851a.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" noModule="" src="/blog-next/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/blog-next/_next/static/chunks/webpack-5fa3d4ae24b2605f.js" defer=""></script><script src="/blog-next/_next/static/chunks/framework-66421cda4049f394.js" defer=""></script><script src="/blog-next/_next/static/chunks/main-2f2d93a54734734e.js" defer=""></script><script src="/blog-next/_next/static/chunks/pages/_app-1908ef6442a48c7f.js" defer=""></script><script src="/blog-next/_next/static/chunks/9809-facf29e513fda46b.js" defer=""></script><script src="/blog-next/_next/static/chunks/2738-36007727db642acd.js" defer=""></script><script src="/blog-next/_next/static/chunks/pages/tags/%5Btag%5D-b669368bd0997ff8.js" defer=""></script><script src="/blog-next/_next/static/ep7Z6bMN5q5X1Nkao2dSu/_buildManifest.js" defer=""></script><script src="/blog-next/_next/static/ep7Z6bMN5q5X1Nkao2dSu/_ssgManifest.js" defer=""></script></head><body><div id="__next"><style data-emotion="css czlpqi">.css-czlpqi{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;width:100%;box-sizing:border-box;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;position:fixed;z-index:1100;top:0;left:auto;right:0;--AppBar-background:#1976d2;--AppBar-color:#fff;background-color:var(--AppBar-background);color:var(--AppBar-color);background-color:rgba(15, 23, 42, 0.75);}@media print{.css-czlpqi{position:absolute;}}</style><style data-emotion="css 1cmpeoq">.css-1cmpeoq{background-color:#fff;color:rgba(0, 0, 0, 0.87);-webkit-transition:box-shadow 300ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:box-shadow 300ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;box-shadow:var(--Paper-shadow);background-image:var(--Paper-overlay);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;width:100%;box-sizing:border-box;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;position:fixed;z-index:1100;top:0;left:auto;right:0;--AppBar-background:#1976d2;--AppBar-color:#fff;background-color:var(--AppBar-background);color:var(--AppBar-color);background-color:rgba(15, 23, 42, 0.75);}@media print{.css-1cmpeoq{position:absolute;}}</style><header class="MuiPaper-root MuiPaper-elevation MuiPaper-elevation4 MuiAppBar-root MuiAppBar-colorPrimary MuiAppBar-positionFixed mui-fixed css-1cmpeoq" style="--Paper-shadow:0px 2px 4px -1px rgba(0,0,0,0.2),0px 4px 5px 0px rgba(0,0,0,0.14),0px 1px 10px 0px rgba(0,0,0,0.12)"><style data-emotion="css awgou1">.css-awgou1{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-left:16px;padding-right:16px;min-height:56px;}@media (min-width:600px){.css-awgou1{padding-left:24px;padding-right:24px;}}@media (min-width:0px){@media (orientation: landscape){.css-awgou1{min-height:48px;}}}@media (min-width:600px){.css-awgou1{min-height:64px;}}</style><div class="MuiToolbar-root MuiToolbar-gutters MuiToolbar-regular css-awgou1"><style data-emotion="css 1guk29">@media (min-width:0px){.css-1guk29{display:none;}}@media (min-width:900px){.css-1guk29{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}</style><div class="ml-2 w-24 mr-4 MuiBox-root css-1guk29"><a class="DefaultLayout_textlink__EVwys" href="/blog-next">Ryo&#x27;s Blog</a></div><style data-emotion="css 1m04nb5">@media (min-width:0px){.css-1m04nb5{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}@media (min-width:900px){.css-1m04nb5{display:none;}}</style><div class="ml-2 mr-4 MuiBox-root css-1m04nb5"><a title="Ryo&#x27;s Blog" href="/blog-next"><style data-emotion="css q7mezt">.css-q7mezt{-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;width:1em;height:1em;display:inline-block;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;-webkit-transition:fill 200ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:fill 200ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;fill:currentColor;font-size:1.5rem;}</style><svg class="MuiSvgIcon-root MuiSvgIcon-fontSizeMedium h-6 w-6 text-gray-300 hover:text-white css-q7mezt" focusable="false" aria-hidden="true" viewBox="0 0 24 24" data-testid="HomeIcon"><path d="M10 20v-6h4v6h5v-8h3L12 3 2 12h3v8z"></path></svg></a></div><style data-emotion="css nznm6s">.css-nznm6s{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex:1;-ms-flex:1;flex:1;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}</style><div class="MuiBox-root css-nznm6s"><div class="inset-0 w-full h-full flex items-center justify-center bg-transparent"><style data-emotion="css 14awfyb animation-61bdi0">.css-14awfyb{display:inline-block;-webkit-animation:animation-61bdi0 1.4s linear infinite;animation:animation-61bdi0 1.4s linear infinite;color:#1976d2;}@-webkit-keyframes animation-61bdi0{0%{-webkit-transform:rotate(0deg);-moz-transform:rotate(0deg);-ms-transform:rotate(0deg);transform:rotate(0deg);}100%{-webkit-transform:rotate(360deg);-moz-transform:rotate(360deg);-ms-transform:rotate(360deg);transform:rotate(360deg);}}@keyframes animation-61bdi0{0%{-webkit-transform:rotate(0deg);-moz-transform:rotate(0deg);-ms-transform:rotate(0deg);transform:rotate(0deg);}100%{-webkit-transform:rotate(360deg);-moz-transform:rotate(360deg);-ms-transform:rotate(360deg);transform:rotate(360deg);}}</style><span class="MuiCircularProgress-root MuiCircularProgress-indeterminate MuiCircularProgress-colorPrimary css-14awfyb" style="width:40px;height:40px" role="progressbar"><style data-emotion="css 4ejps8">.css-4ejps8{display:block;}</style><svg class="MuiCircularProgress-svg css-4ejps8" viewBox="22 22 44 44"><style data-emotion="css 13odlrs animation-1o38n3e">.css-13odlrs{stroke:currentColor;stroke-dasharray:80px,200px;stroke-dashoffset:0;-webkit-animation:animation-1o38n3e 1.4s ease-in-out infinite;animation:animation-1o38n3e 1.4s ease-in-out infinite;}@-webkit-keyframes animation-1o38n3e{0%{stroke-dasharray:1px,200px;stroke-dashoffset:0;}50%{stroke-dasharray:100px,200px;stroke-dashoffset:-15px;}100%{stroke-dasharray:1px,200px;stroke-dashoffset:-126px;}}@keyframes animation-1o38n3e{0%{stroke-dasharray:1px,200px;stroke-dashoffset:0;}50%{stroke-dasharray:100px,200px;stroke-dashoffset:-15px;}100%{stroke-dasharray:1px,200px;stroke-dashoffset:-126px;}}</style><circle class="MuiCircularProgress-circle MuiCircularProgress-circleIndeterminate css-13odlrs" cx="44" cy="44" r="20.2" fill="none" stroke-width="3.6"></circle></svg></span></div></div><style data-emotion="css k008qs">.css-k008qs{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}</style><div class="MuiBox-root css-k008qs"><a title="Twitter" href="https://twitter.com/ryo_okami"><svg class="h-6 w-6 fill-gray-300 hover:fill-white mx-1 sm:mx-2" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a><a title="GitHub" href="https://github.com/RyoJerryYu"><svg class="h-6 w-6 fill-gray-300 hover:fill-white mx-1 sm:mx-2" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a><a title="Pixiv" href="https://www.pixiv.net/users/9159893"><svg class="h-6 w-6 fill-gray-300 hover:fill-white mx-1 sm:mx-2" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4.935 0A4.924 4.924 0 0 0 0 4.935v14.13A4.924 4.924 0 0 0 4.935 24h14.13A4.924 4.924 0 0 0 24 19.065V4.935A4.924 4.924 0 0 0 19.065 0zm7.81 4.547c2.181 0 4.058.676 5.399 1.847a6.118 6.118 0 0 1 2.116 4.66c.005 1.854-.88 3.476-2.257 4.563-1.375 1.092-3.225 1.697-5.258 1.697-2.314 0-4.46-.842-4.46-.842v2.718c.397.116 1.048.365.635.779H5.79c-.41-.41.19-.65.644-.779V7.666c-1.053.81-1.593 1.51-1.868 2.031.32 1.02-.284.969-.284.969l-1.09-1.73s3.868-4.39 9.553-4.39zm-.19.971c-1.423-.003-3.184.473-4.27 1.244v8.646c.988.487 2.484.832 4.26.832h.01c1.596 0 2.98-.593 3.93-1.533.952-.948 1.486-2.183 1.492-3.683-.005-1.54-.504-2.864-1.42-3.86-.918-.992-2.274-1.645-4.002-1.646Z"></path></svg></a></div></div></header><style data-emotion="css awgou1">.css-awgou1{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-left:16px;padding-right:16px;min-height:56px;}@media (min-width:600px){.css-awgou1{padding-left:24px;padding-right:24px;}}@media (min-width:0px){@media (orientation: landscape){.css-awgou1{min-height:48px;}}}@media (min-width:600px){.css-awgou1{min-height:64px;}}</style><div class="MuiToolbar-root MuiToolbar-gutters MuiToolbar-regular css-awgou1"></div><style data-emotion="css vktxal">.css-vktxal{--Grid-columns:12;--Grid-columnSpacing:0px;--Grid-rowSpacing:0px;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;min-width:0;box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;gap:var(--Grid-rowSpacing) var(--Grid-columnSpacing);width:100%;max-width:80rem;margin-left:auto;margin-right:auto;padding:0.5rem;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;}.css-vktxal >*{--Grid-parent-columns:12;}.css-vktxal >*{--Grid-parent-columnSpacing:0px;}.css-vktxal >*{--Grid-parent-rowSpacing:0px;}</style><div class="MuiGrid2-root MuiGrid2-container MuiGrid2-direction-xs-row css-vktxal"><style data-emotion="css 9gdssj">.css-9gdssj{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 0 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 0) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));min-width:0;box-sizing:border-box;}@media (min-width:900px){.css-9gdssj{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 0 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 0) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}@media (min-width:1200px){.css-9gdssj{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 2 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 2) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}</style><div class="MuiGrid2-root MuiGrid2-direction-xs-row MuiGrid2-grid-xs-0 MuiGrid2-grid-md-0 MuiGrid2-grid-lg-2 css-9gdssj"></div><style data-emotion="css 9h67uz">.css-9h67uz{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 12 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 12) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));min-width:0;box-sizing:border-box;}@media (min-width:900px){.css-9h67uz{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 9 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 9) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}@media (min-width:1200px){.css-9h67uz{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 8 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 8) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}</style><div class="MuiGrid2-root MuiGrid2-direction-xs-row MuiGrid2-grid-xs-12 MuiGrid2-grid-md-9 MuiGrid2-grid-lg-8 css-9h67uz"><div class="DefaultLayout_contentHeight__DabjQ"><div class="p-2"><div class="TagsBox_tagsBox__WzhAf"><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E6%9D%82%E6%8A%80">#<!-- -->杂技</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/blog">#<!-- -->Blog</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E6%9D%82%E8%B0%88">#<!-- -->杂谈</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/c++">#<!-- -->C++</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/python">#<!-- -->Python</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84">#<!-- -->数据结构</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E7%AE%97%E6%B3%95">#<!-- -->算法</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E6%8E%92%E5%BA%8F">#<!-- -->排序</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B">#<!-- -->算法竞赛</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F">#<!-- -->设计模式</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E7%AC%94%E8%AE%B0">#<!-- -->笔记</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/github">#<!-- -->GitHub</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/aws">#<!-- -->AWS</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/ci-cd">#<!-- -->CI/CD</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/iac">#<!-- -->IaC</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/devops">#<!-- -->DevOps</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/vscode">#<!-- -->VSCode</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/hexo">#<!-- -->Hexo</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/javascript">#<!-- -->JavaScript</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/kubernetes">#<!-- -->Kubernetes</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/docker">#<!-- -->Docker</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/cloud-native">#<!-- -->Cloud Native</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/cursor">#<!-- -->Cursor</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E5%8F%AF%E8%A7%86%E5%8C%96">#<!-- -->可视化</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E6%95%B0%E5%AD%A6">#<!-- -->数学</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E5%B7%A5%E5%85%B7">#<!-- -->工具</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/nextjs">#<!-- -->Nextjs</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/linux">#<!-- -->Linux</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/systemctl">#<!-- -->systemctl</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/journalctl">#<!-- -->journalctl</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/timedatectl">#<!-- -->timedatectl</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/basicknowledge">#<!-- -->BasicKnowledge</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/operation">#<!-- -->Operation</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/signal">#<!-- -->Signal</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/memory">#<!-- -->memory</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/schedule">#<!-- -->schedule</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/cloud-computing">#<!-- -->Cloud Computing</a><a class="tag-word TagsBox_highlightedTag__cLTHz" href="/blog-next/tags/pytorch">#<!-- -->PyTorch</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/onnx">#<!-- -->ONNX</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0">#<!-- -->深度学习</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2">#<!-- -->模型部署</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0">#<!-- -->学习笔记</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/opencv">#<!-- -->OpenCV</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86">#<!-- -->图像处理</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/rust">#<!-- -->Rust</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80">#<!-- -->编程语言</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/windows">#<!-- -->Windows</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/macos">#<!-- -->macOS</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E5%8F%AF%E6%89%A7%E8%A1%8C%E6%96%87%E4%BB%B6">#<!-- -->可执行文件</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/lora">#<!-- -->LoRA</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83">#<!-- -->参数高效微调</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83">#<!-- -->模型训练</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD">#<!-- -->反向传播</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86">#<!-- -->自动微分</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/golang">#<!-- -->GoLang</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/memory-management">#<!-- -->Memory Management</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/deep-learning">#<!-- -->Deep Learning</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/model-management">#<!-- -->Model Management</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/neural-networks">#<!-- -->Neural Networks</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/resnet">#<!-- -->ResNet</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/mathematics">#<!-- -->Mathematics</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/test">#<!-- -->test</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/wiki">#<!-- -->wiki</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/page1">#<!-- -->page1</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/subpage1">#<!-- -->subpage1</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/page2">#<!-- -->page2</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/subpage2">#<!-- -->subpage2</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/subpage3">#<!-- -->subpage3</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/subpage34">#<!-- -->subpage34</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/page3">#<!-- -->page3</a></div></div><div class="PostList_postList__Tuobz"><div class="PostList_postListElement__qi6kp"><a href="/blog-next/learn_from_ai/pytorch-model-save-and-load"><h6 class="PostList_postTitle__vveJr">PyTorch 模型的保存与加载机制详解</h6><div class="PostList_postDate__z_XQh"><time dateTime="2025-03-07T13:00:00.000Z">2025-03-07</time></div><div class="PostList_postAbstract__HtPA1"><p class="py-1">&gt; 本文为与 DeepSeek 对话记录，深入探讨 PyTorch 中模型的保存和加载机制，包括不同的保存方式、最佳实践以及常见问题的解决方案。</p><p class="py-1">&gt; [!reasoning]-</p><p class="py-1">&gt;</p></div></a><div class="TagsBox_tagsBox__WzhAf py-4 md:py-1"><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/deep-learning">#<!-- -->Deep Learning</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/pytorch">#<!-- -->PyTorch</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/model-management">#<!-- -->Model Management</a></div></div><div class="PostList_postListElement__qi6kp"><a href="/blog-next/learn_from_ai/pytorch-backpropagation-mechanism"><h6 class="PostList_postTitle__vveJr">PyTorch 自动微分与反向传播机制原理解析</h6><div class="PostList_postDate__z_XQh"><time dateTime="2025-03-06T15:50:00.000Z">2025-03-06</time></div><div class="PostList_postAbstract__HtPA1"><p class="py-1">&gt; 本文为用户与 DeepSeek 的问答。主题为 PyTorch 的反向传播机制。本文从数学原理、计算图机制和实际需求三个方面深入解释其工作原理，并结合 PyTorch 的自动微分（Autograd）系统进行说明。</p><p class="py-1">&gt; [!query]</p><p class="py-1">&gt;</p></div></a><div class="TagsBox_tagsBox__WzhAf py-4 md:py-1"><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/pytorch">#<!-- -->PyTorch</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0">#<!-- -->深度学习</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD">#<!-- -->反向传播</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86">#<!-- -->自动微分</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0">#<!-- -->学习笔记</a></div></div><div class="PostList_postListElement__qi6kp"><a href="/blog-next/learn_from_ai/deep-learning-model-formats"><h6 class="PostList_postTitle__vveJr">深度学习模型文件格式对比：pth、safetensor 与 onnx</h6><div class="PostList_postDate__z_XQh"><time dateTime="2024-11-29T02:00:00.000Z">2024-11-29</time></div><div class="PostList_postAbstract__HtPA1"><p class="py-1">&gt; 本页面介绍了三种机器学习模型文件格式：.pth、.safetensor 和 .onnx。主要内容包括每种格式的定义、保存的内容、用途以及它们之间的区别和转换方法。</p><p class="py-1">PyTorch 中的`.pth`文件通常用于保存模型的权重（parameters）和训练过程中的优化器状态（optimizer state）。具体来说，一个`.pth`文件可能包含以下内容：</p><p class="py-1">1. **模型状态字典（Model state dictionary）**：</p></div></a><div class="TagsBox_tagsBox__WzhAf py-4 md:py-1"><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/pytorch">#<!-- -->PyTorch</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/onnx">#<!-- -->ONNX</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0">#<!-- -->深度学习</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2">#<!-- -->模型部署</a><a class="tag-word TagsBox_tag__Rk32C" href="/blog-next/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0">#<!-- -->学习笔记</a></div></div></div></div></div><style data-emotion="css vkdybf">.css-vkdybf{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 0 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 0) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));min-width:0;box-sizing:border-box;}@media (min-width:900px){.css-vkdybf{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 3 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 3) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}@media (min-width:1200px){.css-vkdybf{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 2 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 2) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}</style><div class="MuiGrid2-root MuiGrid2-direction-xs-row MuiGrid2-grid-xs-0 MuiGrid2-grid-md-3 MuiGrid2-grid-lg-2 css-vkdybf"></div></div><footer class="DefaultLayout_footer__n5339"><style data-emotion="css vktxal">.css-vktxal{--Grid-columns:12;--Grid-columnSpacing:0px;--Grid-rowSpacing:0px;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;min-width:0;box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;gap:var(--Grid-rowSpacing) var(--Grid-columnSpacing);width:100%;max-width:80rem;margin-left:auto;margin-right:auto;padding:0.5rem;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;}.css-vktxal >*{--Grid-parent-columns:12;}.css-vktxal >*{--Grid-parent-columnSpacing:0px;}.css-vktxal >*{--Grid-parent-rowSpacing:0px;}</style><div class="MuiGrid2-root MuiGrid2-container MuiGrid2-direction-xs-row css-vktxal"><style data-emotion="css 9gdssj">.css-9gdssj{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 0 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 0) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));min-width:0;box-sizing:border-box;}@media (min-width:900px){.css-9gdssj{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 0 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 0) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}@media (min-width:1200px){.css-9gdssj{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 2 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 2) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}</style><div class="MuiGrid2-root MuiGrid2-direction-xs-row MuiGrid2-grid-xs-0 MuiGrid2-grid-md-0 MuiGrid2-grid-lg-2 css-9gdssj"></div><style data-emotion="css 9h67uz">.css-9h67uz{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 12 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 12) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));min-width:0;box-sizing:border-box;}@media (min-width:900px){.css-9h67uz{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 9 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 9) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}@media (min-width:1200px){.css-9h67uz{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 8 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 8) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}</style><div class="MuiGrid2-root MuiGrid2-direction-xs-row MuiGrid2-grid-xs-12 MuiGrid2-grid-md-9 MuiGrid2-grid-lg-8 css-9h67uz"><div class="flex flex-row justify-center items-center"><div class="DefaultLayout_footerLeft__j0yvY">© 2023 Ryo Jerry Yu. All rights reserved.</div><div class="DefaultLayout_footerRight___Dn67"><a title="Twitter" href="https://twitter.com/ryo_okami"><svg class="h-6 w-6 fill-gray-300 hover:fill-white transition-all ease-in-out mx-1 md:mx-2" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a><a title="GitHub" href="https://github.com/RyoJerryYu"><svg class="h-6 w-6 fill-gray-300 hover:fill-white transition-all ease-in-out mx-1 md:mx-2" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a><a title="Pixiv" href="https://www.pixiv.net/users/9159893"><svg class="h-6 w-6 fill-gray-300 hover:fill-white transition-all ease-in-out mx-1 md:mx-2" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4.935 0A4.924 4.924 0 0 0 0 4.935v14.13A4.924 4.924 0 0 0 4.935 24h14.13A4.924 4.924 0 0 0 24 19.065V4.935A4.924 4.924 0 0 0 19.065 0zm7.81 4.547c2.181 0 4.058.676 5.399 1.847a6.118 6.118 0 0 1 2.116 4.66c.005 1.854-.88 3.476-2.257 4.563-1.375 1.092-3.225 1.697-5.258 1.697-2.314 0-4.46-.842-4.46-.842v2.718c.397.116 1.048.365.635.779H5.79c-.41-.41.19-.65.644-.779V7.666c-1.053.81-1.593 1.51-1.868 2.031.32 1.02-.284.969-.284.969l-1.09-1.73s3.868-4.39 9.553-4.39zm-.19.971c-1.423-.003-3.184.473-4.27 1.244v8.646c.988.487 2.484.832 4.26.832h.01c1.596 0 2.98-.593 3.93-1.533.952-.948 1.486-2.183 1.492-3.683-.005-1.54-.504-2.864-1.42-3.86-.918-.992-2.274-1.645-4.002-1.646Z"></path></svg></a></div></div></div><style data-emotion="css vkdybf">.css-vkdybf{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 0 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 0) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));min-width:0;box-sizing:border-box;}@media (min-width:900px){.css-vkdybf{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 3 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 3) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}@media (min-width:1200px){.css-vkdybf{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;width:calc(100% * 2 / var(--Grid-parent-columns) - (var(--Grid-parent-columns) - 2) * (var(--Grid-parent-columnSpacing) / var(--Grid-parent-columns)));}}</style><div class="MuiGrid2-root MuiGrid2-direction-xs-row MuiGrid2-grid-xs-0 MuiGrid2-grid-md-3 MuiGrid2-grid-lg-2 css-vkdybf"></div></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"allTagInfos":[{"tag":"杂技","slug":"杂技","path":"/tags/杂技","postSlugs":[{"postType":"articles","postPagePath":"/articles/Building-this-blog"},{"postType":"articles","postPagePath":"/articles/hello-world"},{"postType":"articles","postPagePath":"/articles/the-using-in-cpp"}]},{"tag":"Blog","slug":"blog","path":"/tags/blog","postSlugs":[{"postType":"articles","postPagePath":"/articles/Building-this-blog"},{"postType":"articles","postPagePath":"/articles/init-a-new-hexo-project"},{"postType":"articles","postPagePath":"/articles/create-blog-cicd-by-github"},{"postType":"articles","postPagePath":"/articles/use-paste-image-and-vscode-memo"},{"postType":"ideas","postPagePath":"/ideas/blog-in-next"},{"postType":"ideas","postPagePath":"/ideas/blog-syntax"}]},{"tag":"杂谈","slug":"杂谈","path":"/tags/杂谈","postSlugs":[{"postType":"articles","postPagePath":"/articles/hello-world"},{"postType":"articles","postPagePath":"/articles/try-cursor-and-thinking"}]},{"tag":"C++","slug":"c++","path":"/tags/c++","postSlugs":[{"postType":"articles","postPagePath":"/articles/the-using-in-cpp"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/cpp-rvo-and-rust-move-semantics"}]},{"tag":"Python","slug":"python","path":"/tags/python","postSlugs":[{"postType":"articles","postPagePath":"/articles/python-dict"}]},{"tag":"数据结构","slug":"数据结构","path":"/tags/数据结构","postSlugs":[{"postType":"articles","postPagePath":"/articles/python-dict"},{"postType":"articles","postPagePath":"/articles/Sort-algorithm"},{"postType":"articles","postPagePath":"/articles/Handy-heap-cheat-sheet"}]},{"tag":"算法","slug":"算法","path":"/tags/算法","postSlugs":[{"postType":"articles","postPagePath":"/articles/Sort-algorithm"},{"postType":"articles","postPagePath":"/articles/Handy-heap-cheat-sheet"}]},{"tag":"排序","slug":"排序","path":"/tags/排序","postSlugs":[{"postType":"articles","postPagePath":"/articles/Sort-algorithm"}]},{"tag":"算法竞赛","slug":"算法竞赛","path":"/tags/算法竞赛","postSlugs":[{"postType":"articles","postPagePath":"/articles/Handy-heap-cheat-sheet"}]},{"tag":"设计模式","slug":"设计模式","path":"/tags/设计模式","postSlugs":[{"postType":"articles","postPagePath":"/articles/The-beauty-of-design-parten"}]},{"tag":"笔记","slug":"笔记","path":"/tags/笔记","postSlugs":[{"postType":"articles","postPagePath":"/articles/The-beauty-of-design-parten"}]},{"tag":"GitHub","slug":"github","path":"/tags/github","postSlugs":[{"postType":"articles","postPagePath":"/articles/create-blog-cicd-by-github"}]},{"tag":"AWS","slug":"aws","path":"/tags/aws","postSlugs":[{"postType":"articles","postPagePath":"/articles/create-blog-cicd-by-github"}]},{"tag":"CI/CD","slug":"ci-cd","path":"/tags/ci-cd","postSlugs":[{"postType":"articles","postPagePath":"/articles/create-blog-cicd-by-github"}]},{"tag":"IaC","slug":"iac","path":"/tags/iac","postSlugs":[{"postType":"articles","postPagePath":"/articles/create-blog-cicd-by-github"}]},{"tag":"DevOps","slug":"devops","path":"/tags/devops","postSlugs":[{"postType":"articles","postPagePath":"/articles/create-blog-cicd-by-github"},{"postType":"articles","postPagePath":"/articles/introduction-for-k8s"},{"postType":"articles","postPagePath":"/articles/introduction-for-k8s-2"},{"postType":"ideas","postPagePath":"/ideas/newest"}]},{"tag":"VSCode","slug":"vscode","path":"/tags/vscode","postSlugs":[{"postType":"articles","postPagePath":"/articles/use-paste-image-and-vscode-memo"}]},{"tag":"Hexo","slug":"hexo","path":"/tags/hexo","postSlugs":[{"postType":"articles","postPagePath":"/articles/use-paste-image-and-vscode-memo"}]},{"tag":"JavaScript","slug":"javascript","path":"/tags/javascript","postSlugs":[{"postType":"articles","postPagePath":"/articles/use-paste-image-and-vscode-memo"}]},{"tag":"Kubernetes","slug":"kubernetes","path":"/tags/kubernetes","postSlugs":[{"postType":"articles","postPagePath":"/articles/introduction-for-k8s"},{"postType":"articles","postPagePath":"/articles/introduction-for-k8s-2"},{"postType":"ideas","postPagePath":"/ideas/newest"}]},{"tag":"Docker","slug":"docker","path":"/tags/docker","postSlugs":[{"postType":"articles","postPagePath":"/articles/introduction-for-k8s"},{"postType":"articles","postPagePath":"/articles/introduction-for-k8s-2"},{"postType":"ideas","postPagePath":"/ideas/newest"}]},{"tag":"Cloud Native","slug":"cloud-native","path":"/tags/cloud-native","postSlugs":[{"postType":"articles","postPagePath":"/articles/introduction-for-k8s"},{"postType":"articles","postPagePath":"/articles/introduction-for-k8s-2"},{"postType":"ideas","postPagePath":"/ideas/newest"}]},{"tag":"Cursor","slug":"cursor","path":"/tags/cursor","postSlugs":[{"postType":"articles","postPagePath":"/articles/try-cursor-and-thinking"}]},{"tag":"可视化","slug":"可视化","path":"/tags/可视化","postSlugs":[{"postType":"ideas","postPagePath":"/ideas/blog 画图 Iframe 测试"}]},{"tag":"数学","slug":"数学","path":"/tags/数学","postSlugs":[{"postType":"ideas","postPagePath":"/ideas/blog 画图 Iframe 测试"}]},{"tag":"工具","slug":"工具","path":"/tags/工具","postSlugs":[{"postType":"ideas","postPagePath":"/ideas/blog 画图 Iframe 测试"}]},{"tag":"Nextjs","slug":"nextjs","path":"/tags/nextjs","postSlugs":[{"postType":"ideas","postPagePath":"/ideas/blog-in-next"},{"postType":"ideas","postPagePath":"/ideas/blog-syntax"}]},{"tag":"Linux","slug":"linux","path":"/tags/linux","postSlugs":[{"postType":"ideas","postPagePath":"/ideas/Linux Systemd"},{"postType":"ideas","postPagePath":"/ideas/Linux 信号处理 —— Signal"},{"postType":"ideas","postPagePath":"/ideas/Linux 内存 —— 内存分页、分段"},{"postType":"ideas","postPagePath":"/ideas/Linux 内存 —— 堆和栈"},{"postType":"ideas","postPagePath":"/ideas/Linux 内存 —— 虚拟内存"},{"postType":"ideas","postPagePath":"/ideas/Linux 调度 —— 进程与线程"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/executable-file-formats"}]},{"tag":"systemctl","slug":"systemctl","path":"/tags/systemctl","postSlugs":[{"postType":"ideas","postPagePath":"/ideas/Linux Systemd"}]},{"tag":"journalctl","slug":"journalctl","path":"/tags/journalctl","postSlugs":[{"postType":"ideas","postPagePath":"/ideas/Linux Systemd"}]},{"tag":"timedatectl","slug":"timedatectl","path":"/tags/timedatectl","postSlugs":[{"postType":"ideas","postPagePath":"/ideas/Linux Systemd"}]},{"tag":"BasicKnowledge","slug":"basicknowledge","path":"/tags/basicknowledge","postSlugs":[{"postType":"ideas","postPagePath":"/ideas/Linux Systemd"},{"postType":"ideas","postPagePath":"/ideas/Linux 信号处理 —— Signal"},{"postType":"ideas","postPagePath":"/ideas/Linux 内存 —— 内存分页、分段"},{"postType":"ideas","postPagePath":"/ideas/Linux 内存 —— 堆和栈"},{"postType":"ideas","postPagePath":"/ideas/Linux 内存 —— 虚拟内存"},{"postType":"ideas","postPagePath":"/ideas/Linux 调度 —— 进程与线程"}]},{"tag":"Operation","slug":"operation","path":"/tags/operation","postSlugs":[{"postType":"ideas","postPagePath":"/ideas/Linux Systemd"},{"postType":"ideas","postPagePath":"/ideas/Linux 信号处理 —— Signal"},{"postType":"ideas","postPagePath":"/ideas/Linux 内存 —— 内存分页、分段"},{"postType":"ideas","postPagePath":"/ideas/Linux 内存 —— 虚拟内存"}]},{"tag":"Signal","slug":"signal","path":"/tags/signal","postSlugs":[{"postType":"ideas","postPagePath":"/ideas/Linux 信号处理 —— Signal"}]},{"tag":"memory","slug":"memory","path":"/tags/memory","postSlugs":[{"postType":"ideas","postPagePath":"/ideas/Linux 内存 —— 内存分页、分段"},{"postType":"ideas","postPagePath":"/ideas/Linux 内存 —— 堆和栈"},{"postType":"ideas","postPagePath":"/ideas/Linux 内存 —— 虚拟内存"}]},{"tag":"schedule","slug":"schedule","path":"/tags/schedule","postSlugs":[{"postType":"ideas","postPagePath":"/ideas/Linux 调度 —— 进程与线程"}]},{"tag":"Cloud Computing","slug":"cloud-computing","path":"/tags/cloud-computing","postSlugs":[{"postType":"ideas","postPagePath":"/ideas/newest"}]},{"tag":"PyTorch","slug":"pytorch","path":"/tags/pytorch","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/deep-learning-model-formats"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/pytorch-backpropagation-mechanism"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/pytorch-model-save-and-load"}]},{"tag":"ONNX","slug":"onnx","path":"/tags/onnx","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/deep-learning-model-formats"}]},{"tag":"深度学习","slug":"深度学习","path":"/tags/深度学习","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/deep-learning-model-formats"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/lora-matrix-initialization-strategy"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/pytorch-backpropagation-mechanism"}]},{"tag":"模型部署","slug":"模型部署","path":"/tags/模型部署","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/deep-learning-model-formats"}]},{"tag":"学习笔记","slug":"学习笔记","path":"/tags/学习笔记","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/deep-learning-model-formats"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/opencv-coordinate-system-conventions"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/executable-file-formats"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/lora-matrix-initialization-strategy"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/pytorch-backpropagation-mechanism"}]},{"tag":"OpenCV","slug":"opencv","path":"/tags/opencv","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/opencv-coordinate-system-conventions"}]},{"tag":"图像处理","slug":"图像处理","path":"/tags/图像处理","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/opencv-coordinate-system-conventions"}]},{"tag":"Rust","slug":"rust","path":"/tags/rust","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/cpp-rvo-and-rust-move-semantics"}]},{"tag":"编程语言","slug":"编程语言","path":"/tags/编程语言","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/cpp-rvo-and-rust-move-semantics"}]},{"tag":"Windows","slug":"windows","path":"/tags/windows","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/executable-file-formats"}]},{"tag":"macOS","slug":"macos","path":"/tags/macos","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/executable-file-formats"}]},{"tag":"可执行文件","slug":"可执行文件","path":"/tags/可执行文件","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/executable-file-formats"}]},{"tag":"LoRA","slug":"lora","path":"/tags/lora","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/lora-matrix-initialization-strategy"}]},{"tag":"参数高效微调","slug":"参数高效微调","path":"/tags/参数高效微调","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/lora-matrix-initialization-strategy"}]},{"tag":"模型训练","slug":"模型训练","path":"/tags/模型训练","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/lora-matrix-initialization-strategy"}]},{"tag":"反向传播","slug":"反向传播","path":"/tags/反向传播","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/pytorch-backpropagation-mechanism"}]},{"tag":"自动微分","slug":"自动微分","path":"/tags/自动微分","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/pytorch-backpropagation-mechanism"}]},{"tag":"GoLang","slug":"golang","path":"/tags/golang","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/golang-new-and-memory-management"}]},{"tag":"Memory Management","slug":"memory-management","path":"/tags/memory-management","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/golang-new-and-memory-management"}]},{"tag":"Deep Learning","slug":"deep-learning","path":"/tags/deep-learning","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/pytorch-model-save-and-load"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/resnet-math-and-gradient-vanishing"}]},{"tag":"Model Management","slug":"model-management","path":"/tags/model-management","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/pytorch-model-save-and-load"}]},{"tag":"Neural Networks","slug":"neural-networks","path":"/tags/neural-networks","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/resnet-math-and-gradient-vanishing"}]},{"tag":"ResNet","slug":"resnet","path":"/tags/resnet","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/resnet-math-and-gradient-vanishing"}]},{"tag":"Mathematics","slug":"mathematics","path":"/tags/mathematics","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/resnet-math-and-gradient-vanishing"}]},{"tag":"test","slug":"test","path":"/tags/test","postSlugs":[{"postType":"testwiki","postPagePath":"/testwiki/page1"},{"postType":"testwiki","postPagePath":"/testwiki/page1/subpage1"},{"postType":"testwiki","postPagePath":"/testwiki/page2"},{"postType":"testwiki","postPagePath":"/testwiki/page2/subpage2"},{"postType":"testwiki","postPagePath":"/testwiki/page2/subpage3"},{"postType":"testwiki","postPagePath":"/testwiki/page2/subpage3/subpage34"},{"postType":"testwiki","postPagePath":"/testwiki/page3/subpage1"},{"postType":"testwiki","postPagePath":"/testwiki/page3/subpage2"},{"postType":"testwiki","postPagePath":"/testwiki/page3/subpage3"}]},{"tag":"wiki","slug":"wiki","path":"/tags/wiki","postSlugs":[{"postType":"testwiki","postPagePath":"/testwiki/page1"},{"postType":"testwiki","postPagePath":"/testwiki/page1/subpage1"},{"postType":"testwiki","postPagePath":"/testwiki/page2"},{"postType":"testwiki","postPagePath":"/testwiki/page2/subpage2"},{"postType":"testwiki","postPagePath":"/testwiki/page2/subpage3"},{"postType":"testwiki","postPagePath":"/testwiki/page2/subpage3/subpage34"},{"postType":"testwiki","postPagePath":"/testwiki/page3/subpage1"},{"postType":"testwiki","postPagePath":"/testwiki/page3/subpage2"},{"postType":"testwiki","postPagePath":"/testwiki/page3/subpage3"}]},{"tag":"page1","slug":"page1","path":"/tags/page1","postSlugs":[{"postType":"testwiki","postPagePath":"/testwiki/page1"},{"postType":"testwiki","postPagePath":"/testwiki/page1/subpage1"}]},{"tag":"subpage1","slug":"subpage1","path":"/tags/subpage1","postSlugs":[{"postType":"testwiki","postPagePath":"/testwiki/page1/subpage1"},{"postType":"testwiki","postPagePath":"/testwiki/page3/subpage1"}]},{"tag":"page2","slug":"page2","path":"/tags/page2","postSlugs":[{"postType":"testwiki","postPagePath":"/testwiki/page2"},{"postType":"testwiki","postPagePath":"/testwiki/page2/subpage2"},{"postType":"testwiki","postPagePath":"/testwiki/page2/subpage3"},{"postType":"testwiki","postPagePath":"/testwiki/page2/subpage3/subpage34"}]},{"tag":"subpage2","slug":"subpage2","path":"/tags/subpage2","postSlugs":[{"postType":"testwiki","postPagePath":"/testwiki/page2/subpage2"},{"postType":"testwiki","postPagePath":"/testwiki/page3/subpage2"}]},{"tag":"subpage3","slug":"subpage3","path":"/tags/subpage3","postSlugs":[{"postType":"testwiki","postPagePath":"/testwiki/page2/subpage3"},{"postType":"testwiki","postPagePath":"/testwiki/page2/subpage3/subpage34"},{"postType":"testwiki","postPagePath":"/testwiki/page3/subpage3"}]},{"tag":"subpage34","slug":"subpage34","path":"/tags/subpage34","postSlugs":[{"postType":"testwiki","postPagePath":"/testwiki/page2/subpage3/subpage34"}]},{"tag":"page3","slug":"page3","path":"/tags/page3","postSlugs":[{"postType":"testwiki","postPagePath":"/testwiki/page3/subpage1"},{"postType":"testwiki","postPagePath":"/testwiki/page3/subpage2"},{"postType":"testwiki","postPagePath":"/testwiki/page3/subpage3"}]}],"selectedTagInfo":{"tag":"PyTorch","slug":"pytorch","path":"/tags/pytorch","postSlugs":[{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/deep-learning-model-formats"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/pytorch-backpropagation-mechanism"},{"postType":"learn_from_ai","postPagePath":"/learn_from_ai/pytorch-model-save-and-load"}]},"posts":[{"pathMapping":{"filePath":"public/content/learn_from_ai/2025-03-07-pytorch-model-save-and-load.md","pagePath":"/learn_from_ai/pytorch-model-save-and-load","slug":"pytorch-model-save-and-load"},"meta":{"content":"\n\u003e 本文为与 DeepSeek 对话记录，深入探讨 PyTorch 中模型的保存和加载机制，包括不同的保存方式、最佳实践以及常见问题的解决方案。\n\n## Q: PyTorch 中所谓的保存模型/加载模型，指的是保存/加载什么？是 state_dict 吗？\n\n\u003e [!reasoning]-\n\u003e\n\u003e 嗯，我现在要弄清楚 PyTorch 中保存和加载模型到底是怎么回事。用户问是不是保存和加载 state_dict，我需要仔细想一想这个问题。\n\u003e\n\u003e 首先，我记得在 PyTorch 里训练模型的时候，模型的可学习参数，比如各层的权重和偏置，是存放在模型的 parameters 中的。而 state_dict 应该是一个保存这些参数的东西。对，每个 torch.nn.Module 都有 state_dict，它是一个字典，将每个层映射到对应的参数张量。\n\u003e\n\u003e 那保存模型的时候，有两种常见的方法。一种是直接保存整个模型，使用 torch.save(model, 'model.pth')。这样的话，保存的是整个模型对象，包括结构定义和参数。不过这种方法可能有缺点，比如当模型定义所在的文件路径变化时，加载的时候可能会找不到类定义，导致错误。所以通常更推荐另一种方法，就是只保存 state_dict，这样需要的时候再加载到一个定义好的模型结构中。\n\u003e\n\u003e 所以用户的问题是说保存模型是不是保存 state_dict，对吧？是的，通常最佳做法是保存 state_dict，而不是整个模型对象。因为 state_dict 只包含参数，不包含模型结构，这样在加载的时候更灵活。比如，当你想在不同项目中使用同一个模型参数，或者模型类有修改时，加载 state_dict 会更方便。\n\u003e\n\u003e 那加载的时候，就需要先实例化模型，然后用 load_state_dict 方法加载参数。比如：\n\u003e\n\u003e model = MyModelClass(\\*args, \\*\\*kwargs)\n\u003e\n\u003e model.load_state_dict(torch.load('model.pth'))\n\u003e\n\u003e 这样参数就被正确加载到模型里了。而如果保存的是整个模型，加载的时候可以直接用 model = torch.load('model.pth')，但这时候模型类必须在当前作用域可访问，否则会出错。\n\u003e\n\u003e 所以总结一下，保存模型通常指的是保存 state_dict，而加载模型就是加载这个 state_dict 到已经定义好的模型结构中。当然，PyTorch 也允许保存整个模型，但不够灵活，所以推荐用 state_dict 的方式。\n\u003e\n\u003e 另外，可能还有其他需要保存的内容，比如优化器的 state_dict，这样在恢复训练的时候可以接着之前的优化器状态继续训练。这时候保存的 checkpoint 可能包括 model_state_dict、optimizer_state_dict、epoch、loss 等信息。加载的时候需要分别处理这些部分。\n\u003e\n\u003e 但用户的问题主要是关于保存和加载模型本身，所以核心答案应该是 state_dict。不过要说明保存整个模型的情况也存在，但 state_dict 更推荐。所以回答的时候应该涵盖这两种情况，但强调 state_dict 是更常用的方法。\n\n在 PyTorch 中，保存和加载模型的**核心是 `state_dict`**，但具体操作可以灵活选择。以下是详细说明：\n\n---\n\n### 1. **`state_dict` 是什么？**\n\n- **`state_dict`** 是一个 Python 字典对象，它将模型的每一层（如卷积层、全连接层等）映射到对应的参数张量（权重和偏置）。\n- 例如，一个简单的神经网络可能包含：\n  ```python\n  model.state_dict() = {\n      'conv1.weight': tensor(...),\n      'conv1.bias': tensor(...),\n      'fc1.weight': tensor(...),\n      'fc1.bias': tensor(...),\n      ...\n  }\n  ```\n- **优化器**（如 `torch.optim.SGD`）也有自己的 `state_dict`，保存优化器的状态（如动量缓冲等）。\n\n---\n\n### 2. **保存模型的两种方式**\n\n#### **方式 1：仅保存 `state_dict`（推荐）**\n\n- **代码示例**：\n  ```python\n  torch.save(model.state_dict(), 'model_weights.pth')\n  ```\n- **优点**：\n  - 文件体积小，只保存参数，不保存模型结构。\n  - 加载灵活：需先实例化模型结构，再加载参数。\n  - 避免因代码变更（如类名修改）导致的加载失败。\n\n#### **方式 2：保存整个模型（不推荐）**\n\n- **代码示例**：\n  ```python\n  torch.save(model, 'entire_model.pth')\n  ```\n- **缺点**：\n  - 文件体积大，包含模型结构和参数。\n  - 依赖原始代码环境（模型类的定义必须存在），否则加载时会报错。\n\n---\n\n### 3. **加载模型的对应方法**\n\n#### **加载 `state_dict`（需先构建模型结构）**\n\n```python\nmodel = MyModelClass()  # 必须与保存时的模型结构一致\nmodel.load_state_dict(torch.load('model_weights.pth'))\nmodel.eval()  # 切换到推理模式（关闭 dropout 等）\n```\n\n#### **加载整个模型（直接使用）**\n\n```python\nmodel = torch.load('entire_model.pth')\nmodel.eval()\n```\n\n---\n\n### 4. **实际场景中的最佳实践**\n\n- **保存训练检查点（Checkpoint）**：\n  通常需要保存 `state_dict` 之外的信息（如优化器状态、训练步数等）：\n\n  ```python\n  checkpoint = {\n      'model_state_dict': model.state_dict(),\n      'optimizer_state_dict': optimizer.state_dict(),\n      'epoch': 100,\n      'loss': loss,\n  }\n  torch.save(checkpoint, 'checkpoint.pth')\n  ```\n\n- **加载检查点**：\n  ```python\n  checkpoint = torch.load('checkpoint.pth')\n  model.load_state_dict(checkpoint['model_state_dict'])\n  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n  epoch = checkpoint['epoch']\n  ```\n\n---\n\n### 5. **关键总结**\n\n- **保存模型**：本质是保存模型的 `state_dict`（推荐），但也可以保存整个模型。\n- **加载模型**：\n  - 若保存的是 `state_dict`，需先实例化模型结构，再加载参数。\n  - 若保存的是整个模型，直接加载但需保证代码兼容性。\n- **灵活性**：使用 `state_dict` 更安全、更灵活，适合跨项目或模型结构可能变化的场景。\n\n## Q: model 的 config 又是什么东西？是超参吗？\n\n\u003e [!reasoning]-\n\u003e\n\u003e 嗯，用户之前问过 PyTorch 中保存和加载模型的概念，现在又接着问\"model 的 config 是什么东西？是超参吗？\"我需要仔细分析这个问题，确保理解用户的真实需求。\n\u003e\n\u003e 首先，用户已经了解 state_dict，现在转向模型配置（config）。可能他们在实际项目中遇到了需要保存或管理模型结构的情况，或者在阅读代码时遇到了 config 这个术语。用户想知道 config 具体指什么，是否包括超参数。\n\u003e\n\u003e 接下来，我需要明确\"model config\"的定义。在机器学习中，模型配置通常指的是定义模型结构的参数，比如神经网络的层数、每层的神经元数量、激活函数类型等。而超参数可能包括学习率、批量大小、优化器类型等训练过程中的设置。但有时候这两者之间的界限并不严格，特别是当某些结构参数也被视为超参数时。\n\u003e\n\u003e 用户可能混淆了模型配置和超参数，需要区分这两者。需要举例说明，比如在 Transformer 模型中，config 可能包含隐藏层大小、头数等，而超参数则是训练时的设置。但有时，例如在 HuggingFace 的库中，模型配置类（如 BertConfig）确实包含了模型结构的所有参数，这可能让用户产生疑问。\n\u003e\n\u003e 另外，用户可能想知道为什么需要单独保存 config。可能他们在保存模型时，除了 state_dict 之外，还需要保存模型结构的信息，以便重新实例化模型。比如，如果只保存 state_dict，加载时需要先有模型类的定义和 config 参数，才能正确创建模型实例，然后加载权重。\n\u003e\n\u003e 需要解释 config 的作用：它定义了模型的结构，是重建模型实例的必要信息。与超参数不同，config 主要涉及模型架构，而超参数涉及训练过程。但有些情况下，两者可能有重叠，比如学习率可能被包含在训练配置中，而层数在模型配置中。\n\u003e\n\u003e 还需要考虑用户可能的实际应用场景。比如，使用 HuggingFace 的 Transformers 库时，模型配置被明确分离，用户需要保存 config.json 和 model.bin。这时候，config 保存模型结构，model.bin 保存 state_dict。用户可能在这种情况下遇到 config 的概念，需要解释这种设计的原因和好处。\n\u003e\n\u003e 此外，用户可能想知道如何管理 config，比如使用 YAML 或 JSON 文件来存储模型结构参数，方便版本控制和实验复现。这也是为什么分开保存 config 和 state_dict 更灵活，因为修改结构时只需调整 config 而不影响训练好的权重。\n\u003e\n\u003e 最后，要确保回答结构清晰，分点说明，给出代码示例，并比较 config 与超参数的区别和联系。同时，注意用户可能的技术水平，避免使用过于专业的术语，保持解释的易懂性。\n\n在机器学习中，**模型的 `config`（配置）** 通常指**定义模型结构的所有参数**，而超参（Hyperparameters）更多指**控制训练过程的参数**。这两者有时会有重叠，但核心区别在于作用对象。以下是详细解释：\n\n---\n\n### 1. **什么是模型的 `config`？**\n\n- **模型配置**（Model Configuration）是定义**模型结构**的一组参数，例如：\n\n  - 神经网络的层数、每层的神经元数量\n  - 卷积核大小、步长（Stride）、填充（Padding）\n  - 激活函数类型（如 ReLU、Sigmoid）\n  - 注意力机制的头数（如 Transformer 中的 `num_heads`）\n  - 词嵌入维度（如 NLP 模型中的 `hidden_size`）\n\n- **示例**（以 Transformer 模型为例）：\n  ```python\n  config = {\n      \"num_layers\": 12,          # Transformer 层数\n      \"hidden_size\": 768,         # 隐藏层维度\n      \"num_attention_heads\": 12,  # 注意力头数\n      \"intermediate_size\": 3072,  # FeedForward 层维度\n      \"vocab_size\": 30522,        # 词表大小\n  }\n  ```\n\n---\n\n### 2. **模型 `config` 与超参数的区别**\n\n| **类别**     | **模型配置（Config）**                 | **超参数（Hyperparameters）**                                  |\n| ------------ | -------------------------------------- | -------------------------------------------------------------- |\n| **作用对象** | 模型结构                               | 训练过程                                                       |\n| **典型参数** | 层数、维度、注意力头数、卷积核大小     | 学习率、批量大小（Batch Size）、优化器类型、训练轮数（Epochs） |\n| **保存目的** | 重建模型结构（如加载 `state_dict` 前） | 复现训练过程（如调参、实验对比）                               |\n| **修改频率** | 低频（模型结构稳定后很少改动）         | 高频（需反复调整优化）                                         |\n\n---\n\n### 3. **为什么需要单独管理 `config`？**\n\n- **场景 1：重建模型**  \n  若仅保存 `state_dict`（模型权重），加载时必须**先根据 `config` 重建模型结构**，才能加载权重：\n\n  ```python\n  # 保存\n  torch.save(model.state_dict(), \"model_weights.pth\")\n  with open(\"model_config.json\", \"w\") as f:\n      json.dump(config, f)\n\n  # 加载\n  with open(\"model_config.json\", \"r\") as f:\n      config = json.load(f)\n  model = MyModel(**config)  # 根据 config 实例化模型\n  model.load_state_dict(torch.load(\"model_weights.pth\"))\n  ```\n\n- **场景 2：版本控制与实验复现**  \n  将 `config` 保存为 JSON/YAML 文件，便于记录不同模型结构的实验效果。\n\n- **场景 3：共享模型**  \n  开源社区常用模式（如 HuggingFace Transformers）：\n  - `config.json`：定义模型结构\n  - `pytorch_model.bin`：保存 `state_dict`\n\n---\n\n### 4. **`config` 与超参数的重叠情况**\n\n某些参数可能同时影响模型结构和训练，例如：\n\n- **Dropout 比率**：既是模型结构的一部分，也被视为超参数。\n- **词嵌入维度**：影响模型结构，但可能因训练资源调整（如显存不足时调小维度）。\n\n此时，可以**将两者统一管理**，但建议分开存储：\n\n```python\n# 统一配置文件（config.yaml）\nmodel:\n  num_layers: 12\n  hidden_size: 768\ntraining:\n  learning_rate: 1e-4\n  batch_size: 32\n```\n\n---\n\n### 5. **实际代码示例**\n\n#### 定义模型时使用 `config`：\n\n```python\nclass TransformerModel(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.embedding = nn.Embedding(config[\"vocab_size\"], config[\"hidden_size\"])\n        self.layers = nn.ModuleList([TransformerBlock(config) for _ in range(config[\"num_layers\"])])\n        # ...\n\n# 初始化模型\nconfig = {\"vocab_size\": 30000, \"hidden_size\": 512, \"num_layers\": 6}\nmodel = TransformerModel(config)\n```\n\n#### 保存与加载完整模型（含结构和权重）：\n\n```python\n# 保存（不推荐，但某些场景需要）\nfull_model = {\"config\": config, \"state_dict\": model.state_dict()}\ntorch.save(full_model, \"full_model.pth\")\n\n# 加载\nloaded = torch.load(\"full_model.pth\")\nmodel = TransformerModel(loaded[\"config\"])\nmodel.load_state_dict(loaded[\"state_dict\"])\n```\n\n---\n\n### 6. **总结**\n\n- **模型 `config`**：定义模型结构的参数（如层数、维度），是**重建模型**的必需信息。\n- **超参数**：控制训练过程的参数（如学习率、批量大小），影响模型如何学习。\n- **最佳实践**：\n  - 始终保存 `config`（如 JSON 文件），确保模型可复现。\n  - 分开管理模型配置和训练超参数，避免混淆。\n\n\u003e [!info] 亮曰\n\u003e\n\u003e - Config 主要是定义模型结构。会根据 Config 决定有多少层等。\n\u003e - 超参主要是训练过程中的学习率、 Epochs 等，复现训练过程时需要，但与模型结构无关，只与训练过程有关。\n\n## Q: 所谓\"权重\"就是指 state_dict 中的内容吗？\n\n\u003e [!reasoning]-\n\u003e\n\u003e 嗯，用户问：\"所谓'权重'就是指 state_dict 中的内容吗？\"这个问题看起来是想确认 PyTorch 中的权重和 state_dict 之间的关系。首先，我需要回顾一下之前的对话，确保回答的一致性。\n\u003e\n\u003e 之前已经解释了 state_dict 是保存模型参数的核心，里面包含了各层的权重和偏置。用户可能现在对\"权重\"这个术语的具体指向有疑问，需要明确权重是否等同于 state_dict 中的所有内容。\n\u003e\n\u003e 首先，我应该明确\"权重\"在机器学习中的定义。通常，权重指的是模型中的可学习参数，比如线性层中的权重矩阵和偏置向量。而 state_dict 不仅包括这些权重，还可能包括其他参数，比如 BatchNorm 层的均值和方差，或者优化器的状态。因此，state_dict 的内容可能比单纯的\"权重\"更广泛。\n\u003e\n\u003e 接下来，需要区分 state_dict 中的不同部分。模型和优化器都有自己的 state_dict。模型的 state_dict 包含各层的参数，而优化器的 state_dict 包含优化器的状态，如动量缓存等。用户的问题可能集中在模型的 state_dict 中的权重部分，而是否包括其他参数需要澄清。\n\u003e\n\u003e 另外，用户可能对如何正确保存和加载模型有更深入的理解需求。比如，保存 state_dict 时，是否只保存了权重，还是还有其他必要的参数？需要说明 state_dict 中的内容对于模型重建的重要性，以及权重在其中的角色。\n\u003e\n\u003e 可能用户在实际操作中遇到了问题，比如加载模型时结构不匹配，或者参数未正确加载，因此需要明确 state_dict 中的内容。需要举例说明，比如一个简单的线性模型，展示其 state_dict 中的键值对，明确哪些是权重，哪些是偏置，或者其他类型的参数。\n\u003e\n\u003e 还需要考虑用户可能的误解，比如认为 state_dict 仅包含权重，而忽略了其他必要的参数，导致模型无法正确运行。因此，强调 state_dict 包含所有必要的参数，而权重是其中的一部分，但还有其他如偏置、BatchNorm 的参数等。\n\u003e\n\u003e 此外，用户可能关心如何仅保存或操作权重，比如迁移学习中的部分参数加载。这时候需要说明如何从 state_dict 中选择性地提取或加载特定的权重部分。\n\u003e\n\u003e 总结来说，回答需要明确以下几点：\n\u003e\n\u003e 1. 权重是模型中的可学习参数，如线性层的权重矩阵。\n\u003e\n\u003e 2. state_dict 包含模型的所有参数，包括权重、偏置以及其他层特定的参数。\n\u003e\n\u003e 3. 模型的 state_dict 与优化器的 state_dict 不同，后者包含优化器状态。\n\u003e\n\u003e 4. 正确加载模型需要确保 state_dict 的结构与当前模型结构匹配。\n\u003e\n\u003e 5. 示例说明 state_dict 中的具体内容，帮助用户直观理解。\n\u003e\n\u003e 同时，要注意用词准确，避免混淆，比如\"参数\"和\"权重\"的区别，确保用户能清晰理解两者的包含关系。可能还需要提到在保存和加载时的最佳实践，比如如何结合 config 来重建模型结构，再加载 state_dict 中的参数，以确保模型的正确性。\n\u003e\n\u003e 最后，检查是否有遗漏点，比如是否提到 eval()模式的影响，或者训练/推理时加载参数的注意事项，但根据问题范围，可能不需要展开，除非用户有进一步的问题。\n\n在 PyTorch 中，**\"权重\"确实是 `state_dict` 中的核心内容**，但 `state_dict` 包含的信息可能比\"权重\"更广泛。以下是详细解释：\n\n---\n\n### 1. **\"权重\"是什么？**\n\n- **权重（Weights）** 是模型中**可学习的参数**，例如：\n  - 全连接层（`nn.Linear`）中的权重矩阵（`weight`）和偏置（`bias`）。\n  - 卷积层（`nn.Conv2d`）的卷积核参数。\n  - 嵌入层（`nn.Embedding`）的词向量矩阵。\n- 这些参数通过反向传播和优化器（如 SGD、Adam）在训练过程中逐步更新。\n\n---\n\n### 2. **`state_dict` 中的内容**\n\n`state_dict` 是 PyTorch 中模型或优化器的**状态字典**，具体包含：\n\n- **对模型而言**：\n  - 所有权重（`weight`）、偏置（`bias`）。\n  - 其他**与层相关的参数**，例如：\n    - `BatchNorm` 层的 `running_mean` 和 `running_var`（在推理时使用的均值和方差）。\n    - `LSTM` 或 `GRU` 中的隐藏状态缓存（如果模型设计时显式存储了这些状态）。\n  ```python\n  # 示例：一个简单模型的 state_dict\n  model = nn.Sequential(\n      nn.Linear(10, 20),\n      nn.ReLU(),\n      nn.BatchNorm1d(20)\n  )\n  print(model.state_dict().keys())\n  # 输出：\n  # ['0.weight', '0.bias', '2.weight', '2.bias', '2.running_mean', '2.running_var', '2.num_batches_tracked']\n  ```\n- **对优化器而言**：\n  - 优化器的状态（如动量缓存、历史梯度等）。\n  ```python\n  optimizer = torch.optim.Adam(model.parameters())\n  print(optimizer.state_dict().keys())\n  # 输出：\n  # ['state', 'param_groups']\n  ```\n\n---\n\n### 3. **\"权重\"与 `state_dict` 的关系**\n\n- **`state_dict` 包含权重，但不仅限于权重**：\n  - 权重是 `state_dict` 中的一部分（如 `conv1.weight`, `fc.bias`）。\n  - `state_dict` 还可能包含**非可学习的参数**（如 `BatchNorm` 的统计量 `running_mean`）。\n  - 对于复杂模型（如 Transformer），还可能包含位置编码、注意力掩码等参数。\n- **总结**：\n  - **权重是 `state_dict` 的核心内容**，但 `state_dict` 是更全面的模型状态表示。\n\n---\n\n### 4. **为什么需要 `state_dict` 而不仅仅是权重？**\n\n- **完整恢复模型状态**：\n  如果仅保存权重，忽略 `BatchNorm` 的 `running_mean` 等参数，在推理时会导致统计量错误，影响模型性能。\n- **兼容性**：\n  加载模型时需确保 `state_dict` 的键（如层名称）与当前模型结构严格匹配，否则会报错 `Missing keys` 或 `Unexpected keys`。\n- **灵活性**：\n  可以手动修改 `state_dict`，例如迁移学习中仅加载部分层的权重。\n\n---\n\n### 5. **操作 `state_dict` 的常见场景**\n\n#### **(1) 查看模型权重**\n\n```python\nfor name, param in model.named_parameters():\n    print(f\"层名: {name}, 参数形状: {param.shape}\")\n```\n\n#### **(2) 选择性加载部分权重（迁移学习）**\n\n```python\npretrained_dict = torch.load('pretrained.pth')\nmodel_dict = model.state_dict()\n\n# 筛选出名称和形状匹配的权重\npretrained_dict = {\n    k: v for k, v in pretrained_dict.items()\n    if k in model_dict and v.shape == model_dict[k].shape\n}\nmodel_dict.update(pretrained_dict)\nmodel.load_state_dict(model_dict)\n```\n\n#### **(3) 手动修改权重**\n\n```python\n# 将第一层卷积的权重置零\nwith torch.no_grad():\n    model.conv1.weight.copy_(torch.zeros_like(model.conv1.weight))\n```\n\n---\n\n### 6. **总结**\n\n- **权重**是模型的可学习参数，是 `state_dict` 的核心内容。\n- **`state_dict`** 是模型状态的完整表示，包括：\n  - 所有权重、偏置。\n  - 非可学习的运行时参数（如 `BatchNorm` 的统计量）。\n- **最佳实践**：\n  - 保存模型时使用 `torch.save(model.state_dict(), ...)`。\n  - 加载时需先构建相同结构的模型，再调用 `model.load_state_dict()`。\n  - 若需调整模型结构，可选择性加载匹配的权重。\n\n\u003e [!info] 亮曰\n\u003e\n\u003e state_dict 包括 Parameter 与 Buffer ，模型的可学习参数——**权重**主要指其中的 Parameter 。\n","title":"PyTorch 模型的保存与加载机制详解","abstract":"\u003e 本文为与 DeepSeek 对话记录，深入探讨 PyTorch 中模型的保存和加载机制，包括不同的保存方式、最佳实践以及常见问题的解决方案。\n\u003e [!reasoning]-\n\u003e","length":433,"created_at":"2025-03-07T13:00:00.000Z","updated_at":"2025-03-07T13:00:00.000Z","tags":["Deep Learning","PyTorch","Model Management"],"license":true}},{"pathMapping":{"filePath":"public/content/learn_from_ai/2025-03-06-pytorch-backpropagation-mechanism.md","pagePath":"/learn_from_ai/pytorch-backpropagation-mechanism","slug":"pytorch-backpropagation-mechanism"},"meta":{"content":"\n\u003e 本文为用户与 DeepSeek 的问答。主题为 PyTorch 的反向传播机制。本文从数学原理、计算图机制和实际需求三个方面深入解释其工作原理，并结合 PyTorch 的自动微分（Autograd）系统进行说明。\n\n## Q; 深入解析 PyTorch 中的反向传播机制\n\n\u003e [!query]\n\u003e\n\u003e 深入解释 torch 中反向传播机制的数学原理与为何需要反向传播机制。提示：你可以使用公式、Mermaid 图表、表格等方式使内容更容易理解。\n\n\u003e [!reasoning]-\n\u003e\n\u003e 嗯，用户让我深入解释 PyTorch 中的反向传播机制的数学原理以及为什么需要它。好的，我得先回忆一下反向传播的基础知识，然后结合 PyTorch 的具体实现来展开。\n\u003e\n\u003e 首先，反向传播是神经网络训练的核心，用于计算梯度。用户可能已经了解梯度下降，但需要更底层的数学解释。我应该从计算图开始，因为 PyTorch 使用动态图机制。每个张量的运算都会记录在计算图中，这样在反向传播时可以自动计算梯度。\n\u003e\n\u003e 数学原理方面，得先讲链式法则。比如，假设有一个简单的函数，y = w*x + b，然后损失函数是 L = (y - t)^2。那么求 L 对 w 的梯度就需要链式法则：dL/dw = dL/dy * dy/dw。反向传播的过程就是从输出层开始，逐层应用链式法则，将梯度传播回各层的参数。\n\u003e\n\u003e 然后需要解释为什么需要反向传播。手动计算梯度在复杂网络中不现实，反向传播自动高效地计算所有参数的梯度，节省了时间和减少错误。可能还需要比较前向传播和反向传播的计算量，比如反向传播如何复用前向的中间结果，提高效率。\n\u003e\n\u003e PyTorch 中的 autograd 机制是关键。每个 Tensor 的.grad_fn 属性记录了创建它的操作，这样在调用.backward()时，会沿着这些函数形成的计算图反向遍历，应用链式法则。需要举例说明，比如构建一个简单的计算图，然后展示梯度计算的过程。\n\u003e\n\u003e 可能用户对计算图的具体实现细节感兴趣，比如 PyTorch 的动态图特性，每次前向传播都会构建新的图，这样更灵活。但数学原理还是链式法则，不管图的结构如何变化，梯度计算的方法是一致的。\n\u003e\n\u003e 另外，可能需要提到为什么不能只用数值方法来近似梯度，比如计算资源的问题，尤其是高维参数时，数值梯度计算量太大。而反向传播通过解析法高效计算，适合深度学习的大规模参数。\n\u003e\n\u003e 还要注意解释叶子节点和中间节点的梯度存储情况，PyTorch 默认只保留叶子节点的梯度，中间节点的梯度会被释放以节省内存。这可能在训练大模型时很重要，用户可能需要了解如何控制梯度的保留。\n\u003e\n\u003e 或许用户对反向传播的数学推导有更深的需求，比如如何扩展到多层网络，或者如何处理复杂的层结构如卷积层、循环层。但根据问题，可能只需要基础数学，比如链式法则的多次应用，以及如何累积各层的梯度。\n\u003e\n\u003e 最后，总结反向传播的必要性：自动化、高效、准确计算梯度，使得训练深层网络可行。而 PyTorch 的自动微分机制让用户无需手动实现这些复杂的计算，只需关注模型结构。\n\u003e\n\u003e 可能需要用公式来展示链式法则的应用，比如多层的梯度相乘。例如，一个三层的网络，每一层的权重梯度如何计算。同时，用 Mermaid 图展示计算图的结构，说明前向和反向的路径。\n\u003e\n\u003e 还有可能要考虑激活函数的导数，比如 ReLU 在反向传播中的处理，这样在计算图中如何处理不可导点，但 PyTorch 的 autograd 会自动处理这些。\n\u003e\n\u003e 总之，我需要从数学原理（链式法则）、计算图的概念、PyTorch 的实现机制（动态图、autograd）、以及反向传播的必要性（高效、自动）这几个方面来组织内容，并用公式和图表辅助说明。\n\u003e\n\u003e 最后，我需要用一个具体的例子，比如一个简单的神经网络，来展示反向传播的整个过程，包括前向传播、反向传播、梯度计算和参数更新。这样用户可以直观地理解反向传播的每个步骤。\n\u003e\n\u003e 如果用户对 PyTorch 的代码实现感兴趣，我也可以提供一些关键代码段的解析，比如如何定义计算图、如何跟踪梯度、如何执行反向传播等。\n\u003e\n\u003e 总之，我需要确保解释清晰，结合数学原理和代码示例，帮助用户理解 PyTorch 中的反向传播机制。\n\n### 深入解析 PyTorch 中的反向传播机制\n\n反向传播（Backpropagation）是神经网络训练的核心算法。本文将从数学原理、计算图机制和实际需求三个方面深入解释其工作原理，并结合 PyTorch 的自动微分（Autograd）系统进行说明。\n\n---\n\n#### 一、反向传播的数学原理\n\n##### 1. 链式法则（Chain Rule）\n\n反向传播本质上是链式法则的高效实现。假设神经网络的计算流程为：\n\n$$\nL = f(g(h(x)))\n$$\n\n其中：\n\n- $$ h(x) = W_1x + b_1 $$\n- $$ g(z) = \\text{ReLU}(z) $$\n- $$ f(y) = \\frac{1}{2}(y - t)^2 $$ （均方误差损失）\n\n则梯度计算为：\n\n$$\n\\frac{\\partial L}{\\partial W_1} = \\frac{\\partial L}{\\partial f} \\cdot \\frac{\\partial f}{\\partial g} \\cdot \\frac{\\partial g}{\\partial h} \\cdot \\frac{\\partial h}{\\partial W_1}\n$$\n\n##### 2. 梯度累积公式\n\n对于任意参数 $$ \\theta $$，梯度计算可表示为：\n\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\theta} = \\sum_{\\text{path } \\theta \\to \\mathcal{L}} \\left( \\prod_{i} \\frac{\\partial \\text{op}_i}{\\partial \\text{input}_i} \\right)\n$$\n\n---\n\n#### 二、PyTorch 的实现机制\n\n##### 1. 动态计算图（Dynamic Computation Graph）\n\nPyTorch 在前向传播时自动构建计算图，节点为张量，边为运算操作：\n\n```mermaid\ngraph LR\n  x((x)) --\u003e MatMul --\u003e h((h))\n  W1((W1)) --\u003e MatMul\n  b1((b1)) --\u003e Add --\u003e z((z))\n  h --\u003e Add\n  z --\u003e ReLU --\u003e y((y))\n  y --\u003e MSE --\u003e Loss((Loss))\n```\n\n##### 2. Autograd 核心组件\n\n| 组件                   | 作用                                     |\n| ---------------------- | ---------------------------------------- |\n| `Tensor.requires_grad` | 标记需要跟踪梯度的张量                   |\n| `Tensor.grad_fn`       | 记录创建该张量的操作（如 `MulBackward`） |\n| `Tensor.grad`          | 存储计算得到的梯度                       |\n\n##### 3. 反向传播过程\n\n```python\nimport torch\n\nx = torch.tensor([2.0], requires_grad=True)\nW = torch.tensor([3.0], requires_grad=True)\ny = W * x\ny.backward()\n\nprint(W.grad)  # 输出: tensor([2.])\nprint(x.grad)  # 输出: tensor([3.])\n```\n\n---\n\n#### 三、为何需要反向传播？\n\n##### 1. 手动计算不可行性\n\n对于包含百万参数的现代神经网络，手动计算梯度的时间复杂度为 $$ O(n^2) $$ ，而反向传播只需 $$ O(n) $$ 。\n\n##### 2. 计算效率对比\n\n| 方法                 | 时间复杂度   | 空间复杂度 | 数值稳定性 |\n| -------------------- | ------------ | ---------- | ---------- |\n| 数值微分             | $$ O(n^2) $$ | $$ O(1) $$ | 差         |\n| 符号微分             | $$ O(1) $$   | $$ O(n) $$ | 好         |\n| 自动微分（反向传播） | $$ O(n) $$   | $$ O(n) $$ | 优秀       |\n\n##### 3. 内存优化策略\n\nPyTorch 采用以下技术降低内存占用：\n\n- **梯度检查点**：只保留关键节点的中间结果\n- **即时释放中间梯度**：默认只保留叶子节点的梯度\n\n---\n\n#### 四、反向传播的数学扩展\n\n##### 1. 矩阵求导示例\n\n对于全连接层 $$ Y = XW + b $$ ，梯度计算为：\n\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial W} = X^T \\cdot \\frac{\\partial \\mathcal{L}}{\\partial Y}\n$$\n\n##### 2. 复杂运算处理\n\n```python\n# PyTorch 自动处理不可导点\nx = torch.tensor([-1.0, 0.0, 2.0], requires_grad=True)\ny = torch.relu(x)\ny.backward(torch.tensor([1.0, 1.0, 1.0]))\nprint(x.grad)  # 输出: tensor([0., 0., 1.])\n```\n\n---\n\n#### 五、总结\n\n**反向传播的必要性**：\n\n1. **自动微分**：避免手工推导复杂导数\n2. **计算高效**：利用链式法则的分解特性\n3. **内存优化**：动态图的即时构建与销毁\n4. **框架支撑**：支持任意复杂网络结构\n\nPyTorch 通过动态计算图和 Autograd 系统，将反向传播的数学原理高效实现，使得深度学习模型的训练变得可行且高效。理解这一机制对于调试模型、优化内存使用和实现自定义算子至关重要。\n\n## Q: 参数的梯度累加计算公式\n\n\u003e [!query]\n\u003e\n\u003e 你提到对于任意参数 $$ \\theta $$，梯度计算可表示为：\n\u003e\n\u003e $$\n\u003e \\frac{\\partial \\mathcal{L}}{\\partial \\theta} = \\sum_{\\text{path } \\theta \\to \\mathcal{L}} \\left( \\prod_{i} \\frac{\\partial \\text{op}_i}{\\partial \\text{input}_i} \\right)\n\u003e $$\n\u003e\n\u003e 这个公式我没懂，再深入解释一下。我只有本科程度的高等数学知识与线性代数知识，建议一步一步解释推理过程。\n\n\u003e [!reasoning]-\n\u003e\n\u003e 嗯，用户问的是关于反向传播中梯度计算的公式，那个公式看起来有点复杂，对吧？让我先仔细看看用户的问题。他提到，对于任意参数 θ，梯度计算是路径 θ 到 L 的和，每个路径中的各个操作的导数相乘。用户本科数学和线性代数基础，可能需要更基础的解释。\n\u003e\n\u003e 首先，我需要确认用户对这个公式的理解程度。公式里的求和符号和路径可能让他困惑。可能用户对链式法则有一定的了解，但路径的概念不太清楚。比如，在计算图中，参数 θ 到损失 L 可能有多个不同的路径，每个路径对应一个梯度贡献，所以梯度是这些路径贡献的总和。\n\u003e\n\u003e 接下来，我需要用更简单的方式来解释这个公式。或许用一个具体的例子来说明会更好。比如，假设有一个简单的计算图，其中 θ 分两个路径影响 L，每个路径都需要计算导数的乘积，然后将它们相加。\n\u003e\n\u003e 然后，我应该分步骤解释链式法则，以及为什么需要将不同路径的梯度相加。可能需要用图示来辅助，比如画一个简单的计算图，展示多个分支的情况，每个分支对应一个乘积项，最后相加得到总的梯度。\n\u003e\n\u003e 另外，用户可能对“路径”这个词不太理解，需要明确在计算图中的路径指的是什么。例如，一个参数可能在多个层中使用，每次使用都会创建一个不同的路径到损失函数，因此每个路径的梯度都需要被计算并累加。\n\u003e\n\u003e 还要注意，用户可能对乘积的部分有疑问，为什么是各个操作的导数相乘。这时候需要回顾链式法则的基本原理，即复合函数求导时，外层函数的导数和内层函数的导数相乘，而如果有多个中间步骤，就需要连乘这些导数。\n\u003e\n\u003e 可能还需要解释为什么会有多个路径，例如在神经网络中，一个参数可能在多个神经元中被使用，或者在不同的时间步（如 RNN 中），导致梯度需要从各个路径反向传播回来，然后累加起来。\n\u003e\n\u003e 最后，通过一个具体的数学例子，逐步计算每个步骤的导数，并将它们相乘，最后相加，来验证这个公式的正确性。这样用户可以通过实际的计算过程理解抽象的公式。\n\u003e\n\u003e 总结一下，我需要用具体的例子、图示，分步骤解释链式法则在计算图中的多个路径中的应用，以及梯度累加的原因，帮助用户理解这个公式的含义和推导过程。\n\n好的！我将用最直观的方式，通过一个具体例子逐步解释这个公式的数学原理。我们结合图示和分步推导来理解链式法则在反向传播中的应用。\n\n---\n\n### **一、问题场景设定**\n\n假设我们有一个简单的计算图，其中参数 $$\\theta$$ 通过两条路径影响最终损失 $$L$$ ：\n\n```mermaid\ngraph LR\n    θ((θ)) --\u003e Op1 --\u003e A\n    θ --\u003e Op2 --\u003e B\n    A --\u003e Op3 --\u003e L\n    B --\u003e Op3 --\u003e L\n```\n\n- **路径 1**：$$\\theta \\xrightarrow{\\text{Op1}} A \\xrightarrow{\\text{Op3}} L$$\n- **路径 2**：$$\\theta \\xrightarrow{\\text{Op2}} B \\xrightarrow{\\text{Op3}} L$$\n\n目标是计算 $$\\frac{\\partial L}{\\partial \\theta}$$。\n\n---\n\n### **二、分步推导**\n\n#### **步骤 1：前向传播表达式**\n\n假设具体操作为：\n\n- $$A = \\theta^2$$ （Op1：平方操作）\n- $$B = 2\\theta$$ （Op2：线性操作）\n- $$L = A + B$$ （Op3：加法操作）\n\n则最终损失为：\n\n$$\nL = \\theta^2 + 2\\theta\n$$\n\n#### **步骤 2：直接求导（对比验证）**\n\n直接对 $$L$$ 求导：\n\n$$\n\\frac{\\partial L}{\\partial \\theta} = 2\\theta + 2\n$$\n\n---\n\n#### **步骤 3：反向传播视角**\n\n根据计算图，梯度需要沿着两条路径反向传播：\n\n##### **路径 1 的梯度计算（θ → A → L）**\n\n1. $$A = \\theta^2 \\quad \\Rightarrow \\quad \\frac{\\partial A}{\\partial \\theta} = 2\\theta$$\n2. $$L = A + B \\quad \\Rightarrow \\quad \\frac{\\partial L}{\\partial A} = 1$$\n3. 路径 1 的梯度贡献：\n   $$\n   \\frac{\\partial L}{\\partial \\theta} \\bigg|_{\\text{路径1}} = \\frac{\\partial L}{\\partial A} \\cdot \\frac{\\partial A}{\\partial \\theta} = 1 \\cdot 2\\theta = 2\\theta\n   $$\n\n##### **路径 2 的梯度计算（θ → B → L）**\n\n1. $$B = 2\\theta \\quad \\Rightarrow \\quad \\frac{\\partial B}{\\partial \\theta} = 2$$\n2. $$L = A + B \\quad \\Rightarrow \\quad \\frac{\\partial L}{\\partial B} = 1$$\n3. 路径 2 的梯度贡献：\n   $$\n   \\frac{\\partial L}{\\partial \\theta} \\bigg|_{\\text{路径2}} = \\frac{\\partial L}{\\partial B} \\cdot \\frac{\\partial B}{\\partial \\theta} = 1 \\cdot 2 = 2\n   $$\n\n##### **总梯度 = 路径 1 + 路径 2**\n\n$$\n\\frac{\\partial L}{\\partial \\theta} = 2\\theta + 2\n$$\n\n---\n\n### **三、通用公式解析**\n\n原公式：\n\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\theta} = \\sum_{\\text{path } \\theta \\to \\mathcal{L}} \\left( \\prod_{i} \\frac{\\partial \\text{op}_i}{\\partial \\text{input}_i} \\right)\n$$\n\n#### **1. 符号解释**\n\n- **路径（Path）**：参数 $$\\theta$$ 到损失 $$\\mathcal{L}$$ 的所有可能数据流动路径。\n- **乘积项 $$\\prod$$**：沿某条路径的所有操作（op）的导数连乘（链式法则）。\n- **求和项 $$\\sum$$**：将所有路径的梯度贡献相加（多路径时梯度累加）。\n\n#### **2. 关键性质**\n\n- **链式法则**：复合函数的导数 = 外层导数 × 内层导数。\n- **多路径叠加**：如果参数影响输出的多个分支，梯度是各分支贡献的总和。\n\n---\n\n### **四、复杂案例验证**\n\n考虑一个更复杂的计算图：\n\n```mermaid\ngraph LR\n    θ((θ)) --\u003e Op1 --\u003e C\n    θ --\u003e Op2 --\u003e D\n    C --\u003e Op3 --\u003e E\n    D --\u003e Op4 --\u003e E\n    E --\u003e Op5 --\u003e L\n```\n\n#### **前向传播表达式**\n\n- $$C = \\theta^3$$（Op1）\n- $$D = \\sin(\\theta)$$（Op2）\n- $$E = C \\cdot D$$（Op3）\n- $$L = \\ln(E)$$（Op4）\n\n#### **反向传播计算**\n\n##### **路径 1：θ → C → E → L**\n\n$$\n\\frac{\\partial L}{\\partial \\theta} \\bigg|_{\\text{路径1}} = \\frac{\\partial L}{\\partial E} \\cdot \\frac{\\partial E}{\\partial C} \\cdot \\frac{\\partial C}{\\partial \\theta} = \\frac{1}{E} \\cdot D \\cdot 3\\theta^2\n$$\n\n##### **路径 2：θ → D → E → L**\n\n$$\n\\frac{\\partial L}{\\partial \\theta} \\bigg|_{\\text{路径2}} = \\frac{\\partial L}{\\partial E} \\cdot \\frac{\\partial E}{\\partial D} \\cdot \\frac{\\partial D}{\\partial \\theta} = \\frac{1}{E} \\cdot C \\cdot \\cos(\\theta)\n$$\n\n##### **总梯度**\n\n$$\n\\frac{\\partial L}{\\partial \\theta} = \\frac{D \\cdot 3\\theta^2 + C \\cdot \\cos(\\theta)}{E}\n$$\n\n---\n\n### **五、反向传播的本质**\n\n1. **自动化的链式法则**：框架通过计算图自动追踪操作路径。\n2. **梯度累加规则**：当一个参数影响多个分支时，梯度是所有路径贡献的总和。\n3. **计算效率**：避免重复计算，时间复杂度与网络深度成线性关系（$$O(n)$$）。\n\n---\n\n### **六、总结**\n\n- **为什么需要求和（$$\\sum$$）**：因为参数可能通过多个路径影响损失，每个路径贡献一部分梯度。\n- **为什么需要连乘（$$\\prod$$）**：链式法则要求将路径上的所有局部导数相乘。\n- **反向传播的优势**：将复杂的全局求导分解为局部导数的连乘与路径求和，大幅降低计算复杂度。\n\n通过这种分路径计算再累加的方式，反向传播巧妙地利用计算图的结构信息，实现了高效的梯度计算。\n\n## Q: 从 PyTorch 代码层面深入解释一下 PyTorch 的反向传播如何实现\n\n\u003e [!query]\n\u003e\n\u003e 从 PyTorch 代码层面深入解释一下 PyTorch 的反向传播如何实现\n\n\u003e [!reasoning]-\n\u003e\n\u003e 嗯，用户之前已经了解了反向传播的数学原理和为什么需要它，现在他们想从 PyTorch 代码层面深入理解反向传播的实现。用户可能有一定的编程基础，但可能对 PyTorch 的内部机制不太熟悉。我需要确保解释清晰，结合代码示例，同时避免过于复杂的术语。\n\u003e\n\u003e 首先，用户提到了之前的公式，关于梯度的路径求和，现在需要将这一数学概念与 PyTorch 的具体实现联系起来。他们可能想知道 PyTorch 是如何动态构建计算图的，如何跟踪梯度，以及 backward()方法具体做了什么。\n\u003e\n\u003e 接下来，我应该分步骤解释 PyTorch 的关键组件，比如 Tensor 的 requires_grad 属性、grad_fn、grad 属性，以及动态计算图的构建过程。需要举例说明，比如一个简单的计算图，并展示梯度是如何累积的。同时，用户可能对梯度累积和内存管理感兴趣，比如 PyTorch 如何释放中间变量，如何通过 retain_grad()来保留梯度。\n\u003e\n\u003e 另外，用户可能对多路径梯度累加的情况有疑问，比如当多个操作影响同一个参数时，梯度是如何相加的。这时候需要举例说明，比如一个参数通过两条路径影响损失函数，PyTorch 如何处理这种情况。\n\u003e\n\u003e 还需要提到 Autograd 引擎的工作原理，比如如何遍历计算图，执行反向传播，以及如何优化计算效率。可能还需要讨论一些高级话题，比如 detach()的作用，或者如何自定义反向传播函数，但根据用户的知识水平，可能需要保持基础。\n\u003e\n\u003e 用户可能存在的误区是认为 PyTorch 会保存所有中间变量的梯度，但实际上默认只保留叶子节点的梯度。这需要特别说明，并解释如何通过 retain_grad()来查看中间节点的梯度。\n\u003e\n\u003e 最后，应该总结 PyTorch 反向传播的关键点，强调其动态计算图的优势，以及如何高效管理内存和计算资源。确保用户理解为什么 PyTorch 适合动态图模型，以及在实际调试中如何利用这些机制。\n\n以下是关于 PyTorch 反向传播实现机制的代码级深入解析，结合关键代码段和底层原理说明：\n\n---\n\n### **一、PyTorch 反向传播的三大核心组件**\n\n#### **1. Tensor 的梯度追踪机制**\n\n```python\nimport torch\n\n# 创建需要梯度追踪的张量\nx = torch.tensor([2.0], requires_grad=True)  # 叶子节点\nW = torch.tensor([3.0], requires_grad=True)  # 叶子节点\n\n# 执行计算（自动记录操作）\ny = W * x           # grad_fn=\u003cMulBackward0\u003e\nz = y + 1           # grad_fn=\u003cAddBackward0\u003e\nloss = z.mean()      # grad_fn=\u003cMeanBackward0\u003e\n\nprint(loss.grad_fn)  # 输出: \u003cMeanBackward0 object\u003e\n```\n\n- **`requires_grad=True`**：标记需要追踪梯度的张量（叶子节点）\n- **`grad_fn`**：记录创建该张量的操作（反向传播时知道如何计算梯度）\n\n#### **2. 计算图的动态构建**\n\nPyTorch 的计算图是**动态构建的**，每次前向传播都会新建一个图：\n\n```python\n# 示例：动态图特性\ndef forward(x):\n    if x.sum() \u003e 0:\n        return x * 2\n    else:\n        return x * (-1)\n\nx = torch.tensor([3.0], requires_grad=True)\nout = forward(x)  # 根据输入值动态创建不同的计算图\nout.backward()    # 自动适应不同的分支路径\n```\n\n#### **3. 反向传播引擎（Autograd Engine）**\n\n当调用 `.backward()` 时，PyTorch 会执行以下操作：\n\n```python\nloss.backward()  # 触发反向传播\n```\n\n- **反向遍历计算图**：从 `loss` 的 `grad_fn` 开始，沿着 `next_functions` 递归\n- **计算局部梯度**：在每个操作节点调用已注册的 `backward()` 方法\n- **梯度累加**：将计算结果累积到对应张量的 `.grad` 属性中\n\n---\n\n### **二、代码级反向传播流程分解**\n\n#### **步骤 1：前向传播构建计算图**\n\n```python\na = torch.tensor(2.0, requires_grad=True)\nb = torch.tensor(3.0, requires_grad=True)\nc = a * b      # grad_fn=\u003cMulBackward0\u003e\nd = c + 1      # grad_fn=\u003cAddBackward0\u003e\nloss = d**2    # grad_fn=\u003cPowBackward0\u003e\n```\n\n此时的计算图结构：\n\n```mermaid\ngraph LR\n  a --\u003e Mul --\u003e c\n  b --\u003e Mul\n  c --\u003e Add --\u003e d\n  d --\u003e Pow --\u003e loss\n```\n\n#### **步骤 2：执行反向传播**\n\n```python\nloss.backward()  # 触发反向传播\n```\n\n##### **底层操作分解**：\n\n1. **初始化梯度**：设置 `loss.grad = 1.0`（标量损失的默认梯度）\n2. **反向传播到 d**：\n   - 调用 `PowBackward0` 的 `backward()` 方法：\n     ```python\n     d_grad = 2 * d  # 导数公式：d(loss)/d(d) = 2d\n     ```\n3. **反向传播到 c**：\n   - 调用 `AddBackward0` 的 `backward()` 方法：\n     ```python\n     c_grad = d_grad * 1  # 加法操作的导数为1\n     ```\n4. **反向传播到 a 和 b**：\n   - 调用 `MulBackward0` 的 `backward()` 方法：\n     ```python\n     a_grad = c_grad * b  # 导数公式：d(c)/d(a) = b\n     b_grad = c_grad * a  # 导数公式：d(c)/d(b) = a\n     ```\n5. **梯度累加**：\n   ```python\n   a.grad += a_grad  # 实际为 in-place 操作\n   b.grad += b_grad\n   ```\n\n#### **步骤 3：查看结果**\n\n```python\nprint(a.grad)  # 输出: 2*d* b = 2*(2*3+1)*3 = 42\nprint(b.grad)  # 输出: 2*d* a = 2*(2*3+1)*2 = 28\n```\n\n---\n\n### **三、PyTorch 反向传播的关键实现细节**\n\n#### **1. 梯度计算规则注册**\n\n每个 `torch` 操作都有预定义的梯度计算规则：\n\n```python\n# 示例：自定义操作的梯度规则\nclass MyAdd(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x, y):\n        ctx.save_for_backward(x, y)  # 保存前向传播的输入\n        return x + y\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        x, y = ctx.saved_tensors\n        return grad_output * 1, grad_output * 1  # 加法操作的导数\n\n# 使用自定义操作\na = torch.tensor(2.0, requires_grad=True)\nb = torch.tensor(3.0, requires_grad=True)\nc = MyAdd.apply(a, b)\nc.backward()\n```\n\n#### **2. 梯度累加机制**\n\nPyTorch 默认会**累加梯度**，因此每次反向传播前需要手动清零：\n\n```python\noptimizer.zero_grad()  # 标准训练循环中的必要操作\nloss.backward()        # 梯度会累加到 .grad 属性中\noptimizer.step()\n```\n\n#### **3. 非标量张量的反向传播**\n\n当输出为非标量时，需要提供 `gradient` 参数：\n\n```python\nx = torch.tensor([1.0, 2.0], requires_grad=True)\ny = x * 2\n\n# 假设 y 是向量，需要提供梯度初始值\ny.backward(gradient=torch.tensor([0.1, 0.2]))\nprint(x.grad)  # 输出: tensor([0.2, 0.4])\n```\n\n#### **4. 内存优化策略**\n\n- **中间变量释放**：默认只保留叶子节点的梯度\n- **梯度检查点**：通过 `torch.utils.checkpoint` 减少内存占用\n- **禁用梯度计算**：使用 `with torch.no_grad():` 或 `@torch.inference_mode()`\n\n---\n\n### **四、可视化反向传播过程**\n\n#### **示例代码**\n\n```python\nimport torchviz\n\na = torch.tensor(3.0, requires_grad=True)\nb = torch.tensor(4.0, requires_grad=True)\nc = a * b\nd = c.sin()\nd.backward()\n\n# 生成计算图可视化\ntorchviz.make_dot(d, params={'a':a, 'b':b}).render(\"graph\")\n```\n\n#### **生成的计算图结构**\n\n```mermaid\ngraph LR\n  a((a)) --\u003e Mul --\u003e c\n  b((b)) --\u003e Mul\n  c --\u003e Sin --\u003e d((d))\n  d --\u003e Backward\n```\n\n---\n\n### **五、PyTorch 反向传播的性能优化**\n\n#### **1. 异步执行**\n\n```python\n# 使用 CUDA 流实现异步计算\nwith torch.cuda.stream(torch.cuda.Stream()):\n    loss.backward()  # 在非默认流中执行反向传播\n```\n\n#### **2. 混合精度训练**\n\n```python\nscaler = torch.cuda.amp.GradScaler()\n\nwith torch.cuda.amp.autocast():\n    output = model(input)\n    loss = loss_fn(output, target)\n\nscaler.scale(loss).backward()  # 自动缩放梯度\nscaler.step(optimizer)\nscaler.update()\n```\n\n#### **3. 梯度裁剪**\n\n```python\ntorch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n```\n\n---\n\n### **六、调试技巧**\n\n#### **1. 检查梯度是否存在**\n\n```python\nprint([p.requires_grad for p in model.parameters()])  # 检查参数是否启用梯度\n```\n\n#### **2. 梯度数值检查**\n\n```python\nfor name, param in model.named_parameters():\n    if param.grad is not None:\n        print(f\"{name} 梯度均值: {param.grad.mean().item()}\")\n```\n\n#### **3. 保留中间梯度**\n\n```python\ny = x * 2\ny.retain_grad()  # 强制保留中间变量的梯度\ny.backward()\nprint(y.grad)    # 可以查看中间梯度\n```\n\n---\n\n### **七、底层实现原理**\n\n#### **1. C++ 核心引擎**\n\nPyTorch 的反向传播引擎主要由以下 C++ 组件构成：\n\n- **`torch::autograd::Engine`**：管理反向传播任务的执行\n- **`torch::autograd::Node`**：表示计算图中的操作节点\n- **`torch::autograd::Edge`**：表示节点之间的连接关系\n\n#### **2. 反向传播任务调度**\n\n```cpp\n// 伪代码：引擎执行流程\nvoid Engine::execute(const EdgeList\u0026 roots) {\n    // 1. 构建任务队列\n    // 2. 使用线程池并行执行反向任务\n    // 3. 处理依赖关系（拓扑排序）\n    // 4. 调用每个 Node 的 apply() 方法\n}\n```\n\n---\n\n### **八、总结：PyTorch 反向传播的设计哲学**\n\n1. **动态计算图**：即时构建、即时销毁，灵活适应可变网络结构\n2. **延迟计算**：只在需要时执行梯度计算，优化内存使用\n3. **分离式设计**：前向传播记录操作，反向传播时执行实际计算\n4. **可扩展性**：通过注册自定义 Function 支持任意复杂操作\n\n理解这些底层机制，可以帮助开发者：\n\n- 更高效地调试梯度相关问题\n- 合理控制内存使用（如使用 `detach()` 截断计算图）\n- 实现自定义神经网络层和损失函数\n- 优化训练过程的性能\n\n## Q: 深入讲解几种微分方法的复杂度与数值稳定性\n\n\u003e [!query]\n\u003e\n\u003e 你之前提到数值微分、符号微分、自动微分的时间空间复杂度以及数值稳定性的对比。这些复杂度是如何计算出的结果？数值稳定性又如何评估？\n\n\u003e [!reasoning]-\n\u003e\n\u003e 好的，我现在需要仔细理解用户的问题。用户之前询问了 PyTorch 的反向传播机制，现在针对数值微分、符号微分和自动微分的时间空间复杂度以及数值稳定性对比提出疑问，想知道这些复杂度是如何计算的，以及数值稳定性如何评估。用户可能在学习这些微分方法时，对背后的数学原理和评估方法感到困惑，需要更深入的解释。\n\u003e\n\u003e 首先，我需要回忆数值微分、符号微分和自动微分的基本概念。数值微分是通过有限差分近似导数，符号微分是通过代数规则求导表达式，自动微分（如反向传播）则是通过分解计算过程，利用链式法则高效计算梯度。用户已经知道它们的复杂度对比表格，但需要了解这些复杂度是如何得出的，以及数值稳定性的评估方法。\n\u003e\n\u003e 接下来，时间复杂度的计算。对于数值微分，假设有 n 个参数，每个参数都需要单独计算梯度，每次计算需要两次前向传播（f(x+h)和 f(x-h)），所以总的时间复杂度是 O(n)的前向计算乘以 n 个参数，得到 O(n^2)。而自动微分只需要一次前向和一次反向传播，反向传播的时间复杂度与前向相当，所以总的是 O(n)。符号微分则可能因为表达式膨胀导致最坏情况指数级复杂度，但通常情况是线性的，但需要存储整个表达式，空间复杂度高。这些需要详细解释。\n\u003e\n\u003e 空间复杂度方面，数值微分不需要存储中间变量，所以是 O(1)。自动微分需要存储计算图中的中间结果，所以是 O(n)。符号微分需要存储整个符号表达式，可能随着求导次数增加而膨胀，所以空间复杂度是 O(n)。这里可能需要更具体的例子说明。\n\u003e\n\u003e 数值稳定性方面，数值微分因为使用了有限差分，容易受到舍入误差影响，尤其是当 h 很小时。符号微分因为是精确求导，稳定性好。自动微分通过链式法则计算，精度与数学推导相同，所以稳定性优秀。需要解释为什么不同方法会有不同的稳定性，比如舍入误差和表达式膨胀的影响。\n\u003e\n\u003e 用户可能没有完全理解这些复杂度是如何推导出来的，比如为什么自动微分的时间是线性的，或者符号微分的空间复杂度如何。需要分步骤解释，可能用具体的例子，比如一个有 n 个参数的函数，如何计算每种方法所需的步骤数，从而得出时间复杂度。\n\u003e\n\u003e 此外，用户可能对数值稳定性的评估方法不清楚。需要解释数值稳定性通常通过误差分析，比如舍入误差和截断误差的影响。例如，数值微分的误差来源包括选择 h 的大小，过大会导致截断误差，过小导致舍入误差。而符号微分没有数值误差，自动微分则因为使用浮点运算可能有舍入误差，但相对于数值微分更稳定。\n\u003e\n\u003e 需要注意用户的数学背景是本科高等数学和线性代数，所以需要用他们能理解的语言，避免过于复杂的数学推导，但又要足够严谨。可能需要使用具体的例子，比如一个简单的函数，比较三种方法在计算梯度时的步骤，从而说明时间复杂度的差异。\n\u003e\n\u003e 例如，考虑函数 f(w)=w1*x1 + w2*x2 + ... + wn\\*xn，有 n 个参数 w1 到 wn。数值微分需要对每个 wi 计算两次 f 的值，所以总计算次数是 2n 次，每次计算需要 O(n)时间（因为计算点积），所以总时间复杂度是 O(n^2)。自动微分则计算一次前向传播（O(n)时间），反向传播每个节点的梯度计算是 O(1)，n 个节点，所以总时间是 O(n)。符号微分则生成导数表达式，可能有 n 项，每个项是 xi，所以导数是 xi，存储这些需要 O(n)空间，但如果是更复杂的函数，比如多层复合函数，符号表达式可能膨胀，导致空间增加。\n\u003e\n\u003e 在数值稳定性方面，比如用数值微分计算 f(w)=sin(w)，当 w 很大时，计算导数时的小变化可能导致较大的舍入误差。而自动微分直接计算 cos(w)，没有这种误差。\n\u003e\n\u003e 总结，用户需要分步骤的复杂度推导过程和数值稳定性的评估方法，结合具体例子和数学解释，确保他们能理解为什么不同方法有不同的复杂度和稳定性。同时，可能需要指出这些复杂度是理论上的最坏情况还是典型情况，比如符号微分的表达式膨胀在某些情况下可能更严重。\n\n以下是关于数值微分、符号微分和自动微分的时间/空间复杂度计算原理，以及数值稳定性评估方法的详细解释：\n\n---\n\n### 一、时间复杂度计算原理\n\n#### 1. 数值微分（Numerical Differentiation）\n\n**实现方式**：通过有限差分近似导数\n$$ f'(x) \\approx \\frac{f(x+h)-f(x-h)}{2h} $$\n\n**时间复杂度分析**：\n\n- **单参数计算**：每次计算需要 **2 次前向传播**\n- **n 个参数**：需要 **2n 次前向传播**\n- **前向传播复杂度**：假设单次前向传播为 $$ O(k) $$（k 为计算步骤数）\n- **总时间复杂度**：$$ O(2n \\times k) = O(nk) $$\n\n**关键结论**：时间复杂度与参数数量成线性关系，但前向传播的 $$ k $$ 通常与网络规模相关，实际复杂度为 $$ O(n^2) $$\n\n\u003e 示例：计算 $$ f(w*1,w_2,...,w*{100}) $$ 的梯度，需要 200 次前向传播\n\n---\n\n#### 2. 符号微分（Symbolic Differentiation）\n\n**实现方式**：通过代数规则推导闭式表达式\n\n**时间复杂度分析**：\n\n- **表达式膨胀**：对复合函数 $$ f(g(h(x))) $$ 求导会产生嵌套乘积项\n- **最坏情况**：每层操作导致表达式长度指数级增长 $$ O(2^d) $$（d 为网络深度）\n- **优化情况**：现代系统会进行表达式简化，典型复杂度为 $$ O(d) $$\n\n\u003e 示例：对 $$ f(x) = \\sin(e^{x^2}) $$ 求导：\n\u003e $$ f'(x) = \\cos(e^{x^2}) \\cdot e^{x^2} \\cdot 2x $$\n\u003e 表达式长度随求导次数线性增长\n\n---\n\n#### 3. 自动微分（Automatic Differentiation）\n\n**实现方式**：基于计算图分解求导过程\n\n**时间复杂度分析**：\n\n- **前向传播**：$$ O(d) $$（d 为计算图深度）\n- **反向传播**：每个节点执行固定时间的梯度计算，复杂度 $$ O(d) $$\n- **总时间复杂度**：$$ O(d) + O(d) = O(d) $$\n\n**关键优化**：计算图节点数通常与参数数量 $$ n $$ 成线性关系，因此复杂度可表示为 $$ O(n) $$\n\n\u003e 示例：全连接网络的反向传播时间与参数数量成正比\n\n---\n\n### 二、空间复杂度计算原理\n\n#### 对比表格\n\n| 方法     | 空间复杂度 | 原因                                                       |\n| -------- | ---------- | ---------------------------------------------------------- |\n| 数值微分 | $$ O(1) $$ | 只需存储当前参数值和扰动结果                               |\n| 符号微分 | $$ O(n) $$ | 需要存储完整的符号表达式（可能指数膨胀，但优化后线性增长） |\n| 自动微分 | $$ O(n) $$ | 需要存储计算图中所有中间变量的前向值                       |\n\n**详细解释**：\n\n- **数值微分**：仅需保持原始参数和扰动后的参数副本，内存占用恒定\n- **符号微分**：导数的符号表达式可能非常庞大，例如：\n  $$ \\frac{\\partial}{\\partial x} \\prod*{i=1}^n x_i = \\sum*{j=1}^n \\prod\\_{i \\neq j} x_i $$\n  需要存储 $$ n $$ 个乘积项\n- **自动微分**：需要保存前向传播的所有中间结果用于反向计算，例如：\n  ```python\n  # 前向计算需要保存这些值\n  a = W1 * x\n  b = a + b1\n  c = relu(b)\n  ```\n\n---\n\n### 三、数值稳定性评估方法\n\n#### 1. 数值微分稳定性\n\n**误差来源**：\n\n- **截断误差**：$$ O(h^2) $$（来自泰勒展开的近似）\n- **舍入误差**：$$ O(\\epsilon/h) $$（$$ \\epsilon $$ 为机器精度）\n\n**稳定性分析**：\n$$ \\text{总误差} = O(h^2) + O(\\epsilon/h) $$\n\n- **最优步长选择**：当 $$ h \\approx \\sqrt[3]{\\epsilon} $$ 时误差最小\n- **典型问题**：对于病态条件数的问题（如指数函数），小步长会放大舍入误差\n\n\u003e 示例：计算 $$ f(x) = e^x $$ 在 $$ x=20 $$ 处的导数：\n\u003e\n\u003e - 真实导数：$$ e^{20} \\approx 4.85 \\times 10^8 $$\n\u003e - 数值计算可能产生显著相对误差\n\n---\n\n#### 2. 符号微分稳定性\n\n**特点**：\n\n- **精确计算**：理论上没有数值误差\n- **实际限制**：\n  - 符号化简可能导致数值不稳定表达式\n  - 转换为浮点运算时仍会引入舍入误差\n\n**评估方法**：\n\n- **表达式复杂度**：检查导数表达式是否包含病态操作（如大数相减）\n  $$ \\frac{\\partial}{\\partial x} (e^x - e^{-x}) = e^x + e^{-x} $$\n  直接计算可能在 $$ x $$ 较大时出现精度损失\n\n---\n\n#### 3. 自动微分稳定性\n\n**误差来源**：\n\n- **前向传播舍入误差**：与符号微分相同量级\n- **反向传播稳定性**：取决于梯度计算路径\n\n**稳定性优势**：\n\n- **避免误差累积**：通过保持原始计算路径的数值特性\n- **典型对比**：\n  - 直接计算 $$ f(x) = \\sqrt{x^2 + 1} - x $$ 的导数\n  - 符号微分可能得到不稳定的 $$ \\frac{x}{\\sqrt{x^2+1}} - 1 $$\n  - 自动微分在计算时保持原始表达式结构\n\n---\n\n### 四、综合对比与工程选择\n\n#### 1. 方法选择决策树\n\n```mermaid\ngraph TD\n    A[需要微分] --\u003e B{参数规模}\n    B --\u003e|\"小规模(n\u003c100)\"| C[符号微分]\n    B --\u003e|中大规模| D{是否需要最高精度}\n    D --\u003e|是| E[自动微分]\n    D --\u003e|否| F[数值微分]\n    C --\u003e G[获得精确表达式]\n    E --\u003e H[高效计算梯度]\n    F --\u003e I[快速但低精度]\n```\n\n#### 2. 实际框架实现\n\n- **PyTorch/TensorFlow**：采用自动微分（反向传播）\n- **Mathematica**：使用符号微分\n- **有限差分库**：常用于验证其他方法的正确性\n\n---\n\n### 五、深度学习中的特殊考量\n\n#### 1. GPU 内存瓶颈\n\n- **自动微分优化**：PyTorch 的 `checkpoint` 机制通过牺牲计算换内存\n  ```python\n  # 减少中间变量存储\n  from torch.utils.checkpoint import checkpoint\n  x = checkpoint(layer1, x)\n  x = checkpoint(layer2, x)\n  ```\n\n#### 2. 混合精度训练\n\n- **稳定性挑战**：float16 类型下的梯度计算需要特殊处理\n- **解决方案**：梯度缩放（Gradient Scaling）\n  ```python\n  scaler = torch.cuda.amp.GradScaler()\n  with torch.cuda.amp.autocast():\n      output = model(input)\n  scaler.scale(loss).backward()\n  ```\n\n---\n\n### 六、数学证明示例\n\n#### 数值微分误差分析\n\n设真实导数为 $$ f'(x) $$，数值近似为：\n$$ \\tilde{f}'(x) = \\frac{f(x+h) - f(x-h)}{2h} $$\n\n**泰勒展开**：\n$$ f(x+h) = f(x) + hf'(x) + \\frac{h^2}{2}f''(x) + \\frac{h^3}{6}f'''(ξ_1) $$\n$$ f(x-h) = f(x) - hf'(x) + \\frac{h^2}{2}f''(x) - \\frac{h^3}{6}f'''(ξ_2) $$\n\n**相减得**：\n$$ \\tilde{f}'(x) = f'(x) + \\frac{h^2}{12}[f'''(ξ_1) + f'''(ξ_2)] $$\n\n**误差项**：\n$$ \\text{截断误差} = O(h^2) $$\n\n---\n\n### 七、总结理解\n\n1. **复杂度计算本质**：\n\n   - 时间复杂度：计算代价随问题规模的增长率\n   - 空间复杂度：内存需求随问题规模的增长率\n\n2. **稳定性评估核心**：\n\n   - 对舍入误差和截断误差的敏感度\n   - 保持数值计算精度的能力\n\n3. **工程实践指导**：\n   - 小规模问题：优先符号微分（如物理仿真）\n   - 大规模可微编程：必选自动微分（深度学习框架）\n   - 快速验证：使用数值微分（原型开发阶段）\n\n\u003e [!NOTE] 亮曰：\n\u003e\n\u003e - 数值微分：参数做 Delta ，计算最终值的差，没有反向传播过程\n\u003e - 符号微分：直接推导出导数表达式，再代入计算，表达式复杂\n\u003e - 自动微分：前向传播计算每个节点的值，再反向传播用链式法则计算每个节点的梯度。\n\u003e\n\u003e 自动微分可以算是一种动态规划，暂存计算中重复用到的中间数据，用空间换时间。更进一步，反向传播时，用层序遍历计算图，当节点的所有入边（反向时的出边）都计算完后，即可将当前节点从队列中移除，从而节省内存。\n","title":"PyTorch 自动微分与反向传播机制原理解析","abstract":"\u003e 本文为用户与 DeepSeek 的问答。主题为 PyTorch 的反向传播机制。本文从数学原理、计算图机制和实际需求三个方面深入解释其工作原理，并结合 PyTorch 的自动微分（Autograd）系统进行说明。\n\u003e [!query]\n\u003e","length":952,"created_at":"2025-03-06T15:50:00.000Z","updated_at":"2025-03-06T15:50:00.000Z","tags":["PyTorch","深度学习","反向传播","自动微分","学习笔记"],"license":true}},{"pathMapping":{"filePath":"public/content/learn_from_ai/2024-11-29-deep-learning-model-formats.md","pagePath":"/learn_from_ai/deep-learning-model-formats","slug":"deep-learning-model-formats"},"meta":{"content":"\n\u003e 本页面介绍了三种机器学习模型文件格式：.pth、.safetensor 和 .onnx。主要内容包括每种格式的定义、保存的内容、用途以及它们之间的区别和转换方法。\n\n## pytorch 保存的 .pth 文件里都保存了些什么东西？\n\nPyTorch 中的`.pth`文件通常用于保存模型的权重（parameters）和训练过程中的优化器状态（optimizer state）。具体来说，一个`.pth`文件可能包含以下内容：\n\n1. **模型状态字典（Model state dictionary）**：\n   - 这是`.pth`文件中最主要的部分，它包含了模型的所有权重（即神经网络的参数），包括卷积层的滤波器、全连接层的权重和偏置等。\n   - 状态字典是一个简单的 Python 字典对象，其键是层的名字，值是相应的参数张量。\n2. **优化器状态字典（Optimizer state dictionary）**：\n   - 当保存模型时，通常也会保存优化器的状态，这样可以在模型训练中断后，从上次停止的地方继续训练。\n   - 优化器状态字典通常包含每个参数的梯度、动量（momentum）和其他与优化器相关的状态信息（例如 Adam 优化器的矩估计）。\n3. **其他可选信息**：\n   - 有时候，`.pth`文件可能还会包含其他辅助信息，比如训练的损失值、额外的元数据或者批处理大小等，但这些信息不是必须的。\n     以下是一个简单的例子，展示如何在 PyTorch 中保存和加载`.pth`文件：\n\n```python\n# 保存模型和优化器状态\ntorch.save({\n    'epoch': epoch,\n    'model_state_dict': model.state_dict(),\n    'optimizer_state_dict': optimizer.state_dict(),\n    'loss': loss,\n    ...\n}, 'model.pth')\n# 加载模型和优化器状态\ncheckpoint = torch.load('model.pth')\nmodel.load_state_dict(checkpoint['model_state_dict'])\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\nepoch = checkpoint['epoch']\nloss = checkpoint['loss']\n...\n```\n\n在这个例子中，`model`是你要保存的模型对象，`optimizer`是训练该模型使用的优化器。通过`torch.save`函数，你可以将模型的状态字典和优化器的状态字典保存到文件中。之后，可以使用`torch.load`函数来恢复这些状态，以便继续训练或者进行推理。\n\n## .safetensor 文件中又保存了什么东西？\n\n`.safetensor` 文件格式是由 Hugging Face 的 Safety Checker 工具引入的，它是为了在模型推理时提供一个额外的安全层。`.safetensor` 文件中保存的内容主要包括：\n\n1. **模型权重**：\n   - 这是最核心的部分，与 PyTorch 的 `.pth` 文件类似，`.safetensor` 文件也保存了模型的权重，即神经网络中的参数。\n2. **元数据**：\n   - `.safetensor` 文件包含了一些元数据，这些数据描述了模型的架构、权重形状、数据类型等信息，这样可以在加载模型时进行验证和适配。\n3. **安全性信息**：\n   - `.safetensor` 文件可能会包含与模型安全性相关的信息，例如哪些层或参数可能需要特别的安全检查，以及可能的阈值设置等。\n     具体来说，`.safetensor` 文件的内容结构可能如下：\n\n- `weights`: 包含模型权重的字典，通常是以张量的形式存储。\n- `metadata`: 包含模型的元数据，如版本号、架构信息等。\n- `config`: 包含模型配置信息，如模型类型、类名等。\n- `safety`: 包含模型安全性相关的信息。\n  使用 `.safetensor` 文件的目的之一是为了确保在模型部署时能够进行有效的安全检查，特别是在处理生成型模型（如文本生成、图像生成等）时，可以防止生成不适当的内容。\n  请注意，`.safetensor` 文件格式并不是 PyTorch 的标准保存格式，而是 Hugging Face 的特定实现。因此，它可能不如 `.pth` 文件那样被广泛使用。如果你在使用 Hugging Face 的模型和工具，可能会遇到 `.safetensor` 文件。在使用时，需要确保你的环境支持这种格式。\n\n## .onnx 文件中又保存了什么信息？\n\n`.onnx`（Open Neural Network Exchange）文件是一个开放格式，用于表示机器学习模型。它旨在提供一种标准的方式来表示深度学习模型，使得模型可以在不同的框架和工具之间进行转换和互操作。一个`.onnx`文件中通常包含以下信息：\n\n1. **模型图（Model Graph）**：\n   - 模型图定义了模型的计算流程，它由节点（nodes）和边（edges）组成。\n   - 节点代表计算操作，如卷积、矩阵乘法、激活函数等。\n   - 边代表节点之间的数据流，即张量（tensors）的流动。\n2. **初始值（Initializers）**：\n   - 初始值包含了模型的权重、偏置等参数的值。\n   - 这些参数是在模型图执行之前就已经确定的。\n3. **模型属性（Attributes）**：\n   - 每个节点可能有与之关联的属性，这些属性定义了节点的具体行为，例如卷积操作中的步长（stride）和填充（padding）。\n4. **输入和输出（Inputs and Outputs）**：\n   - 定义了模型的输入和输出张量的名称、数据类型和形状。\n   - 这有助于理解模型期望的输入格式以及它将产生的输出格式。\n5. **元数据（Metadata）**：\n   - 包括模型的名称、版本、作者、生产日期等信息。\n   - 这些信息有助于模型的追踪和管理。\n6. **优化信息（Optimization Information）**（可选）：\n   - 一些`.onnx`文件可能包含用于优化模型执行的额外信息，如融合操作或特定硬件上的优化指令。\n     `.onnx`文件的结构大致如下：\n\n- `ir_version`: ONNX 格式的版本号。\n- `opset_import`: 模型使用的操作集版本。\n- `producer_name`: 生成该 ONNX 模型的工具或库的名称。\n- `producer_version`: 生成该 ONNX 模型的工具或库的版本。\n- `graph`: 包含模型图的结构和属性。\n  - `node`: 计算节点列表。\n  - `input`: 输入列表。\n  - `output`: 输出列表。\n  - `initializer`: 初始化参数列表。\n  - `value_info`: 提供额外的张量信息。\n    使用`.onnx`文件，可以轻松地将模型从 PyTorch、TensorFlow、Caffe2 等框架转换到 ONNX 格式，然后再部署到不同的推理引擎或硬件平台上，例如使用 ONNX Runtime 进行推理。这种格式提高了模型的便携性和互操作性。\n\n## 简述 .pth ， .safetensor ， .onnx 保存的信息中，有哪些是相同的？有哪些有区别？\n\n.pth, .safetensor, 和 .onnx 文件格式都用于保存机器学习模型的相关信息，但它们的设计目的、兼容性和包含的具体内容有所不同。以下是它们之间相同点和区别的概述：\n**相同点：**\n\n1. **模型参数/权重**：\n   - 所有三种格式都保存了模型的参数或权重，这些是训练过程中学习到的数值，对于模型的预测能力至关重要。\n2. **元数据**：\n   - 它们都可能包含一些元数据，如模型的版本、创建日期或其他描述性信息，尽管具体的元数据内容和格式可能有所不同。\n     **区别：**\n3. **格式和兼容性**：\n   - `.pth` 是 PyTorch 的原生格式，专门用于保存和加载 PyTorch 模型的状态字典，包括模型权重和优化器状态。\n   - `.safetensor` 是 Hugging Face 的 Safety Checker 工具使用的格式，除了模型权重，还包含了安全性相关的信息。\n   - `.onnx` 是一个开放的、跨框架的格式，用于在不同的深度学习框架之间交换模型，不仅包含模型结构和参数，还定义了模型计算图。\n4. **包含内容**：\n   - `.pth` 文件通常包含模型的状态字典和优化器的状态字典，以及可选的其他训练信息（如损失值、迭代次数等）。\n   - `.safetensor` 文件包含模型权重、元数据以及与模型安全性相关的信息。\n   - `.onnx` 文件包含模型计算图、节点定义、边的连接、初始值（模型权重）、输入输出定义以及可选的优化信息。\n5. **使用场景**：\n   - `.pth` 文件主要用于 PyTorch 模型的训练和推理。\n   - `.safetensor` 文件用于在 Hugging Face 的生态系统中进行模型的安全检查。\n   - `.onnx` 文件用于模型在不同框架之间的转换和部署，特别是在需要跨平台或硬件优化的场景中。\n6. **开放性和互操作性**：\n   - `.onnx` 格式的设计重点在于开放性和互操作性，使其成为不同框架和工具之间模型交换的桥梁。\n   - `.pth` 和 `.safetensor` 更专注于特定框架或工具链内的使用。\n     总结来说，这三种格式都用于保存模型权重，但它们在格式兼容性、包含的额外信息和使用场景上存在明显差异。`.onnx` 格式更加开放和通用，而 `.pth` 和 `.safetensor` 更专注于特定的框架或应用需求。\n\n## 简述 .pth ， .safetensor ， .onnx 保存的信息中有哪些是相同的？保存的信息中又有哪些有区别？\n\n.pth、.safetensor 和.onnx 文件格式虽然都是为了保存机器学习模型的相关信息，但它们在保存的内容上存在相同点和差异。\n**相同点：**\n\n1. **模型参数/权重**：这三种文件格式都会保存模型的参数或权重，这些权重是模型在训练过程中学习到的，对模型的预测能力至关重要。\n2. **元数据**：它们都可能包含一些元数据，例如模型的版本、创建日期或其他描述性信息，尽管具体的元数据和格式可能因文件格式而异。\n   **区别：**\n3. **格式和兼容性**：\n   - .pth 文件是 PyTorch 的原生格式，主要用于保存和加载 PyTorch 模型的状态字典，包括模型权重和优化器状态。\n   - .safetensor 文件是 Hugging Face 的 Safety Checker 工具使用的格式，除了模型权重，还包括安全性相关的信息。\n   - .onnx 文件是一种开放的、跨框架的格式，用于在不同深度学习框架之间交换模型，包含模型结构和参数以及模型计算图。\n4. **包含内容**：\n   - .pth 文件通常包含模型的状态字典和优化器的状态字典，可能还包括其他训练信息，如损失值、迭代次数等。\n   - .safetensor 文件包含模型权重、元数据以及与模型安全性相关的信息。\n   - .onnx 文件包含模型计算图、节点定义、边的连接、初始值（模型权重）、输入输出定义以及可选的优化信息。\n5. **使用场景**：\n   - .pth 文件主要用于 PyTorch 模型的训练和推理。\n   - .safetensor 文件用于 Hugging Face 生态系统中的模型安全检查。\n   - .onnx 文件用于模型在不同框架之间的转换和部署，特别是在需要跨平台或硬件优化的场景中。\n6. **开放性和互操作性**：\n   - .onnx 格式重点在于开放性和互操作性，便于不同框架和工具之间模型交换。\n   - .pth 和.safetensor 文件更专注于特定框架或工具链内的使用。\n     总结来说，这三种文件格式都保存模型权重，但在格式兼容性、包含的额外信息和使用场景上存在明显差异。.onnx 格式更开放和通用，而.pth 和.safetensor 则更专注于特定框架或应用需求。\n\n## .pth ， .safetensor ， .onnx 三种格式，各自能否用于模型的 finetunning ？为什么？\n\n.pth、.safetensor 和 .onnx 三种格式在模型微调（finetuning）方面的适用性各有不同，以下是各自的适用性分析：\n**.pth 格式：**\n.pth 文件可以用于模型的微调。原因如下：\n\n- .pth 文件是 PyTorch 的原生格式，它保存了模型的状态字典，包括模型的权重和可选的优化器状态。\n- 在微调过程中，可以加载 .pth 文件中的模型权重，然后根据新的数据集对模型进行进一步的训练。\n- 如果 .pth 文件中包含了优化器状态，那么可以从中断点继续训练，这对于微调过程是有帮助的。\n  **.safetensor 格式：**\n  .safetensor 文件也可以用于模型的微调，但有一些限制：\n- .safetensor 文件主要是由 Hugging Face 的 Safety Checker 工具使用的，它保存了模型权重和与安全性相关的信息。\n- 虽然这个格式主要用于安全检查，但它仍然包含了模型权重，因此理论上可以用于微调。\n- 但是，由于 .safetensor 文件格式可能不如 .pth 那样被广泛支持，因此在微调时可能需要额外的步骤来转换格式或加载权重。\n  **.onnx 格式：**\n  .onnx 文件在微调方面的适用性较低，原因如下：\n- .onnx 文件是一个开放的、跨框架的格式，它不仅包含模型权重，还定义了模型计算图。\n- 虽然 .onnx 格式支持在不同的框架之间转换模型，但它不是为了微调而设计的。计算图是固定的，不易于修改。\n- 如果需要微调 .onnx 格式的模型，通常需要先将模型转换回原始框架（如 PyTorch 或 TensorFlow），然后再进行微调。\n- 因此，直接在 .onnx 格式上进行微调通常不切实际，除非有特定的工具或库支持这种操作。\n  总结来说，.pth 格式最适合用于 PyTorch 模型的微调，因为它直接与 PyTorch 的训练和推理流程兼容。.safetensor 格式也可以用于微调，但可能需要额外的步骤来处理。而 .onnx 格式通常不直接用于微调，需要转换为其他框架格式后才能进行微调。\n\n## .pth ， .safetensor ， .onnx 三种格式，各自能否用于训练 LoRA ？为什么？\n\nLoRA（Low-Rank Adaptation）是一种用于微调大型预训练模型的技术，它通过引入低秩分解来减少微调所需的参数数量，从而减少存储和计算需求。以下是关于 .pth、.safetensor 和 .onnx 格式在训练 LoRA 时的适用性分析：\n**.pth 格式：**\n.pth 文件可以用于训练 LoRA。原因如下：\n\n- .pth 文件是 PyTorch 的原生格式，可以直接保存和加载模型的权重，包括 LoRA 引入的低秩矩阵。\n- 在训练 LoRA 时，通常需要在原始预训练模型的基础上添加额外的参数（即低秩矩阵），这些参数可以在 PyTorch 中通过自定义层或修改现有层来实现。\n- 由于 .pth 文件与 PyTorch 框架紧密集成，因此可以轻松地保存和加载 LoRA 的参数，并进行训练。\n  **.safetensor 格式：**\n  .safetensor 文件也可以用于训练 LoRA，但可能有一些限制：\n- .safetensor 文件是为了提高模型使用的安全性而设计的，它保存了模型权重和其他与安全性相关的信息。\n- 如果 LoRA 的参数被包含在 .safetensor 文件中，那么理论上可以用于训练。\n- 然而，由于 .safetensor 文件格式可能不如 .pth 那样被广泛支持，因此在训练 LoRA 时可能需要额外的步骤来处理文件格式。\n  **.onnx 格式：**\n  .onnx 文件在训练 LoRA 方面通常不适用。原因如下：\n- .onnx 文件定义了模型的计算图和权重，但它是一个静态的模型描述格式，不适合动态修改模型结构，如添加 LoRA 层。\n- LoRA 需要在预训练模型的特定层中插入低秩矩阵，这通常需要对模型结构进行修改，而 .onnx 格式不支持这种修改。\n- 如果需要使用 .onnx 文件中的模型来训练 LoRA，通常需要先将模型转换回 PyTorch 或其他支持动态图修改的框架，然后再进行训练。\n  总结来说，.pth 格式最适合用于训练 LoRA，因为它与 PyTorch 框架紧密集成，支持动态图和自定义层的添加。.safetensor 格式在理论上也是可行的，但可能需要额外的处理步骤。而 .onnx 格式由于不支持动态修改模型结构，因此不适合直接用于训练 LoRA。\n\n## pth ， safetensor ， onnx ，三种格式如何两两转换？\n\n.pth、.safetensor 和 .onnx 文件格式之间的转换通常需要通过特定的工具和库来实现。以下是如何在这三种格式之间进行两两转换的概述：\n\n### .pth 到 .safetensor 的转换\n\n目前，并没有直接的标准工具来将 .pth 文件转换为 .safetensor 文件。但是，可以手动加载 .pth 文件中的权重，并将其保存为 .safetensor 格式。以下是一个示例步骤：\n\n1. 使用 PyTorch 加载 .pth 文件。\n2. 提取模型权重。\n3. 使用 Hugging Face 的 `transformers` 库或其他相关工具将权重保存为 .safetensor 文件。\n\n### .safetensor 到 .pth 的转换\n\n同样地，将 .safetensor 文件转换为 .pth 文件也没有直接的转换工具。以下是手动转换的步骤：\n\n1. 使用 Hugging Face 的 `transformers` 库或其他相关工具加载 .safetensor 文件。\n2. 提取模型权重。\n3. 使用 PyTorch 将权重保存为 .pth 文件。\n\n### .pth 到 .onnx 的转换\n\nPyTorch 提供了直接将模型转换为 .onnx 格式的工具：\n\n```python\nimport torch\nimport torch.onnx\n# 假设 model 是一个 PyTorch 模型\nmodel = ...  # 加载或定义模型\n# 假设输入是一个张量，其形状与模型输入兼容\ninput_sample = torch.randn(batch_size, channels, height, width)\n# 将模型转换为 ONNX 格式\ntorch.onnx.export(model,               # 模型\n                  input_sample,        # 模型输入（或一个包含输入的元组）\n                  \"model.onnx\",       # 输出文件名\n                  export_params=True,  # 是否导出参数\n                  opset_version=10,    # ONNX 算子集版本\n                  do_constant_folding=True,  # 是否执行常量折叠优化\n                  input_names=['input'],   # 输入名\n                  output_names=['output'], # 输出名\n                  dynamic_axes={'input': {0: 'batch_size'},  # 动态轴\n                                'output': {0: 'batch_size'}})\n```\n\n### .onnx 到 .pth 的转换\n\n将 .onnx 文件转换为 .pth 文件通常不直接进行，因为 .onnx 文件包含了模型的结构信息，而 .pth 文件只包含权重。如果需要，可以重新创建 PyTorch 模型结构，然后加载 .onnx 文件中的权重：\n\n1. 定义与 .onnx 文件对应的 PyTorch 模型结构。\n2. 使用 `onnx.load` 加载 .onnx 文件。\n3. 提取权重并将其加载到 PyTorch 模型中。\n\n### .safetensor 到 .onnx 的转换\n\n目前没有直接的方法将 .safetensor 文件转换为 .onnx 文件。如果需要，可以先将 .safetensor 文件转换为 .pth 文件，然后再按照上述方法将 .pth 文件转换为 .onnx 文件。\n\n### .onnx 到 .safetensor 的转换\n\n同样地，将 .onnx 文件转换为 .safetensor 文件也没有直接的转换工具。如果需要，可以先将 .onnx 文件转换为 .pth 文件，然后再将 .pth 文件转换为 .safetensor 文件。\n在进行这些转换时，需要注意的是，转换过程中可能会丢失一些特定的信息，如优化器状态或模型配置，因此在转换后可能需要额外的步骤来确保模型的完整性和正确性。\n\n## 我有一个从网络上下载的 .pth 文件 `001.pth` 。给我 Python 代码，将其转换为 onnx 格式。\n\n要将一个 `.pth` 文件转换为 `.onnx` 格式，你需要首先加载 `.pth` 文件中的模型，然后使用 PyTorch 的 `torch.onnx.export` 函数来进行转换。以下是一个 Python 代码示例，展示了如何进行这一转换过程。假设你已经有了对应的 PyTorch 模型定义，并且 `.pth` 文件中包含的是该模型的权重。\n请注意，以下代码假设你的模型是一个标准的 PyTorch 模型，并且你知道模型的输入尺 ��。你需要根据你的模型实际情况来调整输入尺寸和模型结构。\n\n```python\nimport torch\nimport torch.onnx\n# 假设模型结构和输入尺寸已知\n# 这里是示例模型结构和输入尺寸，你需要根据你的模型进行修改\nclass MyModel(torch.nn.Module):\n    def __init__(self):\n        super(MyModel, self).__init__()\n        # 定义模型结构\n        self.conv1 = torch.nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n        self.relu = torch.nn.ReLU()\n        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        # ... 添加更多层 ...\n    def forward(self, x):\n        # 定义前向传播\n        x = self.conv1(x)\n        x = self.relu(x)\n        x = self.pool(x)\n        # ... 应用更多层 ...\n        return x\n# 创建模型实例\nmodel = MyModel()\n# 加载.pth文件中的权重\nmodel.load_state_dict(torch.load('001.pth'))\n# 设置模型为评估模式（如果适用）\nmodel.eval()\n# 创建一个符合模型输入尺寸的示例输入\n# 假设输入是单张图片，通道数为3，高和宽分别为224和224\n# 你需要根据你的模型调整输入尺寸\ninput_sample = torch.randn(1, 3, 224, 224)\n# 指定ONNX模型的输出文件名\noutput_file = 'model.onnx'\n# 导出模型为ONNX格式\ntorch.onnx.export(model,               # 模型\n                  input_sample,        # 模型输入（或一个包含输入的元组）\n                  output_file,         # 输出文件名\n                  export_params=True,  # 是否导出参数\n                  opset_version=10,    # ONNX 算子集版本\n                  do_constant_folding=True,  # 是否执行常量折叠优化\n                  input_names=['input'],   # 输入名\n                  output_names=['output'], # 输出名\n                  dynamic_axes={'input': {0: 'batch_size'},  # 动态轴\n                                'output': {0: 'batch_size'}})\n```\n\n在运行这段代码之前，请确保：\n\n- 你的环境中已经安装了 PyTorch 和 onnx。\n- 你已经根据你的模型结构正确地定义了 `MyModel` 类。\n- 你已经根据你的模型输入尺寸正确地设置了 `input_sample`。\n  运行上述代码后，你应该会在当前目录下得到一个名为 `model.onnx` 的文件，这就是转换后的 ONNX 格式的模型。\n\n## 我没有对应的 PyTorch 模型定义。我要如何获得？\n\n如果你没有模型的 PyTorch 定义，但你有一个 `.pth` 文件，你可以尝试以下几种方法来获取或重建模型的结构：\n\n### 1. 使用 PyTorch 的 `torch.jit.load`\n\n如果你的 `.pth` 文件是一个 JIT traced 的模型，你可以使用 `torch.jit.load` 来加载它，这样就不需要原始的模型定义。\n\n```python\nimport torch\n# 加载JIT traced模型\ntraced_model = torch.jit.load('001.pth')\n# 使用模型（例如进行推理）\n# input_sample = ...  # 创建一个符合模型输入尺寸的示例输入\n# output = traced_model(input_sample)\n```\n\n### 2. 查找模型的文档或代码\n\n如果模型是从某个知名的代码库或论文中获得的，你可以尝试查找原始的模型定义代码。通常，论文的附录或代码库的 README 文件会包含模型的定义。\n\n### 3. 使用第三方库\n\n有些第三方库可能提供了预定义的模型结构，你可以尝试使用这些库来加载模型。\n例如，如果你有一个在 torchvision 中定义的模型，你可以这样做：\n\n```python\nimport torch\nimport torchvision.models as models\n# 假设你知道模型是 torchvision 中的某个模型\nmodel = models.resnet50(pretrained=False)\n# 加载权重\nmodel.load_state_dict(torch.load('001.pth'))\n```\n\n### 4. 反序列化状态字典\n\n如果你只是丢失了模型定义，但你有状态字典，你可以尝试反序列化状态字典来重建模型结构。\n\n```python\nimport torch\n# 加载状态字典\nstate_dict = torch.load('001.pth')\n# 假设你知道模型结构，可以创建一个空的模型实例，然后加载状态字典\n# model = ...  # 创建模型实例\n# model.load_state_dict(state_dict)\n```\n\n### 5. 使用模型架构搜索工具\n\n有一些工具和库可以帮助你根据权重文件推断出模型结构。例如，`netron` 是一个可视化神经网络工具，可以显示 `.pth` 文件中的模型结构。\n\n```bash\n# 安装 netron\npip install netron\n# 使用 netron 可视化模型\nnetron start 001.pth\n```\n\n通过这些方法，你应该能够找到或重建模型的结构。一旦你有了模型定义，你可以使用前面提供的代码示例来将 `.pth` 文件转换为 `.onnx` 格式。如果你无法确定模型结构，你可能需要联系模型的原始作者或查找相关的文档来获取模型定义。\n","title":"深度学习模型文件格式对比：pth、safetensor 与 onnx","abstract":"\u003e 本页面介绍了三种机器学习模型文件格式：.pth、.safetensor 和 .onnx。主要内容包括每种格式的定义、保存的内容、用途以及它们之间的区别和转换方法。\nPyTorch 中的`.pth`文件通常用于保存模型的权重（parameters）和训练过程中的优化器状态（optimizer state）。具体来说，一个`.pth`文件可能包含以下内容：\n1. **模型状态字典（Model state dictionary）**：","length":365,"created_at":"2024-11-29T02:00:00.000Z","updated_at":"2024-11-29T02:00:00.000Z","tags":["PyTorch","ONNX","深度学习","模型部署","学习笔记"],"license":true}}]},"__N_SSG":true},"page":"/tags/[tag]","query":{"tag":"pytorch"},"buildId":"ep7Z6bMN5q5X1Nkao2dSu","assetPrefix":"/blog-next","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>