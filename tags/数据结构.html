<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="description" content="The blog owned by Ryo, about Programing, Painting, and Gaming."/><meta property="og:description" content="The blog owned by Ryo, about Programing, Painting, and Gaming."/><meta name="twitter:description" content="The blog owned by Ryo, about Programing, Painting, and Gaming."/><meta property="og:image" content="https://ryojerryyu.github.io/blog-next/img/home-bg-kasumi-hanabi.jpg"/><meta name="twitter:image" content="https://ryojerryyu.github.io/blog-next/img/home-bg-kasumi-hanabi.jpg"/><meta property="og:type" content="website"/><meta property="og:url" content="https://blog.ryo-okami.xyz/tags/数据结构"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:site" content="@ryo_okami"/><meta name="twitter:creator" content="@ryo_okami"/><link rel="icon" href="/blog-next/favicon.ico"/><meta name="viewport" content="width=device-width, initial-scale=1"/><meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests"/><title>数据结构 | Ryo&#x27;s Blog</title><meta property="og:title" content="数据结构"/><meta property="og:site_name" content="Ryo&#x27;s Blog"/><meta name="twitter:title" content="数据结构 | Ryo&#x27;s Blog"/><meta name="next-head-count" content="18"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><link rel="apple-touch-icon" href="/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="192x192" href="/android-chrome-192x192.png"/><link rel="manifest" href="/site.webmanifest"/><meta name="msapplication-TileColor" content="#da532c"/><meta name="theme-color" content="#ffffff"/><link data-next-font="" rel="preconnect" href="/" crossorigin="anonymous"/><link rel="preload" href="/blog-next/_next/static/css/414e1c2e24ae75c1.css" as="style"/><link rel="stylesheet" href="/blog-next/_next/static/css/414e1c2e24ae75c1.css" data-n-g=""/><link rel="preload" href="/blog-next/_next/static/css/6d9fdb47bc37c45a.css" as="style"/><link rel="stylesheet" href="/blog-next/_next/static/css/6d9fdb47bc37c45a.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/blog-next/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/blog-next/_next/static/chunks/webpack-a07052f5f1ddae8f.js" defer=""></script><script src="/blog-next/_next/static/chunks/framework-710e909fd98bd7a1.js" defer=""></script><script src="/blog-next/_next/static/chunks/main-3348426789f06737.js" defer=""></script><script src="/blog-next/_next/static/chunks/pages/_app-d8865336158dbd05.js" defer=""></script><script src="/blog-next/_next/static/chunks/9926-ae962ea167351d2f.js" defer=""></script><script src="/blog-next/_next/static/chunks/pages/tags/%5Btag%5D-b7ba2b60f0f7e79a.js" defer=""></script><script src="/blog-next/_next/static/qJidplpj0hfkJECkA8o2X/_buildManifest.js" defer=""></script><script src="/blog-next/_next/static/qJidplpj0hfkJECkA8o2X/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="DefaultLayout_header__XE11y"><div class="DefaultLayout_icon__nrf7l"><div class="DefaultLayout_textbox__7Wb4y"><a class="DefaultLayout_textlink__6A_gH" href="/blog-next">Ryo&#x27;s Blog</a></div></div><div class="DefaultLayout_navBar___k_JM"><div class="DefaultLayout_navBarItem__YPtK6"><a class="DefaultLayout_textlink__6A_gH" href="/blog-next/articles">Articles</a></div><div class="DefaultLayout_navBarItem__YPtK6"><a class="DefaultLayout_textlink__6A_gH" href="/blog-next/ideas">Ideas</a></div><div class="DefaultLayout_navBarItem__YPtK6"><a class="DefaultLayout_textlink__6A_gH" href="/blog-next/tags">Tags</a></div><div class="DefaultLayout_navBarItem__YPtK6"><a class="DefaultLayout_textlink__6A_gH" href="/blog-next/clips">Clips</a></div></div><div class="DefaultLayout_headerRight__DHBsQ"><div class=" flex flex-row gap-8 items-center justify-center"><a title="Twitter" href="https://twitter.com/ryo_okami"><svg class=" h-6 w-6 fill-gray-300 hover:fill-white transition-all ease-in-out" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a><a title="GitHub" href="https://github.com/RyoJerryYu"><svg class=" h-6 w-6 fill-gray-300 hover:fill-white transition-all ease-in-out" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a><a title="Pixiv" href="https://www.pixiv.net/users/9159893"><svg class=" h-6 w-6 fill-gray-300 hover:fill-white transition-all ease-in-out" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4.935 0A4.924 4.924 0 0 0 0 4.935v14.13A4.924 4.924 0 0 0 4.935 24h14.13A4.924 4.924 0 0 0 24 19.065V4.935A4.924 4.924 0 0 0 19.065 0zm7.81 4.547c2.181 0 4.058.676 5.399 1.847a6.118 6.118 0 0 1 2.116 4.66c.005 1.854-.88 3.476-2.257 4.563-1.375 1.092-3.225 1.697-5.258 1.697-2.314 0-4.46-.842-4.46-.842v2.718c.397.116 1.048.365.635.779H5.79c-.41-.41.19-.65.644-.779V7.666c-1.053.81-1.593 1.51-1.868 2.031.32 1.02-.284.969-.284.969l-1.09-1.73s3.868-4.39 9.553-4.39zm-.19.971c-1.423-.003-3.184.473-4.27 1.244v8.646c.988.487 2.484.832 4.26.832h.01c1.596 0 2.98-.593 3.93-1.533.952-.948 1.486-2.183 1.492-3.683-.005-1.54-.504-2.864-1.42-3.86-.918-.992-2.274-1.645-4.002-1.646Z"></path></svg></a></div></div></header><div class="DefaultLayout_headerBg__ADsuB"></div><div class="max-w-3xl mx-auto p-2"><div class="DefaultLayout_contentHeight__WU8Ci"><div class="max-w-3xl mx-auto p-2"><div class="p-2"><div class="TagsBox_tagsBox__Z0lIP"><a href="/blog-next/tags/%E6%9D%82%E6%8A%80"><div class="TagsBox_tag__PAgNP">杂技</div></a><a href="/blog-next/tags/blog"><div class="TagsBox_tag__PAgNP">Blog</div></a><a href="/blog-next/tags/%E6%9D%82%E8%B0%88"><div class="TagsBox_tag__PAgNP">杂谈</div></a><a href="/blog-next/tags/c++"><div class="TagsBox_tag__PAgNP">C++</div></a><a href="/blog-next/tags/python"><div class="TagsBox_tag__PAgNP">Python</div></a><a href="/blog-next/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><div class="TagsBox_highlightedTag__q1tKH">数据结构</div></a><a href="/blog-next/tags/%E7%AE%97%E6%B3%95"><div class="TagsBox_tag__PAgNP">算法</div></a><a href="/blog-next/tags/%E6%8E%92%E5%BA%8F"><div class="TagsBox_tag__PAgNP">排序</div></a><a href="/blog-next/tags/%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B"><div class="TagsBox_tag__PAgNP">算法竞赛</div></a><a href="/blog-next/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F"><div class="TagsBox_tag__PAgNP">设计模式</div></a><a href="/blog-next/tags/%E7%AC%94%E8%AE%B0"><div class="TagsBox_tag__PAgNP">笔记</div></a><a href="/blog-next/tags/github"><div class="TagsBox_tag__PAgNP">GitHub</div></a><a href="/blog-next/tags/aws"><div class="TagsBox_tag__PAgNP">AWS</div></a><a href="/blog-next/tags/ci-cd"><div class="TagsBox_tag__PAgNP">CI/CD</div></a><a href="/blog-next/tags/iac"><div class="TagsBox_tag__PAgNP">IaC</div></a><a href="/blog-next/tags/devops"><div class="TagsBox_tag__PAgNP">DevOps</div></a><a href="/blog-next/tags/vscode"><div class="TagsBox_tag__PAgNP">VSCode</div></a><a href="/blog-next/tags/hexo"><div class="TagsBox_tag__PAgNP">Hexo</div></a><a href="/blog-next/tags/javascript"><div class="TagsBox_tag__PAgNP">JavaScript</div></a><a href="/blog-next/tags/kubernetes"><div class="TagsBox_tag__PAgNP">Kubernetes</div></a><a href="/blog-next/tags/docker"><div class="TagsBox_tag__PAgNP">Docker</div></a><a href="/blog-next/tags/cloud-native"><div class="TagsBox_tag__PAgNP">Cloud Native</div></a><a href="/blog-next/tags/nextjs"><div class="TagsBox_tag__PAgNP">Nextjs</div></a><a href="/blog-next/tags/cloud-computing"><div class="TagsBox_tag__PAgNP">Cloud Computing</div></a></div></div><div class="PostList_postList__7u2vW"><div class="PostList_postListElement__bxSVR"><a href="/blog-next/articles/Handy-heap-cheat-sheet"><h6 class="PostList_postTitle__uczSA">如何手撕一个堆</h6><div class="PostList_postDate__ns1KP"><time dateTime="2021-08-28T23:09:14.000Z">2021-08-28</time></div><div class="PostList_postAbstract__wW66U"><p class="py-1">在参加如AtCoder等算法竞技，或是刷Leetcode等算法题时，我们总是不可避免地遇到堆这种数据结构。</p><p class="py-1">当然，一般来说我们只要理解堆，知道堆的性质，知道怎么样用堆就足够了。在做题时只需要调用系统类库即可——在参加AtCoder时你甚至不会有时间去自己实现一个堆。</p><p class="py-1">但是，如果哪一天你把编程语言的类库全忘光了，又遇到一题需要频繁求最值的题目——你明知这里要用堆，却又忘记该调用的类名了，咋办？我还真遇到过这问题：三年没刷算法，只能对着一道自己明显会的题干着急，愣是想不起PriorityQueue的名字。这时候，只能自己实现一个堆出来了。</p></div></a><div class="TagsBox_tagsBox__Z0lIP py-4 md:py-1"><a href="/blog-next/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><div class="TagsBox_tag__PAgNP">数据结构</div></a><a href="/blog-next/tags/%E7%AE%97%E6%B3%95"><div class="TagsBox_tag__PAgNP">算法</div></a><a href="/blog-next/tags/%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B"><div class="TagsBox_tag__PAgNP">算法竞赛</div></a></div></div><div class="PostList_postListElement__bxSVR"><a href="/blog-next/articles/Sort-algorithm"><h6 class="PostList_postTitle__uczSA">排序算法</h6><div class="PostList_postDate__ns1KP"><time dateTime="2021-01-11T22:57:10.000Z">2021-01-11</time></div><div class="PostList_postAbstract__wW66U"><p class="py-1">我们知道排序是算法入门基本功，排序算法有多重要想必也不需要我在这里说明了。因此这一篇就按着我的理解，聊一聊排序算法。</p><p class="py-1">当然我不打算随便弄个什么十大排序算法或是经典排序总结之类响当当的名头，各个算法走马看花一样拉出来遛一遍，最后变得跟网上搜索到的其他讲排序的文章一样换汤不换药。你会发现这篇文章的结构跟在网上搜索到的任何讲排序的文章都有所不同：</p><p class="py-1">在这篇文章里，你会发现你找不到冒泡排序——因为我认为冒泡排序只不过是一种低效率的选择排序。</p></div></a><div class="TagsBox_tagsBox__Z0lIP py-4 md:py-1"><a href="/blog-next/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><div class="TagsBox_tag__PAgNP">数据结构</div></a><a href="/blog-next/tags/%E7%AE%97%E6%B3%95"><div class="TagsBox_tag__PAgNP">算法</div></a><a href="/blog-next/tags/%E6%8E%92%E5%BA%8F"><div class="TagsBox_tag__PAgNP">排序</div></a></div></div><div class="PostList_postListElement__bxSVR"><a href="/blog-next/articles/python-dict"><h6 class="PostList_postTitle__uczSA">Python字典的实现原理</h6><div class="PostList_postDate__ns1KP"><time dateTime="2020-08-02T00:10:10.000Z">2020-08-02</time></div><div class="PostList_postAbstract__wW66U"><p class="py-1">&gt; CPython从3.6开始，字典（dict）不再是无序的了——字典的修改了原先的底层实现，变得能按字典插入的顺序进行遍历。而Python从3.7开始将字典的有序性写入语言特性，不管是Jython、IronPython还是其他Python实现，从3.7开始大家的字典都是有序的了。</p><p class="py-1">以前参加Python相关的面试时，面试官经常都会问一个问题：Python里的字典（dict）是有序的吗？</p><p class="py-1">这自然难不倒我，我也照本宣科地讲：Python的字典底层是用哈希表实现的，在不发生冲突时读写的时间复杂度是O（1），比读写时间复杂度为O（logn）的红黑树要更快。但红黑树可以按下标的大小顺序进行遍历，而Dict遍历时是无序的。</p></div></a><div class="TagsBox_tagsBox__Z0lIP py-4 md:py-1"><a href="/blog-next/tags/python"><div class="TagsBox_tag__PAgNP">Python</div></a><a href="/blog-next/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><div class="TagsBox_tag__PAgNP">数据结构</div></a></div></div></div></div></div></div><footer class="DefaultLayout_footer__otgnc"><div class="max-w-3xl mx-auto p-2 w-full"><div class="flex flex-row justify-center items-center"><div class="DefaultLayout_footerLeft__pCizs">© 2023 Ryo Jerry Yu. All rights reserved.</div><div class="DefaultLayout_footerRight__VOEtk"><div class=" flex flex-row gap-8 items-center justify-center"><a title="Twitter" href="https://twitter.com/ryo_okami"><svg class="DefaultLayout_footerIcon__HMPAz h-8 w-8" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a><a title="GitHub" href="https://github.com/RyoJerryYu"><svg class="DefaultLayout_footerIcon__HMPAz h-8 w-8" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a><a title="Pixiv" href="https://www.pixiv.net/users/9159893"><svg class="DefaultLayout_footerIcon__HMPAz h-8 w-8" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4.935 0A4.924 4.924 0 0 0 0 4.935v14.13A4.924 4.924 0 0 0 4.935 24h14.13A4.924 4.924 0 0 0 24 19.065V4.935A4.924 4.924 0 0 0 19.065 0zm7.81 4.547c2.181 0 4.058.676 5.399 1.847a6.118 6.118 0 0 1 2.116 4.66c.005 1.854-.88 3.476-2.257 4.563-1.375 1.092-3.225 1.697-5.258 1.697-2.314 0-4.46-.842-4.46-.842v2.718c.397.116 1.048.365.635.779H5.79c-.41-.41.19-.65.644-.779V7.666c-1.053.81-1.593 1.51-1.868 2.031.32 1.02-.284.969-.284.969l-1.09-1.73s3.868-4.39 9.553-4.39zm-.19.971c-1.423-.003-3.184.473-4.27 1.244v8.646c.988.487 2.484.832 4.26.832h.01c1.596 0 2.98-.593 3.93-1.533.952-.948 1.486-2.183 1.492-3.683-.005-1.54-.504-2.864-1.42-3.86-.918-.992-2.274-1.645-4.002-1.646Z"></path></svg></a></div></div></div></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"allTagInfos":[{"tag":"杂技","slug":"杂技","path":"/tags/杂技","postSlugs":[{"postType":"article","postSlug":"Building-this-blog","postPagePath":"/articles/Building-this-blog"},{"postType":"article","postSlug":"hello-world","postPagePath":"/articles/hello-world"},{"postType":"article","postSlug":"the-using-in-cpp","postPagePath":"/articles/the-using-in-cpp"}]},{"tag":"Blog","slug":"blog","path":"/tags/blog","postSlugs":[{"postType":"article","postSlug":"Building-this-blog","postPagePath":"/articles/Building-this-blog"},{"postType":"article","postSlug":"init-a-new-hexo-project","postPagePath":"/articles/init-a-new-hexo-project"},{"postType":"article","postSlug":"create-blog-cicd-by-github","postPagePath":"/articles/create-blog-cicd-by-github"},{"postType":"article","postSlug":"use-paste-image-and-vscode-memo","postPagePath":"/articles/use-paste-image-and-vscode-memo"},{"postType":"idea","postSlug":"blog-in-next","postPagePath":"/ideas/blog-in-next"},{"postType":"idea","postSlug":"blog-syntax","postPagePath":"/ideas/blog-syntax"}]},{"tag":"杂谈","slug":"杂谈","path":"/tags/杂谈","postSlugs":[{"postType":"article","postSlug":"hello-world","postPagePath":"/articles/hello-world"}]},{"tag":"C++","slug":"c++","path":"/tags/c++","postSlugs":[{"postType":"article","postSlug":"the-using-in-cpp","postPagePath":"/articles/the-using-in-cpp"}]},{"tag":"Python","slug":"python","path":"/tags/python","postSlugs":[{"postType":"article","postSlug":"python-dict","postPagePath":"/articles/python-dict"}]},{"tag":"数据结构","slug":"数据结构","path":"/tags/数据结构","postSlugs":[{"postType":"article","postSlug":"python-dict","postPagePath":"/articles/python-dict"},{"postType":"article","postSlug":"Sort-algorithm","postPagePath":"/articles/Sort-algorithm"},{"postType":"article","postSlug":"Handy-heap-cheat-sheet","postPagePath":"/articles/Handy-heap-cheat-sheet"}]},{"tag":"算法","slug":"算法","path":"/tags/算法","postSlugs":[{"postType":"article","postSlug":"Sort-algorithm","postPagePath":"/articles/Sort-algorithm"},{"postType":"article","postSlug":"Handy-heap-cheat-sheet","postPagePath":"/articles/Handy-heap-cheat-sheet"}]},{"tag":"排序","slug":"排序","path":"/tags/排序","postSlugs":[{"postType":"article","postSlug":"Sort-algorithm","postPagePath":"/articles/Sort-algorithm"}]},{"tag":"算法竞赛","slug":"算法竞赛","path":"/tags/算法竞赛","postSlugs":[{"postType":"article","postSlug":"Handy-heap-cheat-sheet","postPagePath":"/articles/Handy-heap-cheat-sheet"}]},{"tag":"设计模式","slug":"设计模式","path":"/tags/设计模式","postSlugs":[{"postType":"article","postSlug":"The-beauty-of-design-parten","postPagePath":"/articles/The-beauty-of-design-parten"}]},{"tag":"笔记","slug":"笔记","path":"/tags/笔记","postSlugs":[{"postType":"article","postSlug":"The-beauty-of-design-parten","postPagePath":"/articles/The-beauty-of-design-parten"}]},{"tag":"GitHub","slug":"github","path":"/tags/github","postSlugs":[{"postType":"article","postSlug":"create-blog-cicd-by-github","postPagePath":"/articles/create-blog-cicd-by-github"}]},{"tag":"AWS","slug":"aws","path":"/tags/aws","postSlugs":[{"postType":"article","postSlug":"create-blog-cicd-by-github","postPagePath":"/articles/create-blog-cicd-by-github"}]},{"tag":"CI/CD","slug":"ci-cd","path":"/tags/ci-cd","postSlugs":[{"postType":"article","postSlug":"create-blog-cicd-by-github","postPagePath":"/articles/create-blog-cicd-by-github"}]},{"tag":"IaC","slug":"iac","path":"/tags/iac","postSlugs":[{"postType":"article","postSlug":"create-blog-cicd-by-github","postPagePath":"/articles/create-blog-cicd-by-github"}]},{"tag":"DevOps","slug":"devops","path":"/tags/devops","postSlugs":[{"postType":"article","postSlug":"create-blog-cicd-by-github","postPagePath":"/articles/create-blog-cicd-by-github"},{"postType":"article","postSlug":"introduction-for-k8s","postPagePath":"/articles/introduction-for-k8s"},{"postType":"article","postSlug":"introduction-for-k8s-2","postPagePath":"/articles/introduction-for-k8s-2"},{"postType":"idea","postSlug":"newest","postPagePath":"/ideas/newest"}]},{"tag":"VSCode","slug":"vscode","path":"/tags/vscode","postSlugs":[{"postType":"article","postSlug":"use-paste-image-and-vscode-memo","postPagePath":"/articles/use-paste-image-and-vscode-memo"}]},{"tag":"Hexo","slug":"hexo","path":"/tags/hexo","postSlugs":[{"postType":"article","postSlug":"use-paste-image-and-vscode-memo","postPagePath":"/articles/use-paste-image-and-vscode-memo"}]},{"tag":"JavaScript","slug":"javascript","path":"/tags/javascript","postSlugs":[{"postType":"article","postSlug":"use-paste-image-and-vscode-memo","postPagePath":"/articles/use-paste-image-and-vscode-memo"}]},{"tag":"Kubernetes","slug":"kubernetes","path":"/tags/kubernetes","postSlugs":[{"postType":"article","postSlug":"introduction-for-k8s","postPagePath":"/articles/introduction-for-k8s"},{"postType":"article","postSlug":"introduction-for-k8s-2","postPagePath":"/articles/introduction-for-k8s-2"},{"postType":"idea","postSlug":"newest","postPagePath":"/ideas/newest"}]},{"tag":"Docker","slug":"docker","path":"/tags/docker","postSlugs":[{"postType":"article","postSlug":"introduction-for-k8s","postPagePath":"/articles/introduction-for-k8s"},{"postType":"article","postSlug":"introduction-for-k8s-2","postPagePath":"/articles/introduction-for-k8s-2"},{"postType":"idea","postSlug":"newest","postPagePath":"/ideas/newest"}]},{"tag":"Cloud Native","slug":"cloud-native","path":"/tags/cloud-native","postSlugs":[{"postType":"article","postSlug":"introduction-for-k8s","postPagePath":"/articles/introduction-for-k8s"},{"postType":"article","postSlug":"introduction-for-k8s-2","postPagePath":"/articles/introduction-for-k8s-2"},{"postType":"idea","postSlug":"newest","postPagePath":"/ideas/newest"}]},{"tag":"Nextjs","slug":"nextjs","path":"/tags/nextjs","postSlugs":[{"postType":"idea","postSlug":"blog-in-next","postPagePath":"/ideas/blog-in-next"},{"postType":"idea","postSlug":"blog-syntax","postPagePath":"/ideas/blog-syntax"}]},{"tag":"Cloud Computing","slug":"cloud-computing","path":"/tags/cloud-computing","postSlugs":[{"postType":"idea","postSlug":"newest","postPagePath":"/ideas/newest"}]}],"selectedTagInfo":{"tag":"数据结构","slug":"数据结构","path":"/tags/数据结构","postSlugs":[{"postType":"article","postSlug":"python-dict","postPagePath":"/articles/python-dict"},{"postType":"article","postSlug":"Sort-algorithm","postPagePath":"/articles/Sort-algorithm"},{"postType":"article","postSlug":"Handy-heap-cheat-sheet","postPagePath":"/articles/Handy-heap-cheat-sheet"}]},"posts":[{"pathMapping":{"filePath":"public/content/articles/2021-03-21-Handy-heap-cheat-sheet.md","pagePath":"/articles/Handy-heap-cheat-sheet","slug":"Handy-heap-cheat-sheet"},"meta":{"content":"\n# 如何手撕一个堆\n\n# 写在前面\n\n在参加如AtCoder等算法竞技，或是刷Leetcode等算法题时，我们总是不可避免地遇到堆这种数据结构。\n\n当然，一般来说我们只要理解堆，知道堆的性质，知道怎么样用堆就足够了。在做题时只需要调用系统类库即可——在参加AtCoder时你甚至不会有时间去自己实现一个堆。\n\n但是，如果哪一天你把编程语言的类库全忘光了，又遇到一题需要频繁求最值的题目——你明知这里要用堆，却又忘记该调用的类名了，咋办？我还真遇到过这问题：三年没刷算法，只能对着一道自己明显会的题干着急，愣是想不起PriorityQueue的名字。这时候，只能自己实现一个堆出来了。\n\n# 首先要理解，然后才能实现\n\n就像人总不会忘记自行车怎么骑一样，只要理解了数据结构的原理，身体就会自动来帮我们记忆，总不会忘。那要怎么理解一个堆呢？\n\n## 先抓住重点：堆是一种树结构\n\n首先最重要的，要理解堆是一种树结构。不管实际是基于数组实现还是别的什么实现，逻辑结构是树结构没变的。\n\n再进一步，在堆这种树结构中，最重要的约束就是：**对于树中的每个节点，总有父节点大于两个子节点**（以大顶堆为例，下同）。\n\n如此一来，大小关系在树中层层传递，最终可得树的根节点（堆顶）就是整个堆的最大节点，读取堆中最大值的时间复杂度为O(1)。而我们使用堆也一般是为了利用这种堆顶元素就是最大值的特点，读取、删除操作一般会限制为只允许读取、删除堆顶元素。\n\n而且我们可以注意到，与二叉查找树比起来，堆的约束十分之弱：堆只约束父节点与子节点的大小关系，而不需要管左右子树的大小关系，甚至不需要管左右两个子节点之间谁大谁小。这样一来堆就有很多很好的性质了：\n\n1. 堆并不关注左右子树之间的大小情况，那么**要维护一个堆，基本只需要做交换父节点与子节点的操作**，而不需要像二叉查找树那样做各种旋转操作。\n2. 因为维护一个堆不需要做旋转操作，那么几乎不需要花任何代价，就可以把堆的树结构维持在完全二叉树状态。因此堆的物理结构可以设计得很紧凑，**可以使用数组进行实现**。\n3. 因为堆可以维持在完全二叉树状态，那么堆的树结构的高度就可以控制为O(logn)范围内。而如上所述，要维护一个堆我们不需要关注左右子树的关系。因此我们要在堆上做增删操作，都只需要上下交换若干次父子节点。而交换次数最多时，也只是从树根一直交换到树叶，或是从树叶一直交换到树根，最多交换logn次。那么我们可得：**堆的增删操作最坏时间复杂度为O(logn)**。\n\n## 再抓基本操作：上浮与下沉\n\n上面也提到，要维护一个堆，我们只需要上下交换若干次父子节点即可。若一个节点**过大**，就跟他的父节点**向上交换**；若一个节点**过小**，就跟他的子节点**向下交换**。\n\n假设p节点过大破坏了堆结构，即p节点比其父节点g还要大，向上交换如下图：\n\n![p与g交换](/img/in-post/2021-03-21-Handly-heap-cheat-sheet/change.png)\n\n由于除了p过大破坏堆结构以外，其他节点都符合堆结构，则有：\n\n1. p \u003e g \u003e p2\n2. g \u003e 原p \u003e c1与c2\n\n则向上交换后有只有一种破坏堆结构的可能性：p节点过大，比gg节点还要大。而解决方法也很简单，就是递归地进行向上交换，最坏情况下一直交换到堆根节点为止。\n\n同理可得，p节点过小，小于他的子节点时，向下交换后有可能需要递归地向下交换，最坏情况下一直交换到叶子节点为止。要注意向下交换时需要先比较一下两个子节点的大小，再跟较大的子节点交换，才能交换后的大小关系符合堆的要求。\n\n为了简化，我们把前面那种递归地向上交换称为**上浮操作**，把后面这种递归地向下交换称为**下沉操作**。所有需要维护堆结构的操作：增、删、建堆，都可以拆分为上浮操作或是下沉操作的组合。\n\n# 各种接口的逻辑\n\n## 插入元素——入堆\n\n把一个元素p加入堆中，我们可以先把p加到堆尾，然后对p做上浮操作。\n\n虽然堆是一个树结构，但由于堆可以用数组实现，那我们只要用O(1)的时间就可以找到堆尾。而如上面所述上浮操作最多交换到根节点 。由于用数组实现的堆是完全二叉树，交换到根节点时间复杂度为O(logn)。因此我们可得入堆的最坏时间复杂度为O(logn)。\n\n## 删除堆顶元素——出堆\n\n我们从堆中删除元素时，一般只会删除堆顶元素。\n\n删除堆顶元素时，我们可以摘出堆尾元素p填到堆顶的空缺中，再对p做下沉操作。找到堆尾元素需要O(1)时间，下沉操作最多交换到叶子节点，时间复杂度为O(logn)。因此出堆最坏时间复杂度为O(logn)。\n\n这里加点餐：出堆时把堆尾元素p放到堆顶后下沉，而p原先在堆中的最下层，一般在整个堆中都算较小的元素。因此下沉p时有较大概率需要一直把p下沉到最下层或是倒数第二层，即出堆时最坏情况出现概率较高。\n\n## 堆的初始化——建堆\n\n建立一个堆，我们有两种思路：\n\n1. 将元素一个一个插入，即对每个元素都做一次入堆操作。\n2. 当节点p左子树和右子树都各自为一个堆时，只要把p下沉就可以把左右两个堆合并成一个更大的堆。即不断地进行堆合并操作。\n\n下面我们来分析这两种建堆策略。\n\n### 元素逐个入堆\n\n上面说到，入堆就是把元素加到堆尾，再做上浮操作。把元素逐个入堆，就是把元素逐个上浮。\n\n插入第i个元素时，堆的大小为$i$（在不影响计算情况下的近似，下同），则有堆的高度为，则上浮时间复杂度为：\n\n$$T(i) = logi$$\n\n那么把所有元素上浮，则总时间复杂度为：\n\n$$\n\\begin{aligned}\nT(n) \u0026= \\sum_{i=1}^{n}logi\\\\\n\u0026= 1\\times0 + 2\\times1 + ... + 2^{logn}\\times{logn} \\\\\n\u0026=O(nlogn)\n\\end{aligned}\n$$\n\n通过把元素逐个入堆来建堆时，元素的时间复杂度可以用下图直观显示：\n\n![](/img/in-post/2021-03-21-Handly-heap-cheat-sheet/insert-length.png)\n\n（每条红线的长度就是插入该元素所需的时间，红线的总长度就是建堆所需的总时间复杂度）\n\n### 堆合并\n\n我们就可以从树结构的最底层出发不断进行堆合并，小堆合并成大堆，最后合并到根节点就建成整个堆结构。\n\n当节点的左右两个子树都是堆时，只需要对该节点进行下沉操作就可以合并左右两个堆。 不断进行堆合并，就是从下层开始把元素逐个下沉。\n\n下沉第i个元素（从顶到底数）时，以其为顶点的树高度约为$logn-logi$，则有下沉时间复杂度为：\n\n$$\nT(i) = logn-logi\n$$\n\n那么把所有元素下沉，则总时间复杂度为：\n\n$$\n\\begin{aligned}\nT(n) \u0026= \\sum_{i=1}^{n}logn-logi \\\\\n\u0026= \\frac{n}{2^{logn}}\\times{logn}+ ... + \\frac{n}{4}\\times2+\\frac{n}{2}\\times1 \\\\\n\u0026= O(n)\n\\end{aligned}\n$$\n\n同样的，我们也可以把逐个元素下沉所耗费的时间用下图来示意：\n\n![](/img/in-post/2021-03-21-Handly-heap-cheat-sheet/merge-length.png)\n\n### 两种策略的比较与理解\n\n逐个元素入堆的策略时间复杂度为$O(logn)$，堆合并策略的时间复杂度为$O(n)$，为什么会出现差异呢？我们可以从两个角度来理解：\n\n1. 从元素移动路径的角度\n\n    我们从前一小节的两幅图中可发现，元素入堆策略的图中根节点附近红线十分密集。而堆合并策略的红线则整体来说比较稀疏。\n\n    这说明元素入堆策略中，在根节点附近元素做了较多重复无效的移动——也就是说插入一个元素时上浮到了根节点附近，然后又被其他后来的元素顶替下来。一上一下自然消耗了多余的时间，而这种消耗在元素入堆策略中出现频率高，无可忽视。\n\n2. 从元素移动数量与移动距离的角度\n\n    我们知道一般来说树的越下层节点数量越多。特别是用数组实现的堆是个完全二叉树，最下层节点数量占了总数的一半。 因此**建堆的时间复杂度主要取决于底层元素**的移动距离。\n\n    用元素入堆策略需要每个元素进行上浮操作，而偏偏元素数量最多的底层移动距离最长，$O(n)$个元素需要移动$O(logn)$的距离，因此时间复杂度较高。\n\n    而堆合并策略则反过来，需要每个元素进行下沉操作。移动距离最长的只有一个根元素，底层元素几乎不需要移动，因此时间复杂度加起来只有$O(n)$。\n\n    如图所示，颜色越深代表移动距离越长。颜色深度对面积的积分即为建堆时间复杂度。\n\n    ![](/img/in-post/2021-03-21-Handly-heap-cheat-sheet/move-length.png)\n\n综上分析我们可以得出，通过堆合并策略建堆较优，时间复杂度只需$O(n)$。因此我们建堆一般采用堆合并策略，从下往上逐个元素下沉。\n\n# 代码实现\n\n其实理解了上面这些，要写一个堆出来也已经是水到渠成了。但正如Linus所说，Talk is cheap, show me the code。我们还是要亲手写一段，才能知道堆到底长啥样。\n\n```python\nT = TypeVar(\"T\")\nclass Heap(Generic[T]):\n    '''堆结构\n\n    有两个成员：\n    self.A: List[T] # 堆内元素集合，元素类型为T，储存为数组\n    self.fCompare: Callable[[T,T],bool] # 比较函数\n    \n    下面假设堆为大顶堆\n    即有self.fCompare = lambda a,b: a\u003eb\n    '''\n```\n\n## 实现树结构\n\n堆可以实现为基于数组的完全二叉树，以下标为零的节点为树根节点。\n\n对于下标为i的节点，其左子节点、右子节点、父节点的下标分别如下所示：\n\n```python\ndef lfChildOf(i:int):\n    return (i + 1) \u003c\u003c 1 - 1\n\ndef rtChildOf(i:int):\n    return (i + 1) \u003c\u003c 1\n\ndef parentOf(i:int):\n    return (i - 1) \u003e\u003e 1\n```\n\n至于为什么是这样，是因为完全二叉树与数组的对应规则如下图所示。这三个函数也没必要记住，到时候纸上画一画就记起来了。\n\n![](/img/in-post/2021-03-21-Handly-heap-cheat-sheet/tree-struct-function.png)\n\n## 实现基本操作——上浮与下沉\n\n### 上浮\n\n上浮就是递归地进行向上交换，下沉就是递归地进行向下交换。\n\n```python\ndef floatUp(self, i:int):\n    '''上浮操作\n\n    对下标为i的元素递归地进行上浮操作\n    直到该元素小于其父节点或该元素上浮到根节点\n    '''\n    # 元素i上浮到根节点时结束递归\n    if i \u003c= 0:\n        return\n    \n    # 当元素i小于其父节点时符合堆结构，结束递归\n    pr = parentOf(i)\n    if self.fCompare(self.A[pr], self.A[i]):\n        return\n    \n    # 元素i大于其父节点，交换i与其父节点并继续上浮\n    self.A[pr], self.A[i] = self.A[i], self.A[pr]\n    self.floatUp(pr)\n```\n\n### 下沉\n\n而下沉要稍微比上浮复杂。向下交换时，需要先找出较大的子节点，再跟较大的子节点进行交互。还要考虑左右子节点不存在的情况：当子节点下标超出堆大小时，子节点不存在。\n\n```python\ndef size(self):\n    '''返回堆大小\n    '''\n    return len(self.A)\n\ndef sinkDown(self, i:int):\n    '''下沉操作\n\n    对下标为i的元素递归地进行下沉操作\n    直到该元素大于其两个子节点或该元素下沉到叶子节点\n    '''\n    lc = lfChildOf(i)\n    rc = rtChildOf(i)\n\n    # 比较元素i与其两个子节点，获取三个元素中存在且最大的元素\n    larger = i\n    if lc \u003c self.size() and self.fCompare(self.A[lc], self.A[larger]):\n        larger = lc\n    if rc \u003c self.size() and self.fCompare(self.A[rc], self.A[larger]):\n        larger = rc\n    \n    # 当元素i大于其两个子节点时符合堆结构，结束递归\n    # 当元素i下沉到叶子节点时，左右子节点不存在，也会在此结束递归\n    if larger == i:\n        return\n    \n    # 元素i小于其中一个子节点，交换i与较大子节点并继续下沉\n    self.A[larger], self.A[i] = self.A[i], self.A[larger]\n    self.sinkDown(larger)\n```\n\n注意这里上浮和下沉操作使用了递归，会占用递归栈空间，因此额外空间复杂度并不是$O(1)$。\n\n但上浮和下沉都可以改为循环迭代实现，迭代实现时额外空间复杂度为$O(1)$。要改成迭代实现并不困难，还请大家尝试自己实现。\n\n## 实现各种借口——读、增、删、初始化\n\n### 读取堆顶\n\n堆一般只允许读取堆顶，即全堆最大元素。\n\n```python\ndef top(self):\n    '''返回堆顶\n    '''\n    return self.A[0]\n```\n\n### 入堆\n\n入堆时，把元素加到堆尾，再做上浮操作。\n\n```python\ndef insert(self, v:T):\n    '''入堆\n    '''\n    # 将元素加到堆尾并做上浮操作\n    self.A.append(v)\n    self.floatUp(len(self.A) - 1)\n```\n\n### 出堆\n\n出堆时，取出堆顶，把堆尾元素填到堆顶后，再做下沉操作。\n\n```python\ndef pop(self)-\u003eT:\n    '''出堆\n    '''\n    # 取出堆顶元素\n    res = self.A[0]\n\n    # 将堆尾元素填到堆顶并做下沉操作\n    self.A[0] = self.A[len(self.A) - 1]\n    self.A.pop()\n    self.sinkDown(0)\n\n    return res\n```\n\n注意入堆与出堆操作都要保证堆的大小会相应变化。\n\n### 堆初始化\n\n堆的初始化采用堆合并策略，从堆尾到堆顶逐个元素做下沉操作。\n\n```python\ndef __init__(self, A:List[T]=[], \n             fCompare:Callable[[T,T],bool]=lambda a,b:a\u003eb\n             ) -\u003e None:\n    '''堆初始化\n\n    :param A: 在数组A上进行初始化\n    :param fCompare: 比较函数，对堆中节点p与子节点c，有fCompare(p,c)==True\n    '''\n    self.A = A\n    self.fCompare = fCompare\n    for i in reversed(range(len(A))):\n        self.sinkDown(i)\n```\n\n## 整体代码\n\n### 堆的整体实现\n\n综上，堆的整体代码实现如下：\n\n```python\nfrom typing import Any, Callable, Generic, List, TypeVar\n\nT = TypeVar(\"T\")\n\ndef lfChildOf(i:int):\n    return (i + 1) \u003c\u003c 1 - 1\n\ndef rtChildOf(i:int):\n    return (i + 1) \u003c\u003c 1\n\ndef parentOf(i:int):\n    return (i - 1) \u003e\u003e 1\n\nclass Heap(Generic[T]):\n    '''堆结构\n\n    有两个成员：\n    self.A: List[T] # 堆内元素集合，元素类型为T，储存为数组\n    self.fCompare: Callable[[T,T],bool] # 比较函数\n    \n    下面假设堆为大顶堆\n    即有self.fCompare = lambda a,b: a\u003eb\n    '''\n    def __init__(self, A:List[T]=[], \n                 fCompare:Callable[[T,T],bool]=lambda a,b:a\u003eb\n                 ) -\u003e None:\n        '''堆初始化\n\n        :param A: 在数组A上进行初始化\n        :param fCompare: 比较函数，对堆中节点p与子节点c，有fCompare(p,c)==True\n        '''\n        self.A = A\n        self.fCompare = fCompare\n        for i in reversed(range(len(A))):\n            self.sinkDown(i)\n    \n    def size(self):\n        '''返回堆大小\n        '''\n        return len(self.A)\n    \n    def top(self):\n        '''返回堆顶\n        '''\n        return self.A[0]\n    \n    def sinkDown(self, i:int):\n        '''下沉操作\n\n        对下标为i的元素递归地进行下沉操作\n        直到该元素大于其两个子节点或该元素下沉到叶子节点\n        '''\n        lc = lfChildOf(i)\n        rc = rtChildOf(i)\n\n        # 比较元素i与其两个子节点，获取三个元素中存在且最大的元素\n        larger = i\n        if lc \u003c self.size() and self.fCompare(self.A[lc], self.A[larger]):\n            larger = lc\n        if rc \u003c self.size() and self.fCompare(self.A[rc], self.A[larger]):\n            larger = rc\n        \n        # 当元素i大于其两个子节点时符合堆结构，结束递归\n        # 当元素i下沉到叶子节点时，左右子节点不存在，也会在此结束递归\n        if larger == i:\n            return\n        \n        # 元素i小于其中一个子节点，交换i与较大子节点并继续下沉\n        self.A[larger], self.A[i] = self.A[i], self.A[larger]\n        self.sinkDown(larger)\n\n    def floatUp(self, i:int):\n        '''上浮操作\n\n        对下标为i的元素递归地进行上浮操作\n        直到该元素小于其父节点或该元素上浮到根节点\n        '''\n        # 元素i上浮到根节点时结束递归\n        if i \u003c= 0:\n            return\n        \n        # 当元素i小于其父节点时符合堆结构，结束递归\n        pr = parentOf(i)\n        if self.fCompare(self.A[pr], self.A[i]):\n            return\n        \n        # 元素i大于其父节点，交换i与其父节点并继续上浮\n        self.A[pr], self.A[i] = self.A[i], self.A[pr]\n        self.floatUp(pr)\n    \n    def insert(self, v:T):\n        '''入堆\n        '''\n        # 将元素加到堆尾并做上浮操作\n        self.A.append(v)\n        self.floatUp(len(self.A) - 1)\n\n    def pop(self)-\u003eT:\n        '''出堆\n        '''\n        # 取出堆顶元素\n        res = self.A[0]\n\n        # 将堆尾元素填到堆顶并做下沉操作\n        self.A[0] = self.A[len(self.A) - 1]\n        self.A.pop()\n        self.sinkDown(0)\n\n        return res\n```\n\n### 单元测试\n\n入堆、出堆等操作的简单单元测试如下：\n\n```python\nimport pytest\nimport heap\n\n@pytest.fixture\ndef initHeap():\n    return heap.Heap([1,3,4,7,2,6,5,9,0,8], \n                     lambda a,b:a\u003eb)\n\nclass Test_TestHeap:\n    def test_init_notNull(self, initHeap:heap.Heap):\n        assert initHeap.size() == 10\n        assert initHeap.top() == 9\n    \n    def test_insert_notTop(self, initHeap:heap.Heap):\n        initHeap.insert(6)\n        assert initHeap.size() == 11\n        assert initHeap.top() == 9\n    \n    def test_insert_top(self, initHeap:heap.Heap):\n        initHeap.insert(10)\n        assert initHeap.size() == 11\n        assert initHeap.top() == 10\n    \n    def test_pop(self, initHeap:heap.Heap):\n        p = initHeap.pop()\n        assert p == 9\n        assert initHeap.size() == 9\n        assert initHeap.top() == 8\n```\n\n# 关于堆排序\n\n算法竞赛中除了原生使用堆结构以外，还有一个使用到堆的地方——堆排序。堆排序有原地排序、最坏时间复杂度为$O(nlogn)$等优秀的性质，是比较常用的一个排序算法。\n\n然而，手写堆排序要注意的地方与手写堆结构有比较大的不同。堆排序时要注意的点如下：\n\n1. 堆排序时一般要求在给入数组上原地排序，不需要内部维护一个数组结构，反之，需要记录堆结构的大小。\n2. 堆结构一般占用数组前端，因此从小到大排序时，有序部分从数组末尾开始扩张，建立的堆为大顶堆。\n3. 堆排序只需要建堆与出堆操作，因此只需要实现下沉操作。\n\n关于堆排序的具体讨论，有机会的话我会另外写一篇来讲解。","title":"如何手撕一个堆","abstract":"在参加如AtCoder等算法竞技，或是刷Leetcode等算法题时，我们总是不可避免地遇到堆这种数据结构。\n当然，一般来说我们只要理解堆，知道堆的性质，知道怎么样用堆就足够了。在做题时只需要调用系统类库即可——在参加AtCoder时你甚至不会有时间去自己实现一个堆。\n但是，如果哪一天你把编程语言的类库全忘光了，又遇到一题需要频繁求最值的题目——你明知这里要用堆，却又忘记该调用的类名了，咋办？我还真遇到过这问题：三年没刷算法，只能对着一道自己明显会的题干着急，愣是想不起PriorityQueue的名字。这时候，只能自己实现一个堆出来了。","length":483,"created_at":"2021-08-28T23:09:14.000Z","updated_at":"2024-04-14T13:30:33.000Z","tags":["数据结构","算法","算法竞赛"],"license":false}},{"pathMapping":{"filePath":"public/content/articles/2021-01-11-Sort-algorithm.md","pagePath":"/articles/Sort-algorithm","slug":"Sort-algorithm"},"meta":{"content":"\n# 序言\n\n我们知道排序是算法入门基本功，排序算法有多重要想必也不需要我在这里说明了。因此这一篇就按着我的理解，聊一聊排序算法。\n\n当然我不打算随便弄个什么十大排序算法或是经典排序总结之类响当当的名头，各个算法走马看花一样拉出来遛一遍，最后变得跟网上搜索到的其他讲排序的文章一样换汤不换药。你会发现这篇文章的结构跟在网上搜索到的任何讲排序的文章都有所不同：\n\n在这篇文章里，你会发现你找不到冒泡排序——因为我认为冒泡排序只不过是一种低效率的选择排序。\n\n你会发现堆排序被当成是选择排序的一种优化——因为我认为堆排序主要在于使用了堆这种数据结构，而总体思想与选择排序相比没有太大变化。\n\n你还会找到其他与别的文章不一样的地方。因为这篇文章是我按照自己的理解来写的，我脑子里是这样想的，那文章里就是这样写的。我会按照我的理解，从纵向与横向两个维度，来理清楚各个排序算法的特性与异同。\n\n# 整篇文章的要点\n\n整篇文章以纵向——算法分类、以及横向——算法评价两个维度来进行组织。\n\n排序算法可以按照以下方式来进行分类：\n\n- 基于比较的排序算法\n    - 基于分治思想\n        - 快速排序\n        - 归并排序\n    - 基于有序区域扩展\n        - 插入排序\n        - 选择排序\n- 不基于比较的排序算法\n    - 计数排序\n    - 桶排序\n    - 基数排序\n\n文章中还会讲一讲为什么会这么分，每种分类有什么共性，分类之间有什么差异。此外，在最后还会稍微提一提外部排序与适用于并行运算的排序等。\n\n而对于纵向分类中的每一个端点，我们又会从以下五个方面，来对各个算法进行一个总体评价：\n\n- 时间复杂度（最坏，最好，平均※）\n- 空间复杂度\n- 是否原地排序\n- 是否稳定排序\n- 能否用于链表排序\n\n而由于复杂度主要只关注数量级，因此在这篇文章里会在不影响计算结果的前提下对复杂度计算进行适当的近似与简化。\n\n# 快排\n\n## 思想\n\n分治法：先把序列分为小的部分和大的部分，再将两部分分别排序。即：复杂分割，简单合并，主要操作在于分割。\n\n## 要点\n\n### 时间复杂度\n\n推导式：T(n) = T(找) + T(左) + T(右) = O(n) + 两个子问题时间复杂度。\n\n- 最好时间复杂度为每次都正好找到最中间的一个数时时间复杂度为O（nlogn）。证明略。\n- 最坏时间复杂度为每次都正好找到最旁边的数时时间复杂度为O(n^2)。证明略。\n- 平均时间复杂度为O（nlogn），推导式如下：\n\n    快速排序每一步中，将元素分为左右两边需要遍历整个列表，耗时T(n)。假设最后定位的元素为最终第i个元素，则两个子问题复杂度分别为T(i)和T(n-i-1)。\n\n    则有：\n\n    $$\n    \\begin{aligned}\n    T(n) \u0026= n + \\frac{\\sum_{i=0}^{n-1}{T(i)+T(n-i-1)}}{n} \\\\\n    \u0026=n + \\frac{2}{n}\\times\\sum_{i=0}^{n-1}{T(i)} \\\\\n    \\end{aligned}\n    $$\n\n    令 $$\\sum_{i=0}^{n}T(i) = Sum(n)$$ ，即有：\n\n    $$\n    \\begin{aligned}\n    T(n) \u0026= n + \\frac{2}{n} \\times Sum(n-1) \\\\\n    Sum(n) \u0026= \\frac{n+1}{2}T(n+1) - \\frac{n+1}{2}(n+1)\n    \\end{aligned}\n    $$\n\n    错位相减：\n\n    $$\n    \\begin{aligned}\n    Sum(n) - Sum(n-1) \u0026= \\frac{n+1}{2}T(n+1) - \\frac{n+1}{2}(n+1) - \\frac{n}{2}T(n) + \\frac{n}{2}(n) \n    \\\\\n    T(n) \u0026= \\frac{n+1}{2}T(n+1) - \\frac{n}{2}T(n) - \\frac{2n+1}{2} \n    \\\\\n    \\frac{T(n+1)}{n+2} \u0026= \\frac{T(n)}{n+1}+\\frac{2n+1}{(n+1)(n+2)} \n    \\\\\n    \u0026= \\frac{T(n)}{n+1}+\\frac{1}{n}+\\frac{1}{n+1} \n    \\\\\n    \u0026=...\n    \\\\\n    \u0026= \\frac{T(1)}{2}+1+2\\times(\\frac{1}{2}+\\frac{1}{3}+...+\\frac{1}{n})+\\frac{1}{n+1}\n    \\\\\n    \\\\\n    \\frac{T(n)}{n+1}\u0026=\\frac{T(1)}{2}+1+2\\times(\\frac{1}{2}+...+\\frac{1}{n-1})+\\frac{1}{n}\n    \\\\\n    \u0026= O(1)+O(1)+O(logn)+O(\\frac{1}{n})\n    \\\\\n    \u0026= O(logn)\n    \\end{aligned}\n    $$\n\n    其中由于 $$\\frac{1}{x}=\\frac{d(logx)}{dx}$$ ，因此 $$\\frac{1}{2}+...+\\frac{1}{n-1}=O(logn)$$ 。\n\n    则有：\n\n    $$\n    \\begin{aligned}\n    T(n)\u0026=(n+1)\\times O(logn)\\\\\n    \u0026=O(n)\\times O(logn)\\\\\n    \u0026=O(nlogn)\n    \\end{aligned}\n    $$\n\n### 额外空间复杂度\n\n考虑栈深度，额外空间复杂度为O（logn）。由于快速排序主要步骤在于分，因此必须自上而下的进行递归，无法避免栈深度。\n\n### 原地排序\n\n虽然快速排序有额外空间复杂度，但并不妨碍它是一个原地排序。\n\n### 不稳定\n\n堆排序在分操作时将元素左右交换，会破坏稳定性。\n\n### 链表形式特点\n\n- 时间复杂度不变\n- 空间复杂度不变\n- 变为稳定排序※\n\n## 手写时的易错点\n\n- 分成左右子序列时最好完全分开（一边用`\u003c=`一边用`\u003e`），不然容易造成死循环。\n- 分左右子序列时仔细考虑最初下标位置与最终下标位置，以及对应位置的值的大小。\n- 不要忘记递归的结束条件。\n\n# 归并排序\n\n## 思想\n\n分治法：先把两个子序列各自排好序，然后再合并两个子序列。即：简单分割，复杂合并。主要步骤在于合并。\n\n## 要点\n\n- 时间复杂度推导式：T(n) = 2T(n/2) + T(合)\n- 平均、最好、最坏时间复杂度都是O（nlogn），推导过程略。\n- 额外空间复杂度为O（n），合并时必须准备额外空间。但由于主要步骤在于合并，可以自下而上地进行迭代合并，可以不使用栈。\n- 非原地排序\n- 稳定排序\n\n### 链表形式\n\n- 时间复杂度不变\n- 额外空间复杂度变为O(1)※\n- 稳定排序\n- 只能使用迭代形式，不能使用递归形式\n\n## 易错点\n\n- 合并时一边结束时另一边还未结束，需要把那一边也放入合并后序列中\n- 保持稳定排序：合并时左序列等于右序列时也采用左序列\n- 不要忘记递归结束条件\n- 不要忘记循环递进条件\n\n## 进阶\n\n- 原地归并排序：时间复杂度为O（log^2n），牺牲合并的时间复杂度进行原地排序。\n- 多路归并排序：使用竞标树，多路归并，用于磁盘IO。\n\n# 插入排序\n\n## 思想\n\n有序序列不断扩张，每次从无序序列中取出元素加入有序序列，直至长度为N则完成排序。\n\n每次将无序序列当前元素插入有序序列，复杂度取决于有序序列。\n\n## 要点\n\n- 最坏、平均时间复杂度：O（n2）\n- 最好时间复杂度：基本有序情况下，O（n）\n- 额外空间复杂度：O（1）\n- 原地排序\n- 稳定排序\n- 每次插入时都要移动序列，写次数较多\n- 若查找插入位置时使用二分法查找，则可加快时间。（但不足以对时间复杂度造成影响，且最好时间复杂度也会上升为O(nlogn)）\n\n### 链表形式\n\n- 最好，最坏，平均时间复杂度不变\n- 额外空间复杂度不变\n- 稳定排序\n- 插入时不再需要移动序列，但也不能使用二分法查找\n\n## 进阶——希尔排序\n\n- 要点：\n\n    插入排序的优点在于当序列基本有序时，时间复杂度可逼近为O(n)。\n\n    但插入时移动有序序列中元素所耗时间较多，而每次只移动一步。但实际上当序列分布均匀时，有序序列中排靠后的元素在整个序列中也会排靠后。\n\n    可以把序列分为几个大步长序列，在最初的几次插入放开移动步长，让大的元素直接移动到较后位置。再往后慢慢缩小步长，此时序列基本有序，可以利用基本有序时插入排序的优势。\n\n- 时间复杂度\n    1. 当步长为2^i时，不能使时间复杂度缩短为O(nlogn)。因为一个子序列所有元素有可能比另一个子序列最大元素都要大，这时插入排序仍需进行约n^2次操作\n    2. 当步长为2^i时效率较低，因为当步长为4已经有序时，步长为2再比较是无用比较。但由于1.的问题，不能节省比较时间。\n    3. 当步长之间最小公约数较少，甚至互质时，无用比较次数会降低。\n    4. 最坏时间复杂度下限为 $$O(nlog^2n)$$ （当步长采用 $$2^i3^j$$ 时），但一般希尔排序平均时间复杂度都为 $$O(n^{\\frac{3}{2}})$$\n- 额外空间复杂度O(1)\n- 原地排序\n- 不稳定排序：希尔排序步长较大时会发生前后跳转。\n- 不能写为链表形式\n\n# 选择排序\n\n## 思想\n\n有序序列不断扩张，每次从无序序列中取出元素加入有序序列，直至长度为N则完成排序。\n\n每次将选无序序列中最小元素加到有序序列末尾，复杂度取决于无序序列。\n\n## 要点\n\n- 最坏、平均时间复杂度：O（n2）\n- 最好时间复杂度：O（n2），如能保证无序部分的最小元素所在位置一定（堆排序），能降低时间复杂度\n- 额外空间复杂度：O（1）\n- 原地排序\n- 不稳定排序（采用元素交换策略时）\n- 每次找到最小元素后，只需交换一次位置即可，写次数较少。\n- 若找到最小元素后，不直接交换而是进行数组移动，则可进行稳定排序，但写次数变多，与插入排序相比没有优势，也不能使用二分查找进行简化。\n\n### 链表形式\n\n- 最好，最坏，平均时间复杂度不变\n- 额外空间复杂度不变\n- 变为稳定排序※（因为链表不需要数组移动，稳定排序方式的缺点得以消除）\n\n## 进阶——堆排序\n\n- 要点：\n\n    选择排序中耗时最多的是取出无序序列中最小值的时间，需要遍历整个无序序列。\n\n    但实际上我们只关心无序序列中的最小值，而不关心其他值的位置。通过将无序序列建为堆，减少选择时间，降低总的时间复杂度。\n\n- 时间复杂度O（nlogn）\n- 额外空间复杂度O（1）\n- 原地排序\n- 不稳定排序\n- 操作时间复杂度：每次向下比较关注一个节点与其左右子堆顶元素，每次向上比较只关注节点与其父元素（大顶堆，堆大小为n）\n    - 下沉：向下比较，若顶元素不是最大，将顶元素与较大的子堆堆顶元素交换。递归处理该子堆顶元素，直到向下比较顶元素最大。\n\n        最好时间复杂度O（1），最坏时间复杂度为O（h）=O（logn），平均O（logn）\n\n    - 上浮：向上比较，若元素比其上层要大，交换该元素与其上层元素。递归处理其上层元素，直到向上比较不比上层要大。\n\n        最好时间复杂度O（1），最坏时间复杂度O（h）=O（logn），平均O（logn）\n\n    - 入堆：堆扩容一位，将新元素插到尾部，将该元素上浮，最坏、平均时间复杂度O（logn）\n    - 出堆：取出堆顶元素，将尾部放到堆顶，将该元素下沉，最坏、平均时间复杂度O（logn）\n    - 缺点：通常堆尾元素较小，出堆时将堆尾元素放到堆顶再下沉基本要沉到堆底，无用比较较多\n- 建堆时间复杂度O（n）\n    - 策略1：从头开始建堆，逐个元素插入，时间复杂度取决于最后一层，时间复杂度为O（nlogn）\n        - 每次将堆扩容一位，将末尾元素上浮。\n        - 时间复杂度推导：\n\n            每次插入时间：\n\n            $$\n            \\begin{aligned} T(i) \u0026= h\\\\\n            \u0026= logi\n            \\end{aligned}\n            $$\n\n            则有总时间：\n\n            $$\n            \\begin{aligned}\n            T(n) \u0026= \\sum_{i=0}^{n}logi\\\\\n            \u0026= 1\\times1 + 2\\times2+ 3\\times4 + ...+h\\times \\frac{n}{2} \\\\\n            \\\\\n            2T(n) \u0026= 1\\times2 + 2\\times4+ 3\\times8 + ...+h\\times n \\\\\n            \\\\\n            2T(n)-T(n) \u0026= h\\times n - (1+2+4+...+2^{h-1}) \\\\\n            \u0026= h\\times n - O(2^h) \\\\\n            \\\\\n            T(n) \u0026= nlogn - O(2^h) \\\\\n            \u0026= O(nlogn)\n            \\end{aligned}\n            $$\n\n            即时间复杂度为 $$O(nlogn)$$\n\n    - 策略2：从后开始建堆，小堆合并（逐个元素下沉），时间复杂度为O（n）\n        - 每次堆合并时，有三部分：左子堆，右子堆，顶元素。下沉顶元素。\n        - 时间复杂度推导：\n\n            第i个元素合并时，时间为：\n\n            $$\n            \\begin{aligned}\n            T(i) \u0026= h_{子堆}\n            \\end{aligned}\n            $$\n\n            则有总时间：\n\n            $$\n            \\begin{aligned}\n            T(n) \u0026= \\sum_{i=0}^{n} (h_{子堆}) \\\\\n            \u0026= h + (h-1)\\times2 + ... + 2 \\times \\frac{n}{4} + 1 \\times\\frac{n}{2}\\\\\n            \\\\\n            2T(n) \u0026= h \\times 2 + (h-1) \\times 4 + ... + 2 \\times \\frac{n}{2} + n \\\\\n            \\\\\n            2T(n) - T(n) \u0026= n + \\frac{n}{2} + ... + 2 - h \\\\\n            \\\\\n            T(n) \u0026= O(n) - h \\\\ \n            \u0026= O(n)\n            \\end{aligned}\n            $$\n\n            即时间复杂度为 $$O(n)$$ \n\n        - 虽说每步是做一个小堆合并，但实际上从堆尾到堆头遍历，相当于仅关注元素没有稳定，相当于可以直接使用下沉操作。\n\n# 基于比较的排序算法时间复杂度下限：逆序对思想\n\n基于比较的排序算法可以看作序列逆序对的消除。完全随机序列逆序对数量为O(n^2)，若一次元操作只消除一个逆序对，则时间复杂度不会低于O(n^2)。降低时间复杂度关键在于一次消除多个逆序对。\n\n1. 希尔排序通过增大最初的步长来企图一次消除多个逆序对。\n2. 归并排序消除逆序对最主要在于归并步骤。最后几次合并每个子步骤用O(1)时间消除O(n)个逆序对。\n3. 快速排序消除逆序对最主要在于划分步骤。每个划分步骤用O(n)时间消除O(n)+O(左长度×右长度)个逆序对。\n4. 堆排序逆序对消除方式比较Tricky，但可以看出消除逆序对大致在于出堆步骤，通过O(logn)时间复杂度消除O(n)个逆序对。（左小右大排序时需要建立左大右小的大顶堆，建堆时基本没有消除逆序对）\n\n# 最后\n\n这篇文章我们主要关注了排序算法中的大头——基于比较的排序算法。在下篇文章，我们再来看一下不基于比较的排序算法，以及外排序与并行排序。","title":"排序算法","abstract":"我们知道排序是算法入门基本功，排序算法有多重要想必也不需要我在这里说明了。因此这一篇就按着我的理解，聊一聊排序算法。\n当然我不打算随便弄个什么十大排序算法或是经典排序总结之类响当当的名头，各个算法走马看花一样拉出来遛一遍，最后变得跟网上搜索到的其他讲排序的文章一样换汤不换药。你会发现这篇文章的结构跟在网上搜索到的任何讲排序的文章都有所不同：\n在这篇文章里，你会发现你找不到冒泡排序——因为我认为冒泡排序只不过是一种低效率的选择排序。","length":342,"created_at":"2021-01-11T22:57:10.000Z","updated_at":"2024-04-14T13:30:33.000Z","tags":["数据结构","算法","排序"],"license":false}},{"pathMapping":{"filePath":"public/content/articles/2020-08-02-python-dict.md","pagePath":"/articles/python-dict","slug":"python-dict"},"meta":{"content":"\n\u003e CPython从3.6开始，字典（dict）不再是无序的了——字典的修改了原先的底层实现，变得能按字典插入的顺序进行遍历。而Python从3.7开始将字典的有序性写入语言特性，不管是Jython、IronPython还是其他Python实现，从3.7开始大家的字典都是有序的了。\n\n# 前言\n\n以前参加Python相关的面试时，面试官经常都会问一个问题：Python里的字典（dict）是有序的吗？\n\n这自然难不倒我，我也照本宣科地讲：Python的字典底层是用哈希表实现的，在不发生冲突时读写的时间复杂度是O（1），比读写时间复杂度为O（logn）的红黑树要更快。但红黑树可以按下标的大小顺序进行遍历，而Dict遍历时是无序的。\n\n我讲的时候没感觉到任何的违和感，估计面试官们也没觉得任何的不对。直到有一天，我查Python各个版本的新特性时，发现Python 3.6的What's New里有[这么一条](https://docs.python.org/3/whatsnew/3.6.html#new-dict-implementation)：\n\n\u003e New dict implementation\n\u003e \n\u003e The dict type now uses a “compact” representation based on a proposal by Raymond Hettinger which was first implemented by PyPy. The memory usage of the new dict() is between 20% and 25% smaller compared to Python 3.5.\n\u003e \n\u003e The order-preserving aspect of this new implementation is considered an implementation detail and should not be relied upon (this may change in the future, but it is desired to have this new dict implementation in the language for a few releases before changing the language spec to mandate order-preserving semantics for all current and future Python implementations; this also helps preserve backwards-compatibility with older versions of the language where random iteration order is still in effect, e.g. Python 3.5).\n\n啥情况？CPython的dict竟然优化了内存，还变有序了！？\n\n# Python 3.5 以前dict的实现\n\n先不着急看Python 3.6 里的dict，我们先来看看Python 3.5之前的dict是怎么实现的，再拿3.6来做对比。\n\n在Python 3.5以前，dict是用Hash表来实现的，而且Key和Value直接储存在Hash表上。想通过Key获取Value，只需通过Python内部的Hash函数计算出Key对应的Hash值，再映射到Hash表上对应的地址，访问该地址即可获取Key对应的Value。如下图所示：\n\n我们知道，Hash表读写时间复杂度在不发生冲突的情况下都是O（1）。\n\n为什么呢？我们可以把Hash表读写的步骤分开来看：\n\n1. 首先用Hash函数计算key的Hash值，Hash函数一般来说时间复杂度都是O（1）的。\n2. 计算出Hash值后，映射到Hash表内的数组下标，一般用取余数或是取二进制后几位的方式实现，时间复杂度也是O（1）。\n3. 然后用数组下标读取数组中实际储存的键值，数组的下标读取时间复杂度也是O（1）。\n\n这三个步骤串起来后复杂度并没有提升，总的时间复杂度自然也是O（1）的。\n\n而内部储存空间，Python字典中称为entries。entries相当于一个数组，是一段连续的内存空间，每个位置储存一个（Hash值，指向Key的指针，指向Value的指针）三元组。\n\n当然，由于抽屉原理，我们知道Hash表不可避免的会出现Hash冲突，Python的dict也不例外。\n\n而解决Hash冲突的方法有很多，比如C++的unordered_map和Go的map就用链地址法来解决冲突，用链表储存发生冲突的值。而Java更进一步，当链表长度超过8时就转换成红黑树，将链表O（n）的查找复杂度降为O（logn）。C#的HashTable则是用再散列法，内部有多个Hash函数，一次冲突了就换一个函数再算，直到不冲突为止。\n\n而Python的dict则是利用开放寻址法。当插入数据发生冲突时，就会从那个位置往后找，直到找到有空位的地址为止。要查的时候，也是把下标值映射到到地址后，先对比一下下标值相不相等，若不相等则往后继续对比。\n\n这也造成个问题，dict中的元素不能直接从entries中清理掉，不然往后寻找的查找链就会断掉了。只能是先标记住删除，等到一定时机再一并清理。\n\n此外我们也知道，当冲突过发生得过多，dict读写所需的时间也会变多，时间复杂度不再是O(1)，这也是Hash表的通病了。\n\nPython中dict初始化时，内部储存空间entries容量为8。当内部储存空间占用到一定程度（entries容量×装填因子，Python的dict中装填因子是2/3）后，就会进行倍增扩容。每次扩容都要遍历原先的元素，时间复杂度为O(n)，但基本上插入O(n)次之后才会进行一次扩容，所以扩容的均摊时间复杂度为O(1)。而扩容时会重新进行Hash值到entries位置的映射，此时就是把标记删除但仍留在entries中的元素清理掉的最佳时机。\n\nPython3.5之前这种dict的实现就有两个毛病：\n\n1. 元素的顺序不被记录。两个Key值通过Hash函数的出来的Hash值不一定能保证原来的大小关系，由于Hash冲突、扩容等影响元素的顺序也会变化。当然这种无序性也是Hash表通用的特点了。\n2. 占用了太多了无用空间。上面说到entries中每个位置储存一个（Hash值，指向Key的指针，指向Value的指针）三元组，没用到或是标记删除的位置占用了大量的空间。\n\n于是，Raymond Hettinger就提出了一种新的dict实现方式。在CPython3.6中就使用了这种新的实现方式。\n\n# CPython3.6中dict的实现\n\n当要实现一个如下的dict时：\n\n```python\nd = {\n    'timmy': 'red', \n    'barry': 'green', \n    'guido': 'blue'\n}\n```\n\n如在上一节中所讲，在Python3.5以前，在内存储存的形式可以表示成这样子：\n\n```python\nentries = [['--', '--', '--'],\n           [-8522787127447073495, 'barry', 'green'],\n           ['--', '--', '--'],\n           ['--', '--', '--'],\n           ['--', '--', '--'],\n           [-9092791511155847987, 'timmy', 'red'],\n           ['--', '--', '--'],\n           [-6480567542315338377, 'guido', 'blue']]\n```\n\n而CPython3.6以后，是以这种形式储存在内存中的：\n\n```python\nindices =  [None, 1, None, None, None, 0, None, 2]\nentries =  [[-9092791511155847987, 'timmy', 'red'],\n            [-8522787127447073495, 'barry', 'green'],\n            [-6480567542315338377, 'guido', 'blue']]\n```\n\n改变了什么？\n\n1. dict内部的entries改为按插入顺序存储，新增了一个indices用于储存元素在entries中的下标。dict整体仍是Hash表结构，但Hash值映射到indices中，而不是直接映射到entries中。\n2. 由于entries改为了按插入顺序存储，使得申请entries容量时只要申请Hash表长度的2/3即可，省去了Hash表中的无用空间，储存更紧凑。\n3. dict读写步骤从原先的3步变为4步：计算key的Hash值，映射到indices内存空间，从indices读取entries的下标值，用下标从entries中读写数据。读写时间复杂度仍保持为O(1)，冲突、删除标记等Hash表的特性也仍然存在。indices的扩容策略也仍然是倍增扩容，但因为填充因子仍然为2/3，entries每次扩容时只需申请indices长度的2/3即可。\n\n有什么好处？\n\n1. 压缩空间：原先Hash映射是直接映射到entries上，会有大量的空隙。现在Hash映射到indices上，而entries中可更紧凑地存储元素。而indices中储存的entries下标占用内存可以比entries元素要小得多——当entries长度足够短时每个下标只需占一个字节。indices中确实也还仍有空隙，但占用空间总要比旧的dict实现要小得多了。\n2. 更快的遍历：以前的实现遍历dict要遍历整个Hash表，需要挨个位置读取一下，判断它是空闲位置还是实际存在的元素。而现在只需要对变得更紧凑的entries遍历就行了。这也带来一个新的特性：entries是按照元素插入的顺序存储的，遍历entries自然也会按元素插入的顺序输出。这就给dict带来了有序性。\n3. 扩容时关注的内存块更少。原先的entries扩容时所有数据都要重新映射到内存上，cache利用率不好。现在扩容时基本可以整个entries直接复制（当然，有删除标记的数据这时要忽略）。\n\n综上，CPython3.6以后通过增加了一个indices增加了空间利用率，在维持读写时间复杂度不变的情况下增加了遍历与扩容效率。至于dict遍历变得有序，倒是有点次要的特性了。\n\n# 我们是否应利用新dict的有序性？\n\n既然Python中dict变得有序了，那我们是否应该主动去利用它呢？我是这么认为的：\n\n1. 在Python3.6中，我们不推荐利用dict的有序性。3.6时dict的有序性还只是CPython的一个实现细节，并不是Python的语言特性。当我们的代码不是在CPython环境下运行，dict的有序性就不起作用，就容易出莫名其妙的BUG了。\n2. 在Python3.7后，dict按插入顺序进行遍历的性质被写入Python语言特性中。这时确实在代码中利用dict有序性也没什么大问题。但dict这种数据结构，最主要的特性还是表现在Key映射到Value的这种关系，以及O(1)的读写时间复杂度。当我们的代码中需要关注到dict的遍历顺序时，我们就要先质问一下自己：是否应该改为用队列或是其他数据结构来实现？\n\n\n# 参考文献\n\n- [Are dictionaries ordered in Python 3.6+?](https://stackoverflow.com/questions/39980323/are-dictionaries-ordered-in-python-3-6)\n- [[Python-Dev] Python 3.6 dict becomes compact and gets a private version; and keywords become ordered](https://mail.python.org/pipermail/python-dev/2016-September/146327.html)\n- [[Python-Dev] More compact dictionaries with faster iteration](https://mail.python.org/pipermail/python-dev/2012-December/123028.html)\n- [关于python3.6中dict如何保证有序](https://zhuanlan.zhihu.com/p/36167600)\n- [python3.7源码分析－字典_小屋子大侠的博客-CSDN博客_python 字典源码](https://blog.csdn.net/qq_33339479/article/details/90446988)\n- [《深度剖析CPython解释器》9. 解密Python中字典和集合的底层实现，深度分析哈希表](https://www.cnblogs.com/traditional/p/13503114.html)\n- [CPython 源码阅读 - dict](http://blog.dreamfever.me/2018/03/12/cpython-yuan-ma-yue-du-dict/)","title":"Python字典的实现原理","abstract":"\u003e CPython从3.6开始，字典（dict）不再是无序的了——字典的修改了原先的底层实现，变得能按字典插入的顺序进行遍历。而Python从3.7开始将字典的有序性写入语言特性，不管是Jython、IronPython还是其他Python实现，从3.7开始大家的字典都是有序的了。\n以前参加Python相关的面试时，面试官经常都会问一个问题：Python里的字典（dict）是有序的吗？\n这自然难不倒我，我也照本宣科地讲：Python的字典底层是用哈希表实现的，在不发生冲突时读写的时间复杂度是O（1），比读写时间复杂度为O（logn）的红黑树要更快。但红黑树可以按下标的大小顺序进行遍历，而Dict遍历时是无序的。","length":121,"created_at":"2020-08-02T00:10:10.000Z","updated_at":"2022-03-27T13:30:33.000Z","tags":["Python","数据结构"],"license":false}}]},"__N_SSG":true},"page":"/tags/[tag]","query":{"tag":"数据结构"},"buildId":"qJidplpj0hfkJECkA8o2X","assetPrefix":"/blog-next","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>